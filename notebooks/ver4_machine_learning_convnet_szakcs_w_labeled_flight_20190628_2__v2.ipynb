{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training machine learning algorithm to detect showers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of the method is to classify events into two categories - **shower**, **noise**\n",
    "\n",
    "This procedure consists of the following parts:\n",
    "1. [Data selection](#Data-selection)\n",
    "    - Visible simulated events (simu signal above the background, track recognized in simulated shower signal).\n",
    "    - Noisy simulated events (triggered well outside of track injection GTU). However, the background noise is from the flight data.\n",
    "    - Flight noise events (triggered well outside of GTU 40).\n",
    "    - Flight classified events - classified by the manual classification.\n",
    "    \n",
    "    \n",
    "2. [Preparation of the testing and training datasets](#Preparation-of-the-testing-and-training-datasets)\n",
    "    - Limitation: only subset of all extracted features is used to decrease computational demands of feature selection. However, the subset should be large enough to contain most of the features that are expected to have some property allowing to distinguish between a shower track and noise. This procedure should be selecting around 1000 event features from the database.\n",
    "    - All visible simulated events should be included.\n",
    "    - Datasets should be balanced (same size of each class).\n",
    "    - Noise datased should be constructed by following priority: classified noise, unclassified flight, unclassified simu.\n",
    "    \n",
    "    \n",
    "3. Conversion\n",
    "    \n",
    "    \n",
    "4. Training\n",
    "    \n",
    "    \n",
    "5. [Evaluation of the recognition efficiency](#Recognition-efficiency-RFECV-model)\n",
    "    - Accuracy of classification on the whole dataset.\n",
    "    - Accuracy (specificity) of classification on the labeled dataset of noise events.\n",
    "    - Dependence of sensitivity to true energy, azimuth, and zenith angles.\n",
    "    - Dependence of sensitivity to background intensity. *NOT DONE YET (TODO)*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "(section not in the report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import subprocess\n",
    "import re\n",
    "import numpy as np\n",
    "import psycopg2 as pg\n",
    "import pandas as pd\n",
    "import pandas.io.sql as psql\n",
    "import getpass\n",
    "import matplotlib as mpl\n",
    "import argparse\n",
    "import glob\n",
    "import traceback\n",
    "import hashlib\n",
    "import math\n",
    "import collections\n",
    "import functools\n",
    "\n",
    "mpl.rcParams['figure.dpi'] = 80\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.optimize as sp_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.13/02\n"
     ]
    }
   ],
   "source": [
    "app_base_dir = '/home/spbproc/euso-spb-patt-reco-v1'\n",
    "if app_base_dir not in sys.path:\n",
    "    sys.path.append(app_base_dir)\n",
    "\n",
    "import event_processing_v3\n",
    "import event_processing_v4\n",
    "import postgresql_v3_event_storage\n",
    "import dataset_query_functions_v3\n",
    "\n",
    "import tool.acqconv\n",
    "from data_analysis_utils import *\n",
    "from data_analysis_utils_dataframes import *\n",
    "# import supervised_classification as supc    \n",
    "from utility_funtions import key_vals2val_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.preprocessing\n",
    "import sklearn.feature_selection\n",
    "import sklearn.ensemble \n",
    "# import sklearn.neural_network\n",
    "import sklearn.discriminant_analysis\n",
    "import sklearn.model_selection\n",
    "import sklearn.metrics\n",
    "import sklearn.pipeline\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_snippets_dir = 'ver4_machine_learning_convnet_szakcs_w_labeled_flight_20190628_2__v2'\n",
    "source_data_snippets_dir = 'ver4_machine_learning_w_labeled_flight_20190628_2'\n",
    "os.makedirs(data_snippets_dir, exist_ok=True)\n",
    "os.makedirs(os.path.join(data_snippets_dir, 'figures'), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "covnet_euso_base_dir = '/mnt/data_wdblue3d1/spbproc/convnet_euso'\n",
    "covnet_euso_docker_dir = covnet_euso_base_dir\n",
    "covnet_euso_dockerfile = os.path.join(covnet_euso_docker_dir, 'Dockerfile-gpu')\n",
    "covnet_euso_src_dir = os.path.join(covnet_euso_base_dir, 'src')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_processing_cls = event_processing_v4.EventProcessingV4\n",
    "event_v3_storage_provider_simu = dataset_query_functions_v3.build_event_v3_storage_provider(\n",
    "    event_storage_provider_config_file=os.path.join(app_base_dir,'config_simu_w_flatmap.ini'), \n",
    "    table_names_version='ver4',\n",
    "    event_storage_class=postgresql_v3_event_storage.PostgreSqlEventV3StorageProvider,\n",
    "    event_processing_class=event_processing_cls\n",
    ")\n",
    "\n",
    "query_functions_simu = dataset_query_functions_v3.Ver3DatasetQueryFunctions(event_v3_storage_provider_simu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_processing_cls = event_processing_v4.EventProcessingV4\n",
    "event_v3_storage_provider_flight, config_w_flatmap_flight = dataset_query_functions_v3.build_event_v3_storage_provider(\n",
    "    event_storage_provider_config_file=os.path.join(app_base_dir,'config_w_flatmap.ini'), \n",
    "    table_names_version='ver4',\n",
    "    event_storage_class=postgresql_v3_event_storage.PostgreSqlEventV3StorageProvider,\n",
    "    event_processing_class=event_processing_cls,\n",
    "    return_global_config=True\n",
    ")\n",
    "\n",
    "query_functions_flight = dataset_query_functions_v3.Ver3DatasetQueryFunctions(event_v3_storage_provider_flight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_inverse_means_frame_arr(config, calibration_map_path=None, ret_calibration_map_path=False, ret_arr=True):\n",
    "    import process_acquisition_file\n",
    "    \n",
    "    if not calibration_map_path:\n",
    "        if 'ProcessAcquisitionsParams' in config and 'calibration_map_path' in config['ProcessAcquisitionsParams']:\n",
    "            calibration_map_path = config['ProcessAcquisitionsParams']['calibration_map_path']\n",
    "        if 'FeatureExtractionParams' in config and 'calibration_map_path' in config['FeatureExtractionParams']:\n",
    "            calibration_map_path = config['FeatureExtractionParams']['calibration_map_path']\n",
    "\n",
    "    if calibration_map_path:\n",
    "        inverse_means_frame_pathname, inverse_means_frame_arr = \\\n",
    "            process_acquisition_file.prepare_inverse_means_file(\n",
    "                calibration_map_path, os.path.dirname(calibration_map_path),\n",
    "                exist_ok=True, load_if_exists=True)\n",
    "        if ret_calibration_map_path:\n",
    "            if ret_arr:\n",
    "                return calibration_map_path, inverse_means_frame_arr\n",
    "            return calibration_map_path\n",
    "        elif ret_arr:\n",
    "            return inverse_means_frame_arr\n",
    "    if ret_calibration_map_path and ret_arr:\n",
    "        return None, None\n",
    "    elif ret_calibration_map_path or ret_arr:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "inverse_means_frame_arr = load_inverse_means_frame_arr(config_w_flatmap_flight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selected columns\n",
    "\n",
    "Unlinke machine learning approach, that would be trained directly on pixels and learn to identify important features as a part of a learning (for example convolutional neural network), this approach depends on a set of preselected features. Its possible advantage is that there is no need to discover identified features and after the feature extraction, the training is faster.\n",
    "\n",
    "One of the sources of possible bias in the analysis might be initial selection of features that are analyzed by feature elimination methods.\n",
    "\n",
    "For this experiment selected features include:\n",
    "- number of triggered pixels (`trg_count_nonzero`),\n",
    "- some properties describing the background frames and background frames projection,\n",
    "- similarly for all frames of an event\n",
    "- informations about line orientations in projections of a shower\n",
    "- informations about precision of estimation the orientation of a shower\n",
    "- ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_included_columns_re_list = [\n",
    "    ('^$','source_file_(acquisition|trigger)(_full)?|global_gtu|packet_id|gtu_in_packet|event_id|num_gtu'),\n",
    "    'trg_((gtu|x)_[yx])_hough_peak_thr1_major_line_phi', \n",
    "    ('orig_x_y','count_nonzero')\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List of columns of simu data tables used for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spb_processing_v4_simu_flatmap.event\n",
      "\t- event_id\n",
      "\t- source_file_acquisition_full\n",
      "\t- source_file_trigger_full\n",
      "\t- source_file_acquisition\n",
      "\t- source_file_trigger\n",
      "\t- global_gtu\n",
      "\t- packet_id\n",
      "\t- gtu_in_packet\n",
      "\t- num_gtu\n",
      "\n",
      "spb_processing_v4_simu_flatmap.event_orig_x_y\n",
      "\t- count_nonzero\n",
      "\n",
      "spb_processing_v4_simu_flatmap.event_trg_x_y_hough_peak_thr1\n",
      "\t- major_line_phi\n",
      "\n",
      "spb_processing_v4_simu_flatmap.event_trg_gtu_x_hough_peak_thr1\n",
      "\t- major_line_phi\n",
      "\n",
      "spb_processing_v4_simu_flatmap.event_trg_gtu_y_hough_peak_thr1\n",
      "\t- major_line_phi\n",
      "\n",
      "------------------------------------------------------------\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "common_columns_for_analysis_dict = query_functions_simu.get_columns_for_classification_dict__by_excluding(\n",
    "    excluded_columns_re_list=('^.+$',),\n",
    "    default_excluded_columns_re_list=[],\n",
    "    included_columns_re_list=common_included_columns_re_list\n",
    ")\n",
    "\n",
    "print_columns_dict(common_columns_for_analysis_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_df_columns = query_functions_simu.get_dataframe_columns_from_dict(common_columns_for_analysis_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List of columns of flight data tables used for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "flight_columns_for_analysis_dict = query_functions_flight.get_columns_for_classification_dict__by_excluding(\n",
    "    excluded_columns_re_list=('^.+$',),\n",
    "    default_excluded_columns_re_list=[],\n",
    "    included_columns_re_list=common_included_columns_re_list\n",
    ")\n",
    "\n",
    "# print_columns_dict(flight_columns_for_analysis_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data selection queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simu visible events (base)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All positive samples for the training are simulated shower tracks with background from the flight data (see notebook ver4_flatmap_visible_events). Events considered as positive samples have to contain track signal (see ver4_test_selection_visualization__simu_signal notebook) and has to be considered as visible (see ver4_flatmap_simu_visible_events notebook). \n",
    "\n",
    "Visibility of the event is decided by a rule that **there should be at least two frames of the event which  contain a signal pixel that is greater or equal to maximum background intensity in the frame**.\n",
    "\n",
    "Additionally there is rule that the first trigger of a visible event should be in GTU $42\\pm10$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not in the report\n",
    "\n",
    "current_columns_for_analysis_dict = common_columns_for_analysis_dict\n",
    "\n",
    "common_select_clause_str, common_tables_list = \\\n",
    "    query_functions_simu.get_query_clauses__select(current_columns_for_analysis_dict)\n",
    "\n",
    "simu_where_clauses_str, simu_tables_list = \\\n",
    "    query_functions_simu.get_query_clauses__where_simu(\n",
    "        gtu_in_packet_distacne=(40, 10), \n",
    "        num_frames_signals_ge_bg__ge=2, num_frames_signals_ge_bg__le=999\n",
    "    )\n",
    "\n",
    "joined_select_clause_str = common_select_clause_str + ', ' + \\\n",
    "    ', '.join(['{{database_schema_name}}.simu_event.{}'.format(attr) for attr in [\n",
    "        'simu2npy_pathname', 'edetector_numphotons', 'edetector_numcellhits', 'edetector_numfee', 'eptttrigger_fnumtrigg', \n",
    "        'etruth_trueenergy', 'etruth_truetheta', 'etruth_truephi', 'egeometry_pos_z',\n",
    "        'etruth_trueshowermaxpos_x', 'etruth_trueshowermaxpos_y', 'etruth_trueshowermaxpos_z'\n",
    "    ]]) + ', ' + \\\n",
    "    ', '.join(['{{database_schema_name}}.simu_event_additional.{}'.format(attr) for attr in [\n",
    "        'num_frames_counts_gt_bg', 'num_frames_signals_gt_bg', 'num_frames_signals_ge_bg'\n",
    "    ]])\n",
    "\n",
    "joined_tables_list = common_tables_list + simu_tables_list + [\n",
    "    ('{database_schema_name}.simu_event_relation','{data_table_name}','event_id'),\n",
    "    ('{database_schema_name}.simu_event_additional','{database_schema_name}.simu_event_relation','relation_id'),\n",
    "    ('{database_schema_name}.simu_event','{database_schema_name}.simu_event_relation','simu_event_id'),\n",
    "]\n",
    "\n",
    "join_clauses_str = \\\n",
    "    query_functions_simu.get_query_clauses__join(joined_tables_list)\n",
    "\n",
    "source_data_type_num = 3001\n",
    "\n",
    "simu_events_selection_query = query_functions_simu.get_events_selection_query_plain(\n",
    "    source_data_type_num=source_data_type_num,\n",
    "    select_additional=joined_select_clause_str, \n",
    "    join_additional=join_clauses_str,\n",
    "    where_additional=simu_where_clauses_str,\n",
    "    order_by='{data_table_name}.event_id', \n",
    "    offset=0, \n",
    "    limit=350000,\n",
    "    base_select='')\n",
    "\n",
    "# print(simu_events_selection_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "simu_df = psql.read_sql(simu_events_selection_query, event_v3_storage_provider_simu.connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_id</th>\n",
       "      <th>source_file_acquisition_full</th>\n",
       "      <th>source_file_trigger_full</th>\n",
       "      <th>source_file_acquisition</th>\n",
       "      <th>source_file_trigger</th>\n",
       "      <th>global_gtu</th>\n",
       "      <th>packet_id</th>\n",
       "      <th>gtu_in_packet</th>\n",
       "      <th>num_gtu</th>\n",
       "      <th>orig_x_y_count_nonzero</th>\n",
       "      <th>...</th>\n",
       "      <th>etruth_trueenergy</th>\n",
       "      <th>etruth_truetheta</th>\n",
       "      <th>etruth_truephi</th>\n",
       "      <th>egeometry_pos_z</th>\n",
       "      <th>etruth_trueshowermaxpos_x</th>\n",
       "      <th>etruth_trueshowermaxpos_y</th>\n",
       "      <th>etruth_trueshowermaxpos_z</th>\n",
       "      <th>num_frames_counts_gt_bg</th>\n",
       "      <th>num_frames_signals_gt_bg</th>\n",
       "      <th>num_frames_signals_ge_bg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11464</td>\n",
       "      <td>/home/spbproc/SPBDATA_processed/spb_simu/posz_...</td>\n",
       "      <td>/home/spbproc/SPBDATA_processed/spb_simu/posz_...</td>\n",
       "      <td>posz_27000000.00/energy_1.00e+13/thousnd27E20....</td>\n",
       "      <td>posz_27000000.00/energy_1.00e+13/thousnd27E20....</td>\n",
       "      <td>169</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>11</td>\n",
       "      <td>2290</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000e+13</td>\n",
       "      <td>1.311530</td>\n",
       "      <td>2.02739</td>\n",
       "      <td>27000000.0</td>\n",
       "      <td>-174947.0</td>\n",
       "      <td>4109870.0</td>\n",
       "      <td>11689800.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11465</td>\n",
       "      <td>/home/spbproc/SPBDATA_processed/spb_simu/posz_...</td>\n",
       "      <td>/home/spbproc/SPBDATA_processed/spb_simu/posz_...</td>\n",
       "      <td>posz_27000000.00/energy_1.00e+13/thousnd27E20....</td>\n",
       "      <td>posz_27000000.00/energy_1.00e+13/thousnd27E20....</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>24</td>\n",
       "      <td>2290</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000e+13</td>\n",
       "      <td>0.696797</td>\n",
       "      <td>4.65066</td>\n",
       "      <td>27000000.0</td>\n",
       "      <td>977005.0</td>\n",
       "      <td>1573110.0</td>\n",
       "      <td>4239100.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11486</td>\n",
       "      <td>/home/spbproc/SPBDATA_processed/spb_simu/posz_...</td>\n",
       "      <td>/home/spbproc/SPBDATA_processed/spb_simu/posz_...</td>\n",
       "      <td>posz_27000000.00/energy_1.00e+13/thousnd27E20....</td>\n",
       "      <td>posz_27000000.00/energy_1.00e+13/thousnd27E20....</td>\n",
       "      <td>169</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>11</td>\n",
       "      <td>2290</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000e+13</td>\n",
       "      <td>1.311530</td>\n",
       "      <td>2.02739</td>\n",
       "      <td>27000000.0</td>\n",
       "      <td>-174947.0</td>\n",
       "      <td>4109870.0</td>\n",
       "      <td>11689800.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11487</td>\n",
       "      <td>/home/spbproc/SPBDATA_processed/spb_simu/posz_...</td>\n",
       "      <td>/home/spbproc/SPBDATA_processed/spb_simu/posz_...</td>\n",
       "      <td>posz_27000000.00/energy_1.00e+13/thousnd27E20....</td>\n",
       "      <td>posz_27000000.00/energy_1.00e+13/thousnd27E20....</td>\n",
       "      <td>169</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>11</td>\n",
       "      <td>2290</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000e+13</td>\n",
       "      <td>1.311530</td>\n",
       "      <td>2.02739</td>\n",
       "      <td>27000000.0</td>\n",
       "      <td>-174947.0</td>\n",
       "      <td>4109870.0</td>\n",
       "      <td>11689800.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11494</td>\n",
       "      <td>/home/spbproc/SPBDATA_processed/spb_simu/posz_...</td>\n",
       "      <td>/home/spbproc/SPBDATA_processed/spb_simu/posz_...</td>\n",
       "      <td>posz_27000000.00/energy_1.00e+13/thousnd27E20....</td>\n",
       "      <td>posz_27000000.00/energy_1.00e+13/thousnd27E20....</td>\n",
       "      <td>166</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>10</td>\n",
       "      <td>2289</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000e+13</td>\n",
       "      <td>0.941292</td>\n",
       "      <td>5.61160</td>\n",
       "      <td>27000000.0</td>\n",
       "      <td>-5503800.0</td>\n",
       "      <td>3748850.0</td>\n",
       "      <td>5879780.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   event_id                       source_file_acquisition_full  \\\n",
       "0     11464  /home/spbproc/SPBDATA_processed/spb_simu/posz_...   \n",
       "1     11465  /home/spbproc/SPBDATA_processed/spb_simu/posz_...   \n",
       "2     11486  /home/spbproc/SPBDATA_processed/spb_simu/posz_...   \n",
       "3     11487  /home/spbproc/SPBDATA_processed/spb_simu/posz_...   \n",
       "4     11494  /home/spbproc/SPBDATA_processed/spb_simu/posz_...   \n",
       "\n",
       "                            source_file_trigger_full  \\\n",
       "0  /home/spbproc/SPBDATA_processed/spb_simu/posz_...   \n",
       "1  /home/spbproc/SPBDATA_processed/spb_simu/posz_...   \n",
       "2  /home/spbproc/SPBDATA_processed/spb_simu/posz_...   \n",
       "3  /home/spbproc/SPBDATA_processed/spb_simu/posz_...   \n",
       "4  /home/spbproc/SPBDATA_processed/spb_simu/posz_...   \n",
       "\n",
       "                             source_file_acquisition  \\\n",
       "0  posz_27000000.00/energy_1.00e+13/thousnd27E20....   \n",
       "1  posz_27000000.00/energy_1.00e+13/thousnd27E20....   \n",
       "2  posz_27000000.00/energy_1.00e+13/thousnd27E20....   \n",
       "3  posz_27000000.00/energy_1.00e+13/thousnd27E20....   \n",
       "4  posz_27000000.00/energy_1.00e+13/thousnd27E20....   \n",
       "\n",
       "                                 source_file_trigger  global_gtu  packet_id  \\\n",
       "0  posz_27000000.00/energy_1.00e+13/thousnd27E20....         169          1   \n",
       "1  posz_27000000.00/energy_1.00e+13/thousnd27E20....         163          1   \n",
       "2  posz_27000000.00/energy_1.00e+13/thousnd27E20....         169          1   \n",
       "3  posz_27000000.00/energy_1.00e+13/thousnd27E20....         169          1   \n",
       "4  posz_27000000.00/energy_1.00e+13/thousnd27E20....         166          1   \n",
       "\n",
       "   gtu_in_packet  num_gtu  orig_x_y_count_nonzero            ...             \\\n",
       "0             41       11                    2290            ...              \n",
       "1             35       24                    2290            ...              \n",
       "2             41       11                    2290            ...              \n",
       "3             41       11                    2290            ...              \n",
       "4             38       10                    2289            ...              \n",
       "\n",
       "   etruth_trueenergy  etruth_truetheta  etruth_truephi egeometry_pos_z  \\\n",
       "0       1.000000e+13          1.311530         2.02739      27000000.0   \n",
       "1       1.000000e+13          0.696797         4.65066      27000000.0   \n",
       "2       1.000000e+13          1.311530         2.02739      27000000.0   \n",
       "3       1.000000e+13          1.311530         2.02739      27000000.0   \n",
       "4       1.000000e+13          0.941292         5.61160      27000000.0   \n",
       "\n",
       "   etruth_trueshowermaxpos_x  etruth_trueshowermaxpos_y  \\\n",
       "0                  -174947.0                  4109870.0   \n",
       "1                   977005.0                  1573110.0   \n",
       "2                  -174947.0                  4109870.0   \n",
       "3                  -174947.0                  4109870.0   \n",
       "4                 -5503800.0                  3748850.0   \n",
       "\n",
       "   etruth_trueshowermaxpos_z  num_frames_counts_gt_bg  \\\n",
       "0                 11689800.0                      3.0   \n",
       "1                  4239100.0                     16.0   \n",
       "2                 11689800.0                      2.0   \n",
       "3                 11689800.0                      3.0   \n",
       "4                  5879780.0                      5.0   \n",
       "\n",
       "   num_frames_signals_gt_bg  num_frames_signals_ge_bg  \n",
       "0                       3.0                       3.0  \n",
       "1                      16.0                      16.0  \n",
       "2                       2.0                       2.0  \n",
       "3                       3.0                       3.0  \n",
       "4                       5.0                       5.0  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simu_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simu noise events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simu noise events are events that are caused by a trigger well outside of GTU of shower injection into a packet. \n",
    "\n",
    "It is not ideal to use these these events as samples of the dataset because due the way the background of these events is added to the signal. Simply, if there is less packets providing the background than simualated signal tracks then same event might be repeated multiple times in the dataset. \n",
    "Besides repetition of a background packet, background of the simualted event is created by repeating sequence of background frames, thus this might cause multiple events in a same packet. How often this situation happens has not been tested. It is not expected to be very typical.\n",
    "\n",
    "Better method of constructing these events would help validity of this analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not in the report\n",
    "\n",
    "current_columns_for_analysis_dict = common_columns_for_analysis_dict\n",
    "\n",
    "common_select_clause_str, common_tables_list = \\\n",
    "    query_functions_simu.get_query_clauses__select(current_columns_for_analysis_dict)\n",
    "\n",
    "# simu_noise_where_clauses_str = ' AND abs(gtu_in_packet-42) >= 20 '\n",
    "\n",
    "# OPTIMIZATION, ROWS WITH NULL SHOULD BE ALSO ANALYZED  - noise simu df is not used\n",
    "simu_noise_where_clauses_str = '''\n",
    "    AND abs(gtu_in_packet-42) >= 20 \n",
    "    AND {database_schema_name}.event_trg_gtu_y_hough_peak_thr1.major_line_phi IS NOT NULL \n",
    "    AND {database_schema_name}.event_trg_gtu_x_hough_peak_thr1.major_line_phi IS NOT NULL \n",
    "    AND {database_schema_name}.event_trg_x_y_hough_peak_thr1.major_line_phi IS NOT NULL\n",
    "'''\n",
    "\n",
    "joined_select_clause_str = common_select_clause_str + ', ' + \\\n",
    "    ', '.join(['{{database_schema_name}}.simu_event.{}'.format(attr) for attr in [\n",
    "        'simu2npy_pathname', 'edetector_numphotons', 'edetector_numcellhits', 'edetector_numfee', 'eptttrigger_fnumtrigg', \n",
    "        'etruth_trueenergy', 'etruth_truetheta', 'etruth_truephi', 'egeometry_pos_z'\n",
    "    ]]) + ', ' + \\\n",
    "    ', '.join(['{{database_schema_name}}.simu_event_additional.{}'.format(attr) for attr in [\n",
    "        'num_frames_counts_gt_bg', 'num_frames_signals_gt_bg', 'num_frames_signals_ge_bg'\n",
    "    ]])\n",
    "\n",
    "joined_tables_list = common_tables_list + simu_tables_list + [\n",
    "    ('{database_schema_name}.simu_event_relation','{data_table_name}','event_id'),\n",
    "    ('{database_schema_name}.simu_event_additional','{database_schema_name}.simu_event_relation','relation_id'),\n",
    "    ('{database_schema_name}.simu_event','{database_schema_name}.simu_event_relation','simu_event_id'),\n",
    "]\n",
    "\n",
    "join_clauses_str = \\\n",
    "    query_functions_simu.get_query_clauses__join(joined_tables_list)\n",
    "\n",
    "source_data_type_num = 3001\n",
    "\n",
    "noise_simu_events_selection_query = query_functions_simu.get_events_selection_query_plain(\n",
    "    source_data_type_num=source_data_type_num,\n",
    "    select_additional=joined_select_clause_str, \n",
    "    join_additional=join_clauses_str,\n",
    "    where_additional=simu_noise_where_clauses_str,\n",
    "    order_by='{data_table_name}.event_id', \n",
    "    offset=0, \n",
    "    limit=350000,\n",
    "    base_select='')\n",
    "\n",
    "# print(noise_simu_events_selection_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_simu_df = psql.read_sql(noise_simu_events_selection_query, event_v3_storage_provider_simu.connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_id</th>\n",
       "      <th>source_file_acquisition_full</th>\n",
       "      <th>source_file_trigger_full</th>\n",
       "      <th>source_file_acquisition</th>\n",
       "      <th>source_file_trigger</th>\n",
       "      <th>global_gtu</th>\n",
       "      <th>packet_id</th>\n",
       "      <th>gtu_in_packet</th>\n",
       "      <th>num_gtu</th>\n",
       "      <th>orig_x_y_count_nonzero</th>\n",
       "      <th>...</th>\n",
       "      <th>edetector_numcellhits</th>\n",
       "      <th>edetector_numfee</th>\n",
       "      <th>eptttrigger_fnumtrigg</th>\n",
       "      <th>etruth_trueenergy</th>\n",
       "      <th>etruth_truetheta</th>\n",
       "      <th>etruth_truephi</th>\n",
       "      <th>egeometry_pos_z</th>\n",
       "      <th>num_frames_counts_gt_bg</th>\n",
       "      <th>num_frames_signals_gt_bg</th>\n",
       "      <th>num_frames_signals_ge_bg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11479</td>\n",
       "      <td>/home/spbproc/SPBDATA_processed/spb_simu/posz_...</td>\n",
       "      <td>/home/spbproc/SPBDATA_processed/spb_simu/posz_...</td>\n",
       "      <td>posz_27000000.00/energy_1.00e+13/thousnd27E20....</td>\n",
       "      <td>posz_27000000.00/energy_1.00e+13/thousnd27E20....</td>\n",
       "      <td>137</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>2290</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>22456</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+13</td>\n",
       "      <td>0.765393</td>\n",
       "      <td>2.473790</td>\n",
       "      <td>27000000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11500</td>\n",
       "      <td>/home/spbproc/SPBDATA_processed/spb_simu/posz_...</td>\n",
       "      <td>/home/spbproc/SPBDATA_processed/spb_simu/posz_...</td>\n",
       "      <td>posz_27000000.00/energy_1.00e+13/thousnd27E20....</td>\n",
       "      <td>posz_27000000.00/energy_1.00e+13/thousnd27E20....</td>\n",
       "      <td>201</td>\n",
       "      <td>1</td>\n",
       "      <td>73</td>\n",
       "      <td>10</td>\n",
       "      <td>2290</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>22456</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+13</td>\n",
       "      <td>0.765393</td>\n",
       "      <td>2.473790</td>\n",
       "      <td>27000000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11507</td>\n",
       "      <td>/home/spbproc/SPBDATA_processed/spb_simu/posz_...</td>\n",
       "      <td>/home/spbproc/SPBDATA_processed/spb_simu/posz_...</td>\n",
       "      <td>posz_27000000.00/energy_1.00e+13/thousnd27E20....</td>\n",
       "      <td>posz_27000000.00/energy_1.00e+13/thousnd27E20....</td>\n",
       "      <td>140</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>2290</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>19291</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+13</td>\n",
       "      <td>1.192790</td>\n",
       "      <td>0.311703</td>\n",
       "      <td>27000000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11516</td>\n",
       "      <td>/home/spbproc/SPBDATA_processed/spb_simu/posz_...</td>\n",
       "      <td>/home/spbproc/SPBDATA_processed/spb_simu/posz_...</td>\n",
       "      <td>posz_27000000.00/energy_1.00e+13/thousnd27E20....</td>\n",
       "      <td>posz_27000000.00/energy_1.00e+13/thousnd27E20....</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>105</td>\n",
       "      <td>10</td>\n",
       "      <td>2290</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>22456</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+13</td>\n",
       "      <td>0.765393</td>\n",
       "      <td>2.473790</td>\n",
       "      <td>27000000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11533</td>\n",
       "      <td>/home/spbproc/SPBDATA_processed/spb_simu/posz_...</td>\n",
       "      <td>/home/spbproc/SPBDATA_processed/spb_simu/posz_...</td>\n",
       "      <td>posz_27000000.00/energy_1.00e+13/thousnd27E20....</td>\n",
       "      <td>posz_27000000.00/energy_1.00e+13/thousnd27E20....</td>\n",
       "      <td>204</td>\n",
       "      <td>1</td>\n",
       "      <td>76</td>\n",
       "      <td>10</td>\n",
       "      <td>2290</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>19291</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+13</td>\n",
       "      <td>1.192790</td>\n",
       "      <td>0.311703</td>\n",
       "      <td>27000000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   event_id                       source_file_acquisition_full  \\\n",
       "0     11479  /home/spbproc/SPBDATA_processed/spb_simu/posz_...   \n",
       "1     11500  /home/spbproc/SPBDATA_processed/spb_simu/posz_...   \n",
       "2     11507  /home/spbproc/SPBDATA_processed/spb_simu/posz_...   \n",
       "3     11516  /home/spbproc/SPBDATA_processed/spb_simu/posz_...   \n",
       "4     11533  /home/spbproc/SPBDATA_processed/spb_simu/posz_...   \n",
       "\n",
       "                            source_file_trigger_full  \\\n",
       "0  /home/spbproc/SPBDATA_processed/spb_simu/posz_...   \n",
       "1  /home/spbproc/SPBDATA_processed/spb_simu/posz_...   \n",
       "2  /home/spbproc/SPBDATA_processed/spb_simu/posz_...   \n",
       "3  /home/spbproc/SPBDATA_processed/spb_simu/posz_...   \n",
       "4  /home/spbproc/SPBDATA_processed/spb_simu/posz_...   \n",
       "\n",
       "                             source_file_acquisition  \\\n",
       "0  posz_27000000.00/energy_1.00e+13/thousnd27E20....   \n",
       "1  posz_27000000.00/energy_1.00e+13/thousnd27E20....   \n",
       "2  posz_27000000.00/energy_1.00e+13/thousnd27E20....   \n",
       "3  posz_27000000.00/energy_1.00e+13/thousnd27E20....   \n",
       "4  posz_27000000.00/energy_1.00e+13/thousnd27E20....   \n",
       "\n",
       "                                 source_file_trigger  global_gtu  packet_id  \\\n",
       "0  posz_27000000.00/energy_1.00e+13/thousnd27E20....         137          1   \n",
       "1  posz_27000000.00/energy_1.00e+13/thousnd27E20....         201          1   \n",
       "2  posz_27000000.00/energy_1.00e+13/thousnd27E20....         140          1   \n",
       "3  posz_27000000.00/energy_1.00e+13/thousnd27E20....         233          1   \n",
       "4  posz_27000000.00/energy_1.00e+13/thousnd27E20....         204          1   \n",
       "\n",
       "   gtu_in_packet  num_gtu  orig_x_y_count_nonzero            ...             \\\n",
       "0              9       10                    2290            ...              \n",
       "1             73       10                    2290            ...              \n",
       "2             12       10                    2290            ...              \n",
       "3            105       10                    2290            ...              \n",
       "4             76       10                    2290            ...              \n",
       "\n",
       "   edetector_numcellhits  edetector_numfee  eptttrigger_fnumtrigg  \\\n",
       "0                      0             22456                      0   \n",
       "1                      0             22456                      0   \n",
       "2                      0             19291                      0   \n",
       "3                      0             22456                      0   \n",
       "4                      0             19291                      0   \n",
       "\n",
       "  etruth_trueenergy  etruth_truetheta  etruth_truephi  egeometry_pos_z  \\\n",
       "0      1.000000e+13          0.765393        2.473790       27000000.0   \n",
       "1      1.000000e+13          0.765393        2.473790       27000000.0   \n",
       "2      1.000000e+13          1.192790        0.311703       27000000.0   \n",
       "3      1.000000e+13          0.765393        2.473790       27000000.0   \n",
       "4      1.000000e+13          1.192790        0.311703       27000000.0   \n",
       "\n",
       "   num_frames_counts_gt_bg  num_frames_signals_gt_bg  num_frames_signals_ge_bg  \n",
       "0                      NaN                       NaN                       NaN  \n",
       "1                      NaN                       NaN                       NaN  \n",
       "2                      NaN                       NaN                       NaN  \n",
       "3                      NaN                       NaN                       NaN  \n",
       "4                      NaN                       NaN                       NaN  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noise_simu_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Flight improbable events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More preferred set of background noise events consists of events that triggered outside of expected range of GTU. Note that these events were triggered in a configuration with lowered thresholds (number selected bin is halved). However, using such events on its own is not sufficient because the actual flight events are those that were triggered in default configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# not in the report\n",
    "current_columns_for_analysis_dict = flight_columns_for_analysis_dict\n",
    "\n",
    "unl_noise_flight_select_clause_str, unl_noise_flight_tables_list = \\\n",
    "    query_functions_flight.get_query_clauses__select(current_columns_for_analysis_dict)\n",
    "\n",
    "unl_noise_flight_clauses_str = \\\n",
    "    query_functions_flight.get_query_clauses__join(unl_noise_flight_tables_list)\n",
    "\n",
    "unl_noise_source_data_type_num = 1\n",
    "\n",
    "unl_noise_flight_where_clauses_str = ''' \n",
    "    AND abs(gtu_in_packet-42) > 20\n",
    "    AND {database_schema_name}.event_orig_x_y.count_nonzero > 256*6\n",
    "''' \n",
    "\n",
    "# intentionally removed\n",
    "#     AND {database_schema_name}.event_trg_gtu_y_hough_peak_thr1.major_line_phi IS NOT NULL \n",
    "#     AND {database_schema_name}.event_trg_gtu_x_hough_peak_thr2.major_line_phi IS NOT NULL \n",
    "#     AND {database_schema_name}.event_trg_x_y_hough_peak_thr1.major_line_phi IS NOT NULL\n",
    "\n",
    "unl_noise_flight_events_selection_query = \\\n",
    "    query_functions_flight.get_events_selection_query_plain(\n",
    "        source_data_type_num=unl_noise_source_data_type_num,\n",
    "        select_additional=unl_noise_flight_select_clause_str, \n",
    "        join_additional=unl_noise_flight_clauses_str,\n",
    "        where_additional=unl_noise_flight_where_clauses_str,\n",
    "        order_by='{data_table_name}.event_id', \n",
    "        offset=0, \n",
    "        limit=80000,                            # intentionally selecting incomplete subset to save memory !!!!!!!!!!!!!\n",
    "    #     limit=350000,\n",
    "        base_select='')\n",
    "\n",
    "# print(unl_noise_flight_events_selection_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "all_unl_noise_flight_df = psql.read_sql(unl_noise_flight_events_selection_query, event_v3_storage_provider_flight.connection)\n",
    "# flight_df = psql.read_sql(flight_events_selection_query, event_v3_storage_provider_flight.connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_id</th>\n",
       "      <th>source_file_acquisition_full</th>\n",
       "      <th>source_file_trigger_full</th>\n",
       "      <th>source_file_acquisition</th>\n",
       "      <th>source_file_trigger</th>\n",
       "      <th>global_gtu</th>\n",
       "      <th>packet_id</th>\n",
       "      <th>gtu_in_packet</th>\n",
       "      <th>num_gtu</th>\n",
       "      <th>orig_x_y_count_nonzero</th>\n",
       "      <th>trg_x_y_hough_peak_thr1_major_line_phi</th>\n",
       "      <th>trg_gtu_x_hough_peak_thr1_major_line_phi</th>\n",
       "      <th>trg_gtu_y_hough_peak_thr1_major_line_phi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>/home/spbproc/SPBDATA_flight/allpackets-SPBEUS...</td>\n",
       "      <td>/home/spbproc/SPBDATA_processed/allpackets-SPB...</td>\n",
       "      <td>allpackets-SPBEUSO-ACQUISITION-20170429-055842...</td>\n",
       "      <td>trn_20170429-055842-001.001_C_inverse_flat_ave...</td>\n",
       "      <td>94</td>\n",
       "      <td>0</td>\n",
       "      <td>94</td>\n",
       "      <td>12</td>\n",
       "      <td>2048</td>\n",
       "      <td>5.818010</td>\n",
       "      <td>2.471490</td>\n",
       "      <td>2.41973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>65</td>\n",
       "      <td>/home/spbproc/SPBDATA_flight/allpackets-SPBEUS...</td>\n",
       "      <td>/home/spbproc/SPBDATA_processed/allpackets-SPB...</td>\n",
       "      <td>allpackets-SPBEUSO-ACQUISITION-20170429-055842...</td>\n",
       "      <td>trn_20170429-055842-001.001_C_inverse_flat_ave...</td>\n",
       "      <td>131</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>2042</td>\n",
       "      <td>1.580130</td>\n",
       "      <td>0.098652</td>\n",
       "      <td>2.57798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70</td>\n",
       "      <td>/home/spbproc/SPBDATA_flight/allpackets-SPBEUS...</td>\n",
       "      <td>/home/spbproc/SPBDATA_processed/allpackets-SPB...</td>\n",
       "      <td>allpackets-SPBEUSO-ACQUISITION-20170429-055842...</td>\n",
       "      <td>trn_20170429-055842-001.001_C_inverse_flat_ave...</td>\n",
       "      <td>226</td>\n",
       "      <td>1</td>\n",
       "      <td>98</td>\n",
       "      <td>10</td>\n",
       "      <td>2039</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.407700</td>\n",
       "      <td>1.58790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84</td>\n",
       "      <td>/home/spbproc/SPBDATA_flight/allpackets-SPBEUS...</td>\n",
       "      <td>/home/spbproc/SPBDATA_processed/allpackets-SPB...</td>\n",
       "      <td>allpackets-SPBEUSO-ACQUISITION-20170503-085415...</td>\n",
       "      <td>trn_20170503-085415-001.001_C_inverse_flat_ave...</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>2290</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>94</td>\n",
       "      <td>/home/spbproc/SPBDATA_flight/allpackets-SPBEUS...</td>\n",
       "      <td>/home/spbproc/SPBDATA_processed/allpackets-SPB...</td>\n",
       "      <td>allpackets-SPBEUSO-ACQUISITION-20170429-055842...</td>\n",
       "      <td>trn_20170429-055842-001.001_C_inverse_flat_ave...</td>\n",
       "      <td>479</td>\n",
       "      <td>3</td>\n",
       "      <td>95</td>\n",
       "      <td>10</td>\n",
       "      <td>2039</td>\n",
       "      <td>0.013996</td>\n",
       "      <td>1.329610</td>\n",
       "      <td>3.02945</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   event_id                       source_file_acquisition_full  \\\n",
       "0        63  /home/spbproc/SPBDATA_flight/allpackets-SPBEUS...   \n",
       "1        65  /home/spbproc/SPBDATA_flight/allpackets-SPBEUS...   \n",
       "2        70  /home/spbproc/SPBDATA_flight/allpackets-SPBEUS...   \n",
       "3        84  /home/spbproc/SPBDATA_flight/allpackets-SPBEUS...   \n",
       "4        94  /home/spbproc/SPBDATA_flight/allpackets-SPBEUS...   \n",
       "\n",
       "                            source_file_trigger_full  \\\n",
       "0  /home/spbproc/SPBDATA_processed/allpackets-SPB...   \n",
       "1  /home/spbproc/SPBDATA_processed/allpackets-SPB...   \n",
       "2  /home/spbproc/SPBDATA_processed/allpackets-SPB...   \n",
       "3  /home/spbproc/SPBDATA_processed/allpackets-SPB...   \n",
       "4  /home/spbproc/SPBDATA_processed/allpackets-SPB...   \n",
       "\n",
       "                             source_file_acquisition  \\\n",
       "0  allpackets-SPBEUSO-ACQUISITION-20170429-055842...   \n",
       "1  allpackets-SPBEUSO-ACQUISITION-20170429-055842...   \n",
       "2  allpackets-SPBEUSO-ACQUISITION-20170429-055842...   \n",
       "3  allpackets-SPBEUSO-ACQUISITION-20170503-085415...   \n",
       "4  allpackets-SPBEUSO-ACQUISITION-20170429-055842...   \n",
       "\n",
       "                                 source_file_trigger  global_gtu  packet_id  \\\n",
       "0  trn_20170429-055842-001.001_C_inverse_flat_ave...          94          0   \n",
       "1  trn_20170429-055842-001.001_C_inverse_flat_ave...         131          1   \n",
       "2  trn_20170429-055842-001.001_C_inverse_flat_ave...         226          1   \n",
       "3  trn_20170503-085415-001.001_C_inverse_flat_ave...          12          0   \n",
       "4  trn_20170429-055842-001.001_C_inverse_flat_ave...         479          3   \n",
       "\n",
       "   gtu_in_packet  num_gtu  orig_x_y_count_nonzero  \\\n",
       "0             94       12                    2048   \n",
       "1              3       12                    2042   \n",
       "2             98       10                    2039   \n",
       "3             12        9                    2290   \n",
       "4             95       10                    2039   \n",
       "\n",
       "   trg_x_y_hough_peak_thr1_major_line_phi  \\\n",
       "0                                5.818010   \n",
       "1                                1.580130   \n",
       "2                                     NaN   \n",
       "3                                     NaN   \n",
       "4                                0.013996   \n",
       "\n",
       "   trg_gtu_x_hough_peak_thr1_major_line_phi  \\\n",
       "0                                  2.471490   \n",
       "1                                  0.098652   \n",
       "2                                  1.407700   \n",
       "3                                       NaN   \n",
       "4                                  1.329610   \n",
       "\n",
       "   trg_gtu_y_hough_peak_thr1_major_line_phi  \n",
       "0                                   2.41973  \n",
       "1                                   2.57798  \n",
       "2                                   1.58790  \n",
       "3                                       NaN  \n",
       "4                                   3.02945  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_unl_noise_flight_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56229"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_unl_noise_flight_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intentional !!!\n",
    "unl_noise_flight_df = all_unl_noise_flight_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Flight labeled events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Important part of the dataset is set of events that were triggered by the hardware. These events are expected to be the hardest to recognize. Previous classification experiments without this set of events significantly limited usefulness of the method because it classified 60% of the flight events sample as a track (see ver4_test_selection_visualization__simu_20181018 notebook).\n",
    "Addition of a relatively small set of these events (around 1500) seems to help significantly (see ver4_machine_learning_flight_classification_tsne_cfg3 notebook).\n",
    "\n",
    "The manually classified dataset has been created using web classification tool (script web_manual_classification.py). The tool is available at http://eusospb-data.michalvrabel.sk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "EVENT_CLASSES = {\n",
    "    'pixel': 2,\n",
    "    'top_left_ec': 5,\n",
    "    'blob': 12,\n",
    "    'large_blob': 11,\n",
    "    'short_single_gtu_track': 7,\n",
    "    'single_gtu_track': 3,\n",
    "    'noise': 1,\n",
    "    'cartesian_line': 4,\n",
    "    'strong_pmt_edge': 9,\n",
    "    'few_pixels': 6,\n",
    "    'bg_increased_suddenly': 10,\n",
    "    'persistent_pixel': 14,\n",
    "    'noise_unspecified': 0,\n",
    "    'unspecified': 8,\n",
    "    'shower': 13,\n",
    "    '2pix_line': 15,\n",
    "    'bright_blob': 16,\n",
    "    'blob_and_pixels': 17,\n",
    "    'pixel_w_blob_behind': 18,\n",
    "    'storng_light': 19,\n",
    "    'sparse_blobs': 20,\n",
    "    'noise_with_weak_pixel': 21,\n",
    "    #\n",
    "    'unclassified': -1\n",
    "}\n",
    "\n",
    "INVERSE_EVENT_CLASSES = {v: k for k, v in EVENT_CLASSES.items()}\n",
    "\n",
    "EVENT_CLASS_NUMBER_UNLABELED = -1\n",
    "EVENT_CLASS_NUMBER_UNLABELED_NOISE = -2\n",
    "EVENT_CLASS_LABLELED_NOISE_FLIGHT = -3  # in case of reduced classification\n",
    "\n",
    "classification_table_name = event_v3_storage_provider_flight.database_schema_name + '.event_manual_classification'\n",
    "classification_table_cls_column_name_simple = 'class_number'\n",
    "classification_table_note_column_name_simple = 'note'\n",
    "classification_table_last_modification_column_name_simple = 'last_modification'\n",
    "classification_table_cls_column_name = classification_table_name + '.' + classification_table_cls_column_name_simple\n",
    "classification_table_note_column_name = classification_table_name + '.' + classification_table_note_column_name_simple\n",
    "classification_table_last_modification_column_name = classification_table_name + '.' + classification_table_last_modification_column_name_simple\n",
    "classification_df_cls_column_name ='manual_classification_' + classification_table_cls_column_name_simple\n",
    "classification_df_note_column_name ='manual_classification_' + classification_table_note_column_name_simple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Labeled filght noise In the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not in the report\n",
    "current_columns_for_analysis_dict = flight_columns_for_analysis_dict\n",
    "\n",
    "lbl_noise_flight_select_clause_str, lbl_noise_flight_tables_list = \\\n",
    "    query_functions_flight.get_query_clauses__select({\n",
    "        **current_columns_for_analysis_dict,\n",
    "        classification_table_name: [classification_table_cls_column_name_simple]\n",
    "    })\n",
    "\n",
    "lbl_noise_flight_clauses_str = query_functions_flight.get_query_clauses__join(lbl_noise_flight_tables_list)\n",
    "\n",
    "lbl_noise_source_data_type_num = 1\n",
    "\n",
    "lbl_noise_flight_where_clauses_str = ''' \n",
    "    AND abs(gtu_in_packet-42) <= 20\n",
    "    AND {{database_schema_name}}.event_orig_x_y.count_nonzero > 256*6\n",
    "    AND {classification_table_cls_column_name} NOT IN ({event_class_shower}, {event_class_unspecified})\n",
    "    \n",
    "'''.format(\n",
    "    classification_table_cls_column_name=classification_table_cls_column_name,\n",
    "    classification_table_last_modification_column_name=classification_table_last_modification_column_name,\n",
    "    event_class_shower=EVENT_CLASSES['shower'],\n",
    "    event_class_unspecified=EVENT_CLASSES['unspecified']\n",
    ")\n",
    "\n",
    "# intentionally removed\n",
    "\n",
    "# AND {{database_schema_name}}.event_trg_gtu_y_hough_peak_thr1.major_line_phi IS NOT NULL \n",
    "# AND {{database_schema_name}}.event_trg_gtu_x_hough_peak_thr2.major_line_phi IS NOT NULL \n",
    "# AND {{database_schema_name}}.event_trg_x_y_hough_peak_thr1.major_line_phi IS NOT NULL\n",
    "# AND {classification_table_last_modification_column_name} < '2019-04-09'\n",
    "\n",
    "lbl_noise_flight_events_selection_query = \\\n",
    "    query_functions_flight.get_events_selection_query_plain(\n",
    "        source_data_type_num=lbl_noise_source_data_type_num,\n",
    "        select_additional=lbl_noise_flight_select_clause_str, \n",
    "        join_additional=lbl_noise_flight_clauses_str,\n",
    "        where_additional=lbl_noise_flight_where_clauses_str,\n",
    "        order_by='{data_table_name}.event_id', \n",
    "        offset=0, \n",
    "        limit=10000,                            # intentionally selecting incomplete subset to save memory !!!!!!!!!!!!!\n",
    "    #     limit=350000,\n",
    "        base_select='')\n",
    "\n",
    "# print(lbl_noise_flight_events_selection_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbl_noise_flight_db_df = psql.read_sql(lbl_noise_flight_events_selection_query, event_v3_storage_provider_flight.connection)\n",
    "# lbl_noise_flight_df[classification_df_cls_column_name] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4783"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lbl_noise_flight_db_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "noise_unspecified             \t225\n",
      "noise                         \t406\n",
      "pixel                         \t767\n",
      "single_gtu_track              \t218\n",
      "cartesian_line                \t77\n",
      "top_left_ec                   \t494\n",
      "few_pixels                    \t256\n",
      "short_single_gtu_track        \t188\n",
      "bg_increased_suddenly         \t478\n",
      "large_blob                    \t199\n",
      "blob                          \t424\n",
      "persistent_pixel              \t135\n",
      "2pix_line                     \t98\n",
      "bright_blob                   \t141\n",
      "blob_and_pixels               \t36\n",
      "pixel_w_blob_behind           \t434\n",
      "storng_light                  \t18\n",
      "sparse_blobs                  \t62\n",
      "noise_with_weak_pixel         \t127\n"
     ]
    }
   ],
   "source": [
    "for k, v in lbl_noise_flight_db_df.groupby(classification_df_cls_column_name).count()['event_id'].items():\n",
    "    print('{:<30}\\t{:d}'.format(INVERSE_EVENT_CLASSES[k], v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_id</th>\n",
       "      <th>source_file_acquisition_full</th>\n",
       "      <th>source_file_trigger_full</th>\n",
       "      <th>source_file_acquisition</th>\n",
       "      <th>source_file_trigger</th>\n",
       "      <th>global_gtu</th>\n",
       "      <th>packet_id</th>\n",
       "      <th>gtu_in_packet</th>\n",
       "      <th>num_gtu</th>\n",
       "      <th>orig_x_y_count_nonzero</th>\n",
       "      <th>trg_x_y_hough_peak_thr1_major_line_phi</th>\n",
       "      <th>trg_gtu_x_hough_peak_thr1_major_line_phi</th>\n",
       "      <th>trg_gtu_y_hough_peak_thr1_major_line_phi</th>\n",
       "      <th>manual_classification_class_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75</td>\n",
       "      <td>/home/spbproc/SPBDATA_flight/allpackets-SPBEUS...</td>\n",
       "      <td>/home/spbproc/SPBDATA_processed/allpackets-SPB...</td>\n",
       "      <td>allpackets-SPBEUSO-ACQUISITION-20170501-050224...</td>\n",
       "      <td>trn_20170501-050224-001.001_C_inverse_flat_ave...</td>\n",
       "      <td>162</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>15</td>\n",
       "      <td>2290</td>\n",
       "      <td>2.50343</td>\n",
       "      <td>6.283010</td>\n",
       "      <td>6.28298</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>87</td>\n",
       "      <td>/home/spbproc/SPBDATA_flight/allpackets-SPBEUS...</td>\n",
       "      <td>/home/spbproc/SPBDATA_processed/allpackets-SPB...</td>\n",
       "      <td>allpackets-SPBEUSO-ACQUISITION-20170502-061155...</td>\n",
       "      <td>trn_20170502-061155-001.001_C_inverse_flat_ave...</td>\n",
       "      <td>168</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>92</td>\n",
       "      <td>2304</td>\n",
       "      <td>0.43432</td>\n",
       "      <td>0.018703</td>\n",
       "      <td>6.25235</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>95</td>\n",
       "      <td>/home/spbproc/SPBDATA_flight/allpackets-SPBEUS...</td>\n",
       "      <td>/home/spbproc/SPBDATA_processed/allpackets-SPB...</td>\n",
       "      <td>allpackets-SPBEUSO-ACQUISITION-20170501-050224...</td>\n",
       "      <td>trn_20170501-050224-001.001_C_inverse_flat_ave...</td>\n",
       "      <td>551</td>\n",
       "      <td>4</td>\n",
       "      <td>39</td>\n",
       "      <td>10</td>\n",
       "      <td>2290</td>\n",
       "      <td>1.53181</td>\n",
       "      <td>0.702623</td>\n",
       "      <td>1.41792</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>/home/spbproc/SPBDATA_flight/allpackets-SPBEUS...</td>\n",
       "      <td>/home/spbproc/SPBDATA_processed/allpackets-SPB...</td>\n",
       "      <td>allpackets-SPBEUSO-ACQUISITION-20170429-055842...</td>\n",
       "      <td>trn_20170429-055842-001.001_C_inverse_flat_ave...</td>\n",
       "      <td>536</td>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>12</td>\n",
       "      <td>2043</td>\n",
       "      <td>0.06070</td>\n",
       "      <td>6.277520</td>\n",
       "      <td>1.43817</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>134</td>\n",
       "      <td>/home/spbproc/SPBDATA_flight/allpackets-SPBEUS...</td>\n",
       "      <td>/home/spbproc/SPBDATA_processed/allpackets-SPB...</td>\n",
       "      <td>allpackets-SPBEUSO-ACQUISITION-20170504-113024...</td>\n",
       "      <td>trn_20170504-113024-001.001_C_inverse_flat_ave...</td>\n",
       "      <td>550</td>\n",
       "      <td>4</td>\n",
       "      <td>38</td>\n",
       "      <td>13</td>\n",
       "      <td>2290</td>\n",
       "      <td>1.37296</td>\n",
       "      <td>2.788830</td>\n",
       "      <td>1.56580</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   event_id                       source_file_acquisition_full  \\\n",
       "0        75  /home/spbproc/SPBDATA_flight/allpackets-SPBEUS...   \n",
       "1        87  /home/spbproc/SPBDATA_flight/allpackets-SPBEUS...   \n",
       "2        95  /home/spbproc/SPBDATA_flight/allpackets-SPBEUS...   \n",
       "3       100  /home/spbproc/SPBDATA_flight/allpackets-SPBEUS...   \n",
       "4       134  /home/spbproc/SPBDATA_flight/allpackets-SPBEUS...   \n",
       "\n",
       "                            source_file_trigger_full  \\\n",
       "0  /home/spbproc/SPBDATA_processed/allpackets-SPB...   \n",
       "1  /home/spbproc/SPBDATA_processed/allpackets-SPB...   \n",
       "2  /home/spbproc/SPBDATA_processed/allpackets-SPB...   \n",
       "3  /home/spbproc/SPBDATA_processed/allpackets-SPB...   \n",
       "4  /home/spbproc/SPBDATA_processed/allpackets-SPB...   \n",
       "\n",
       "                             source_file_acquisition  \\\n",
       "0  allpackets-SPBEUSO-ACQUISITION-20170501-050224...   \n",
       "1  allpackets-SPBEUSO-ACQUISITION-20170502-061155...   \n",
       "2  allpackets-SPBEUSO-ACQUISITION-20170501-050224...   \n",
       "3  allpackets-SPBEUSO-ACQUISITION-20170429-055842...   \n",
       "4  allpackets-SPBEUSO-ACQUISITION-20170504-113024...   \n",
       "\n",
       "                                 source_file_trigger  global_gtu  packet_id  \\\n",
       "0  trn_20170501-050224-001.001_C_inverse_flat_ave...         162          1   \n",
       "1  trn_20170502-061155-001.001_C_inverse_flat_ave...         168          1   \n",
       "2  trn_20170501-050224-001.001_C_inverse_flat_ave...         551          4   \n",
       "3  trn_20170429-055842-001.001_C_inverse_flat_ave...         536          4   \n",
       "4  trn_20170504-113024-001.001_C_inverse_flat_ave...         550          4   \n",
       "\n",
       "   gtu_in_packet  num_gtu  orig_x_y_count_nonzero  \\\n",
       "0             34       15                    2290   \n",
       "1             40       92                    2304   \n",
       "2             39       10                    2290   \n",
       "3             24       12                    2043   \n",
       "4             38       13                    2290   \n",
       "\n",
       "   trg_x_y_hough_peak_thr1_major_line_phi  \\\n",
       "0                                 2.50343   \n",
       "1                                 0.43432   \n",
       "2                                 1.53181   \n",
       "3                                 0.06070   \n",
       "4                                 1.37296   \n",
       "\n",
       "   trg_gtu_x_hough_peak_thr1_major_line_phi  \\\n",
       "0                                  6.283010   \n",
       "1                                  0.018703   \n",
       "2                                  0.702623   \n",
       "3                                  6.277520   \n",
       "4                                  2.788830   \n",
       "\n",
       "   trg_gtu_y_hough_peak_thr1_major_line_phi  \\\n",
       "0                                   6.28298   \n",
       "1                                   6.25235   \n",
       "2                                   1.41792   \n",
       "3                                   1.43817   \n",
       "4                                   1.56580   \n",
       "\n",
       "   manual_classification_class_number  \n",
       "0                                   0  \n",
       "1                                  19  \n",
       "2                                  15  \n",
       "3                                   1  \n",
       "4                                   2  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lbl_noise_flight_db_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Labeled flight noise in the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbl_noise_flight_df = pd.read_csv(os.path.join(source_data_snippets_dir, 'events/labeled_flight_noise.tsv.gz'), sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2619"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lbl_noise_flight_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "noise_unspecified             \t42\n",
      "noise                         \t255\n",
      "pixel                         \t532\n",
      "single_gtu_track              \t111\n",
      "cartesian_line                \t30\n",
      "top_left_ec                   \t355\n",
      "few_pixels                    \t162\n",
      "short_single_gtu_track        \t79\n",
      "bg_increased_suddenly         \t196\n",
      "large_blob                    \t145\n",
      "blob                          \t301\n",
      "persistent_pixel              \t34\n",
      "2pix_line                     \t29\n",
      "bright_blob                   \t90\n",
      "blob_and_pixels               \t24\n",
      "pixel_w_blob_behind           \t147\n",
      "storng_light                  \t5\n",
      "sparse_blobs                  \t19\n",
      "noise_with_weak_pixel         \t63\n"
     ]
    }
   ],
   "source": [
    "for k, v in lbl_noise_flight_df.groupby(classification_df_cls_column_name).count()['event_id'].items():\n",
    "    print('{:<30}\\t{:d}'.format(INVERSE_EVENT_CLASSES[k], v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>event_id</th>\n",
       "      <th>source_file_acquisition_full</th>\n",
       "      <th>source_file_trigger_full</th>\n",
       "      <th>source_file_acquisition</th>\n",
       "      <th>source_file_trigger</th>\n",
       "      <th>global_gtu</th>\n",
       "      <th>packet_id</th>\n",
       "      <th>gtu_in_packet</th>\n",
       "      <th>num_gtu</th>\n",
       "      <th>...</th>\n",
       "      <th>proc3_gtu_y_hough_peak_thr3_major_line_phi_diff_pi_over_2</th>\n",
       "      <th>proc3_gtu_x_hough_peak_thr3_major_line_phi_diff_0</th>\n",
       "      <th>proc3_gtu_x_hough_peak_thr3_major_line_phi_diff_pi_over_2</th>\n",
       "      <th>norm_proc1_x_y_hough_peak_thr2_line_clusters_count</th>\n",
       "      <th>norm_proc1_x_y_hough_peak_thr2_line_clusters_max_peak_clu_width</th>\n",
       "      <th>norm_proc1_gtu_y_hough_peak_thr2_line_clusters_max_peak_clu_width</th>\n",
       "      <th>norm_proc1_gtu_x_hough_peak_thr2_line_clusters_max_peak_clu_width</th>\n",
       "      <th>norm_trg_count_nonzero</th>\n",
       "      <th>norm_num_gtu</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>/home/spbproc/SPBDATA_flight/allpackets-SPBEUS...</td>\n",
       "      <td>/home/spbproc/SPBDATA_processed/allpackets-SPB...</td>\n",
       "      <td>allpackets-SPBEUSO-ACQUISITION-20170501-050224...</td>\n",
       "      <td>trn_20170501-050224-001.001_C_inverse_flat_ave...</td>\n",
       "      <td>162</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>1.568001</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>1.570768</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.972067</td>\n",
       "      <td>0.971591</td>\n",
       "      <td>0.977654</td>\n",
       "      <td>0.020705</td>\n",
       "      <td>0.148515</td>\n",
       "      <td>324.316832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>95</td>\n",
       "      <td>/home/spbproc/SPBDATA_flight/allpackets-SPBEUS...</td>\n",
       "      <td>/home/spbproc/SPBDATA_processed/allpackets-SPB...</td>\n",
       "      <td>allpackets-SPBEUSO-ACQUISITION-20170501-050224...</td>\n",
       "      <td>trn_20170501-050224-001.001_C_inverse_flat_ave...</td>\n",
       "      <td>551</td>\n",
       "      <td>4</td>\n",
       "      <td>39</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.079414</td>\n",
       "      <td>1.194000</td>\n",
       "      <td>0.376796</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.910615</td>\n",
       "      <td>0.920455</td>\n",
       "      <td>0.893855</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>0.099010</td>\n",
       "      <td>324.316832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>134</td>\n",
       "      <td>/home/spbproc/SPBDATA_flight/allpackets-SPBEUS...</td>\n",
       "      <td>/home/spbproc/SPBDATA_processed/allpackets-SPB...</td>\n",
       "      <td>allpackets-SPBEUSO-ACQUISITION-20170504-113024...</td>\n",
       "      <td>trn_20170504-113024-001.001_C_inverse_flat_ave...</td>\n",
       "      <td>550</td>\n",
       "      <td>4</td>\n",
       "      <td>38</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>0.212524</td>\n",
       "      <td>1.548263</td>\n",
       "      <td>0.022534</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.826816</td>\n",
       "      <td>0.892045</td>\n",
       "      <td>0.910615</td>\n",
       "      <td>0.000327</td>\n",
       "      <td>0.128713</td>\n",
       "      <td>324.316832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>322</td>\n",
       "      <td>/home/spbproc/SPBDATA_flight/allpackets-SPBEUS...</td>\n",
       "      <td>/home/spbproc/SPBDATA_processed/allpackets-SPB...</td>\n",
       "      <td>allpackets-SPBEUSO-ACQUISITION-20170505-100211...</td>\n",
       "      <td>trn_20170505-100211-001.001_C_inverse_flat_ave...</td>\n",
       "      <td>547</td>\n",
       "      <td>4</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>1.561131</td>\n",
       "      <td>0.007136</td>\n",
       "      <td>1.563660</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.944134</td>\n",
       "      <td>0.948864</td>\n",
       "      <td>0.921788</td>\n",
       "      <td>0.000246</td>\n",
       "      <td>0.099010</td>\n",
       "      <td>324.316832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>520</td>\n",
       "      <td>/home/spbproc/SPBDATA_flight/allpackets-SPBEUS...</td>\n",
       "      <td>/home/spbproc/SPBDATA_processed/allpackets-SPB...</td>\n",
       "      <td>allpackets-SPBEUSO-ACQUISITION-20170505-100211...</td>\n",
       "      <td>trn_20170505-100211-001.001_C_inverse_flat_ave...</td>\n",
       "      <td>1576</td>\n",
       "      <td>12</td>\n",
       "      <td>40</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>1.495681</td>\n",
       "      <td>0.210610</td>\n",
       "      <td>1.360186</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.899441</td>\n",
       "      <td>0.926136</td>\n",
       "      <td>0.916201</td>\n",
       "      <td>0.000430</td>\n",
       "      <td>0.099010</td>\n",
       "      <td>324.316832</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1195 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  event_id                       source_file_acquisition_full  \\\n",
       "0           0        75  /home/spbproc/SPBDATA_flight/allpackets-SPBEUS...   \n",
       "1           1        95  /home/spbproc/SPBDATA_flight/allpackets-SPBEUS...   \n",
       "2           2       134  /home/spbproc/SPBDATA_flight/allpackets-SPBEUS...   \n",
       "3           3       322  /home/spbproc/SPBDATA_flight/allpackets-SPBEUS...   \n",
       "4           4       520  /home/spbproc/SPBDATA_flight/allpackets-SPBEUS...   \n",
       "\n",
       "                            source_file_trigger_full  \\\n",
       "0  /home/spbproc/SPBDATA_processed/allpackets-SPB...   \n",
       "1  /home/spbproc/SPBDATA_processed/allpackets-SPB...   \n",
       "2  /home/spbproc/SPBDATA_processed/allpackets-SPB...   \n",
       "3  /home/spbproc/SPBDATA_processed/allpackets-SPB...   \n",
       "4  /home/spbproc/SPBDATA_processed/allpackets-SPB...   \n",
       "\n",
       "                             source_file_acquisition  \\\n",
       "0  allpackets-SPBEUSO-ACQUISITION-20170501-050224...   \n",
       "1  allpackets-SPBEUSO-ACQUISITION-20170501-050224...   \n",
       "2  allpackets-SPBEUSO-ACQUISITION-20170504-113024...   \n",
       "3  allpackets-SPBEUSO-ACQUISITION-20170505-100211...   \n",
       "4  allpackets-SPBEUSO-ACQUISITION-20170505-100211...   \n",
       "\n",
       "                                 source_file_trigger  global_gtu  packet_id  \\\n",
       "0  trn_20170501-050224-001.001_C_inverse_flat_ave...         162          1   \n",
       "1  trn_20170501-050224-001.001_C_inverse_flat_ave...         551          4   \n",
       "2  trn_20170504-113024-001.001_C_inverse_flat_ave...         550          4   \n",
       "3  trn_20170505-100211-001.001_C_inverse_flat_ave...         547          4   \n",
       "4  trn_20170505-100211-001.001_C_inverse_flat_ave...        1576         12   \n",
       "\n",
       "   gtu_in_packet  num_gtu     ...      \\\n",
       "0             34       15     ...       \n",
       "1             39       10     ...       \n",
       "2             38       13     ...       \n",
       "3             35       10     ...       \n",
       "4             40       10     ...       \n",
       "\n",
       "   proc3_gtu_y_hough_peak_thr3_major_line_phi_diff_pi_over_2  \\\n",
       "0                                           1.568001           \n",
       "1                                           0.079414           \n",
       "2                                           0.212524           \n",
       "3                                           1.561131           \n",
       "4                                           1.495681           \n",
       "\n",
       "   proc3_gtu_x_hough_peak_thr3_major_line_phi_diff_0  \\\n",
       "0                                           0.000028   \n",
       "1                                           1.194000   \n",
       "2                                           1.548263   \n",
       "3                                           0.007136   \n",
       "4                                           0.210610   \n",
       "\n",
       "   proc3_gtu_x_hough_peak_thr3_major_line_phi_diff_pi_over_2  \\\n",
       "0                                           1.570768           \n",
       "1                                           0.376796           \n",
       "2                                           0.022534           \n",
       "3                                           1.563660           \n",
       "4                                           1.360186           \n",
       "\n",
       "   norm_proc1_x_y_hough_peak_thr2_line_clusters_count  \\\n",
       "0                                           0.833333    \n",
       "1                                           0.750000    \n",
       "2                                           0.750000    \n",
       "3                                           0.833333    \n",
       "4                                           0.583333    \n",
       "\n",
       "   norm_proc1_x_y_hough_peak_thr2_line_clusters_max_peak_clu_width  \\\n",
       "0                                           0.972067                 \n",
       "1                                           0.910615                 \n",
       "2                                           0.826816                 \n",
       "3                                           0.944134                 \n",
       "4                                           0.899441                 \n",
       "\n",
       "   norm_proc1_gtu_y_hough_peak_thr2_line_clusters_max_peak_clu_width  \\\n",
       "0                                           0.971591                   \n",
       "1                                           0.920455                   \n",
       "2                                           0.892045                   \n",
       "3                                           0.948864                   \n",
       "4                                           0.926136                   \n",
       "\n",
       "   norm_proc1_gtu_x_hough_peak_thr2_line_clusters_max_peak_clu_width  \\\n",
       "0                                           0.977654                   \n",
       "1                                           0.893855                   \n",
       "2                                           0.910615                   \n",
       "3                                           0.921788                   \n",
       "4                                           0.916201                   \n",
       "\n",
       "   norm_trg_count_nonzero  norm_num_gtu        rank  \n",
       "0                0.020705      0.148515  324.316832  \n",
       "1                0.000102      0.099010  324.316832  \n",
       "2                0.000327      0.128713  324.316832  \n",
       "3                0.000246      0.099010  324.316832  \n",
       "4                0.000430      0.099010  324.316832  \n",
       "\n",
       "[5 rows x 1195 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lbl_noise_flight_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Flight unclassified probable events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Small subset of flight unclassified events, that were caused by trigger around GTU 42, are selected to be used for basic check of the data reduction capability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not in the report\n",
    "current_columns_for_analysis_dict = flight_columns_for_analysis_dict\n",
    "\n",
    "unl_flight_select_clause_str, unl_flight_tables_list = \\\n",
    "    query_functions_flight.get_query_clauses__select(current_columns_for_analysis_dict)\n",
    "\n",
    "unl_flight_clauses_str = \\\n",
    "    query_functions_flight.get_query_clauses__join(unl_flight_tables_list)\n",
    "\n",
    "unl_flight_source_data_type_num = 1\n",
    "# intentionally keeping trg conditions, for consistency\n",
    "unl_flight_where_clauses_str = ''' \n",
    "    AND abs(gtu_in_packet-42) < 20\n",
    "    AND {{database_schema_name}}.event_trg_gtu_y_hough_peak_thr1.major_line_phi IS NOT NULL \n",
    "    AND {{database_schema_name}}.event_trg_gtu_x_hough_peak_thr1.major_line_phi IS NOT NULL \n",
    "    AND {{database_schema_name}}.event_trg_x_y_hough_peak_thr1.major_line_phi IS NOT NULL\n",
    "    AND {{database_schema_name}}.event_orig_x_y.count_nonzero > 256*6\n",
    "    AND NOT EXISTS(\n",
    "        SELECT {classification_table}.{{data_table_pk}} \n",
    "        FROM {classification_table} \n",
    "        WHERE {classification_table}.{{data_table_pk}} = {{data_table_name}}.{{data_table_pk}} LIMIT 1\n",
    "    )\n",
    "'''.format(\n",
    "    classification_table=classification_table_name,\n",
    ")\n",
    "\n",
    "unl_flight_events_selection_query = query_functions_flight.get_events_selection_query_plain(\n",
    "    source_data_type_num=unl_flight_source_data_type_num,\n",
    "    select_additional=unl_flight_select_clause_str, \n",
    "    join_additional=unl_flight_clauses_str,\n",
    "    where_additional=unl_flight_where_clauses_str,\n",
    "    order_by='{data_table_name}.event_id',  # 'RANDOM()', # it might be skewed\n",
    "    offset=0, \n",
    "    limit=10000,                            # intentionally selecting incomplete subset to save memory !!!!!!!!!!!!!\n",
    "#     limit=350000,\n",
    "    base_select='')\n",
    "\n",
    "# print(unl_flight_events_selection_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "unl_flight_df = psql.read_sql(unl_flight_events_selection_query, event_v3_storage_provider_flight.connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_id</th>\n",
       "      <th>source_file_acquisition_full</th>\n",
       "      <th>source_file_trigger_full</th>\n",
       "      <th>source_file_acquisition</th>\n",
       "      <th>source_file_trigger</th>\n",
       "      <th>global_gtu</th>\n",
       "      <th>packet_id</th>\n",
       "      <th>gtu_in_packet</th>\n",
       "      <th>num_gtu</th>\n",
       "      <th>orig_x_y_count_nonzero</th>\n",
       "      <th>trg_x_y_hough_peak_thr1_major_line_phi</th>\n",
       "      <th>trg_gtu_x_hough_peak_thr1_major_line_phi</th>\n",
       "      <th>trg_gtu_y_hough_peak_thr1_major_line_phi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>61</td>\n",
       "      <td>/home/spbproc/SPBDATA_flight/allpackets-SPBEUS...</td>\n",
       "      <td>/home/spbproc/SPBDATA_processed/allpackets-SPB...</td>\n",
       "      <td>allpackets-SPBEUSO-ACQUISITION-20170429-055842...</td>\n",
       "      <td>trn_20170429-055842-001.001_C_inverse_flat_ave...</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>11</td>\n",
       "      <td>2045</td>\n",
       "      <td>0.433973</td>\n",
       "      <td>0.629839</td>\n",
       "      <td>2.798010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67</td>\n",
       "      <td>/home/spbproc/SPBDATA_flight/allpackets-SPBEUS...</td>\n",
       "      <td>/home/spbproc/SPBDATA_processed/allpackets-SPB...</td>\n",
       "      <td>allpackets-SPBEUSO-ACQUISITION-20170429-055842...</td>\n",
       "      <td>trn_20170429-055842-001.001_C_inverse_flat_ave...</td>\n",
       "      <td>166</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>11</td>\n",
       "      <td>2041</td>\n",
       "      <td>0.140550</td>\n",
       "      <td>0.029569</td>\n",
       "      <td>2.507860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>73</td>\n",
       "      <td>/home/spbproc/SPBDATA_flight/allpackets-SPBEUS...</td>\n",
       "      <td>/home/spbproc/SPBDATA_processed/allpackets-SPB...</td>\n",
       "      <td>allpackets-SPBEUSO-ACQUISITION-20170501-050224...</td>\n",
       "      <td>trn_20170501-050224-001.001_C_inverse_flat_ave...</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>22</td>\n",
       "      <td>2290</td>\n",
       "      <td>5.521390</td>\n",
       "      <td>2.409180</td>\n",
       "      <td>0.313222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>77</td>\n",
       "      <td>/home/spbproc/SPBDATA_flight/allpackets-SPBEUS...</td>\n",
       "      <td>/home/spbproc/SPBDATA_processed/allpackets-SPB...</td>\n",
       "      <td>allpackets-SPBEUSO-ACQUISITION-20170430-072445...</td>\n",
       "      <td>trn_20170430-072445-001.001_C_inverse_flat_ave...</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>33</td>\n",
       "      <td>2290</td>\n",
       "      <td>5.914780</td>\n",
       "      <td>0.000931</td>\n",
       "      <td>6.276950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>78</td>\n",
       "      <td>/home/spbproc/SPBDATA_flight/allpackets-SPBEUS...</td>\n",
       "      <td>/home/spbproc/SPBDATA_processed/allpackets-SPB...</td>\n",
       "      <td>allpackets-SPBEUSO-ACQUISITION-20170429-055842...</td>\n",
       "      <td>trn_20170429-055842-001.001_C_inverse_flat_ave...</td>\n",
       "      <td>296</td>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "      <td>13</td>\n",
       "      <td>2056</td>\n",
       "      <td>2.401640</td>\n",
       "      <td>6.274460</td>\n",
       "      <td>6.281470</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   event_id                       source_file_acquisition_full  \\\n",
       "0        61  /home/spbproc/SPBDATA_flight/allpackets-SPBEUS...   \n",
       "1        67  /home/spbproc/SPBDATA_flight/allpackets-SPBEUS...   \n",
       "2        73  /home/spbproc/SPBDATA_flight/allpackets-SPBEUS...   \n",
       "3        77  /home/spbproc/SPBDATA_flight/allpackets-SPBEUS...   \n",
       "4        78  /home/spbproc/SPBDATA_flight/allpackets-SPBEUS...   \n",
       "\n",
       "                            source_file_trigger_full  \\\n",
       "0  /home/spbproc/SPBDATA_processed/allpackets-SPB...   \n",
       "1  /home/spbproc/SPBDATA_processed/allpackets-SPB...   \n",
       "2  /home/spbproc/SPBDATA_processed/allpackets-SPB...   \n",
       "3  /home/spbproc/SPBDATA_processed/allpackets-SPB...   \n",
       "4  /home/spbproc/SPBDATA_processed/allpackets-SPB...   \n",
       "\n",
       "                             source_file_acquisition  \\\n",
       "0  allpackets-SPBEUSO-ACQUISITION-20170429-055842...   \n",
       "1  allpackets-SPBEUSO-ACQUISITION-20170429-055842...   \n",
       "2  allpackets-SPBEUSO-ACQUISITION-20170501-050224...   \n",
       "3  allpackets-SPBEUSO-ACQUISITION-20170430-072445...   \n",
       "4  allpackets-SPBEUSO-ACQUISITION-20170429-055842...   \n",
       "\n",
       "                                 source_file_trigger  global_gtu  packet_id  \\\n",
       "0  trn_20170429-055842-001.001_C_inverse_flat_ave...          39          0   \n",
       "1  trn_20170429-055842-001.001_C_inverse_flat_ave...         166          1   \n",
       "2  trn_20170501-050224-001.001_C_inverse_flat_ave...          39          0   \n",
       "3  trn_20170430-072445-001.001_C_inverse_flat_ave...          38          0   \n",
       "4  trn_20170429-055842-001.001_C_inverse_flat_ave...         296          2   \n",
       "\n",
       "   gtu_in_packet  num_gtu  orig_x_y_count_nonzero  \\\n",
       "0             39       11                    2045   \n",
       "1             38       11                    2041   \n",
       "2             39       22                    2290   \n",
       "3             38       33                    2290   \n",
       "4             40       13                    2056   \n",
       "\n",
       "   trg_x_y_hough_peak_thr1_major_line_phi  \\\n",
       "0                                0.433973   \n",
       "1                                0.140550   \n",
       "2                                5.521390   \n",
       "3                                5.914780   \n",
       "4                                2.401640   \n",
       "\n",
       "   trg_gtu_x_hough_peak_thr1_major_line_phi  \\\n",
       "0                                  0.629839   \n",
       "1                                  0.029569   \n",
       "2                                  2.409180   \n",
       "3                                  0.000931   \n",
       "4                                  6.274460   \n",
       "\n",
       "   trg_gtu_y_hough_peak_thr1_major_line_phi  \n",
       "0                                  2.798010  \n",
       "1                                  2.507860  \n",
       "2                                  0.313222  \n",
       "3                                  6.276950  \n",
       "4                                  6.281470  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unl_flight_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification column for unlabeled filght\n",
    "(not in the report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "unl_flight_df[classification_df_cls_column_name] = EVENT_CLASS_NUMBER_UNLABELED\n",
    "unl_noise_flight_df[classification_df_cls_column_name] = EVENT_CLASS_NUMBER_UNLABELED_NOISE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flight datasets in dict\n",
    "(not in the report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "flight_df_dict = {\n",
    "    'unl_noise_flight_df': unl_noise_flight_df, \n",
    "    'lbl_noise_flight_df': lbl_noise_flight_df, \n",
    "    'unl_flight_df': unl_flight_df\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Closing connections\n",
    "(not in the report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_v3_storage_provider_simu.connection.close()\n",
    "event_v3_storage_provider_flight.connection.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combined simulations dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simu dataframes are combined because they have same columns. \n",
    "Then within this dataset events are classified into four groups based on \n",
    "- **Query classification information** - Primary classification based on the original data selection query - original intention of the data selection.\n",
    "- **Simu signal classification information** - Secondary classification is addition of labeled simu signal events. The events are loaded from tables prepared in ver4_test_selection_visualization__simu_signal notebook.\n",
    "\n",
    "The groups are the following:\n",
    "- **simu noise** - data selected by query intended to select visible events but simu signal is classified as noisy simu data\n",
    "- **simu track** - data selected by query intended to select visible events and simu signal is classified as a signal - <br> *these events will be used as positive samples for machine learning algorithms*\n",
    "- **noise track** - data selected by query intended to select noise events but simu signal is classified as a shower\n",
    "- **noise noise** - data selected by query intended to select noise events and contains simu signal classified as noisy simu data (could be used as a part of negative samples dataset, although it is not ideal)\n",
    "- **simu unclassified**, **noise unclassified** - data without any labelling for simu signal data, generaly should consist of short tracks or noisy tracks, in-between easily recognizable tracks and noise.\n",
    "- **simu noise underflow**, **simu noise overflow**, **simu track underflow**, **simu track overflow** - data selected by query intended to select visible events but no simu signal is present (ideally should be empty)\n",
    "- **noise noise underflow**, **noise noise overflow**, **noise track underflow**, **noise track overflow**   - data selected by query intended to select noise events and no simu signal is present - <br> *these events will be used as negative samples but with a low priority*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_simu_df = pd.concat([simu_df, noise_simu_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flight_columns_list = list(lbl_noise_flight_df.columns.values)\n",
    "# combined_flight_df = pd.concat([unl_noise_flight_df[flight_columns_list], lbl_noise_flight_df[flight_columns_list], unl_flight_df[flight_columns_list]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(simu_df) = 35607\n",
      "len(noise_simu_df) = 128793\n",
      "len(combined_simu_df) = 164400\n"
     ]
    }
   ],
   "source": [
    "print('len(simu_df) =', len(simu_df))\n",
    "print('len(noise_simu_df) =', len(noise_simu_df))\n",
    "print('len(combined_simu_df) =', len(combined_simu_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### $R_{max}$ property of simulated showers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'etruth_trueshowermaxpos_x', 'etruth_trueshowermaxpos_y', 'etruth_trueshowermaxpos_z'\n",
    "combined_simu_df['calc_etruth_trueshower_rmax'] = np.hypot(combined_simu_df['etruth_trueshowermaxpos_x'], combined_simu_df['etruth_trueshowermaxpos_y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Query classification information\n",
    "Primary classification based on the original data selection query - original intention of the data selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_simu_df['cond_selection_query'] = 'undefined'\n",
    "combined_simu_df.loc[combined_simu_df['event_id'].isin(simu_df['event_id']), 'cond_selection_query'] = 'simu'\n",
    "combined_simu_df.loc[combined_simu_df['event_id'].isin(noise_simu_df['event_id']), 'cond_selection_query'] = 'noise'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "if('simu_df' in locals()): del simu_df\n",
    "if('noise_simu_df' in locals()): del noise_simu_df\n",
    "# if('unl_noise_flight_df' in locals()): del unl_noise_flight_df\n",
    "# if('lbl_noise_flight_df' in locals()): del lbl_noise_flight_df\n",
    "# if('unl_flight_df' in locals()): del unl_flight_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simu signal classification information\n",
    "Secondary classification is addition of labeled simu signal events.\n",
    "The events are loaded from tables prepared in ver4_test_selection_visualization__simu_signal notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [['event_id', 'source_file_acquisition', 'global_gtu', 'packet_id', 'gtu_in_packet', 'num_gtu', 'source_file_acquisition_full']]\n",
    "\n",
    "simu_signal_data_snippets_dir = 'ver4_simu_signal_data_snippets'\n",
    "simu_signal_visible_tracks_table_path = os.path.join(simu_signal_data_snippets_dir, 'visible_tracks_table.tsv')\n",
    "simu_signal_noisy_events_table_path = os.path.join(simu_signal_data_snippets_dir, 'noisy_events_table.tsv')\n",
    "\n",
    "combined_simu_df, unclassified_simu_df, \\\n",
    "track_simu_df, track_underflow_simu_df, track_overflow_simu_df, \\\n",
    "noise_simu_df, noise_underflow_simu_df, noise_overflow_simu_df, \\\n",
    "simu_signal_track_events_df, simu_signal_noisy_events_df = \\\n",
    "    add_classification_columns(\n",
    "        combined_simu_df, \n",
    "        simu_signal_visible_tracks_table_path, simu_signal_noisy_events_table_path,\n",
    "        ret_simu_signal=True, ret_under_over_track=True, ret_split_noise=True,\n",
    "        simu_track_class='track', simu_noise_class='noise',\n",
    "        simu_track_underflow_class='track_underflow', simu_track_overflow_class='track_overflow',\n",
    "        simu_noise_underflow_class='noise_underflow', simu_noise_overflow_class='noise_overflow',\n",
    "        simu_events_file_pathname_dir=data_snippets_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Combined label - joining query and labeled simu class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_simu_df['cond_selection_combined'] = 'undefined'\n",
    "\n",
    "for selection_query in ['simu','noise']:\n",
    "    for selection_simu_signal in ['noise','track']:\n",
    "        for simu_signal_sync in ['', 'underflow', 'overflow']:\n",
    "            t_selection_simu_signal = selection_simu_signal\n",
    "            if len(simu_signal_sync) > 0:\n",
    "                t_selection_simu_signal += '_' + simu_signal_sync\n",
    "            combined_simu_df.loc[\n",
    "                (combined_simu_df['cond_selection_query'] == selection_query ) & \n",
    "                (combined_simu_df['cond_selection_simple'] == t_selection_simu_signal), \n",
    "                'cond_selection_combined'] = selection_query + '_' + t_selection_simu_signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Size of the  subsets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Simu signal labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(simu_signal_track_events_df) 14866\n",
      "len(simu_signal_noisy_events_df) 59279\n",
      "--------------------------------------------------\n",
      "len(combined_simu_df)            164400\n",
      "--------------------------------------------------\n",
      "len(unclassified_simu_df)        9288\n",
      "len(track_simu_df)               35038\n",
      "len(track_underflow_simu_df)     5983\n",
      "len(track_overflow_simu_df)      16956\n",
      "len(noise_simu_df)               1608\n",
      "len(noise_underflow_simu_df)     24689\n",
      "len(noise_overflow_simu_df)      70838\n",
      "--------------------------------------------------\n",
      "                                    164400\n",
      "--------------------------------------------------\n",
      "len(track_simu_df)/len(combined_simu_df)        =  0.2131265206812652\n",
      "len(unclassified_simu_df)/len(combined_simu_df) =  0.056496350364963505\n",
      "len(noise_simu_df)/len(combined_simu_df)        =  0.00978102189781022\n"
     ]
    }
   ],
   "source": [
    "print('len(simu_signal_track_events_df)', len(simu_signal_track_events_df))\n",
    "print('len(simu_signal_noisy_events_df)', len(simu_signal_noisy_events_df))\n",
    "print('-'*50)\n",
    "print('len(combined_simu_df)           ', len(combined_simu_df))\n",
    "print('-'*50)\n",
    "print('len(unclassified_simu_df)       ', len(unclassified_simu_df))\n",
    "print('len(track_simu_df)              ', len(track_simu_df))\n",
    "print('len(track_underflow_simu_df)    ', len(track_underflow_simu_df))\n",
    "print('len(track_overflow_simu_df)     ', len(track_overflow_simu_df))\n",
    "print('len(noise_simu_df)              ', len(noise_simu_df))\n",
    "print('len(noise_underflow_simu_df)    ', len(noise_underflow_simu_df))\n",
    "print('len(noise_overflow_simu_df)     ', len(noise_overflow_simu_df))\n",
    "print('-'*50)\n",
    "print('                                   ', \n",
    "      len(unclassified_simu_df) + \\\n",
    "      len(track_simu_df) + len(track_underflow_simu_df) + len(track_overflow_simu_df) + \\\n",
    "      len(noise_simu_df) + len(noise_underflow_simu_df) + len(noise_overflow_simu_df)\n",
    "     )\n",
    "print('-'*50)\n",
    "print('len(track_simu_df)/len(combined_simu_df)        = ', len(track_simu_df)/len(combined_simu_df))\n",
    "print('len(unclassified_simu_df)/len(combined_simu_df) = ', len(unclassified_simu_df)/len(combined_simu_df))\n",
    "print('len(noise_simu_df)/len(combined_simu_df)        = ', len(noise_simu_df)/len(combined_simu_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Selection query and simu signal labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simu - noise                   4\n",
      "simu - noise_underflow         0\n",
      "simu - noise_overflow          0\n",
      "simu - track                   34521\n",
      "simu - track_underflow         0\n",
      "simu - track_overflow          0\n",
      "noise - noise                  1604\n",
      "noise - noise_underflow        24689\n",
      "noise - noise_overflow         70838\n",
      "noise - track                  517\n",
      "noise - track_underflow        5983\n",
      "noise - track_overflow         16956\n"
     ]
    }
   ],
   "source": [
    "for selection_query in ['simu','noise']:\n",
    "    for selection_simu_signal in ['noise','track']:\n",
    "        for simu_signal_sync in ['', 'underflow', 'overflow']:\n",
    "            t_selection_simu_signal = selection_simu_signal\n",
    "            if len(simu_signal_sync) > 0:\n",
    "                t_selection_simu_signal += '_' + simu_signal_sync\n",
    "            print('{:<30} {}'.format(\n",
    "                '{} - {}'.format(selection_query, t_selection_simu_signal),\n",
    "                np.count_nonzero(\n",
    "                    (combined_simu_df['cond_selection_query'] == selection_query ) & \\\n",
    "                    (combined_simu_df['cond_selection_simple'] == t_selection_simu_signal))\n",
    "            ))                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Example of track underflow subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>edetector_numcellhits</th>\n",
       "      <th>edetector_numfee</th>\n",
       "      <th>edetector_numphotons</th>\n",
       "      <th>egeometry_pos_z</th>\n",
       "      <th>eptttrigger_fnumtrigg</th>\n",
       "      <th>etruth_trueenergy</th>\n",
       "      <th>etruth_truephi</th>\n",
       "      <th>etruth_trueshowermaxpos_x</th>\n",
       "      <th>etruth_trueshowermaxpos_y</th>\n",
       "      <th>etruth_trueshowermaxpos_z</th>\n",
       "      <th>...</th>\n",
       "      <th>source_file_trigger</th>\n",
       "      <th>source_file_trigger_full</th>\n",
       "      <th>trg_gtu_x_hough_peak_thr1_major_line_phi</th>\n",
       "      <th>trg_gtu_y_hough_peak_thr1_major_line_phi</th>\n",
       "      <th>trg_x_y_hough_peak_thr1_major_line_phi</th>\n",
       "      <th>calc_etruth_trueshower_rmax</th>\n",
       "      <th>cond_selection_query</th>\n",
       "      <th>simu2npy_signals_pathname</th>\n",
       "      <th>simu2npy_signals_pathname_short</th>\n",
       "      <th>cond_selection_simple</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45187</th>\n",
       "      <td>0</td>\n",
       "      <td>27651</td>\n",
       "      <td>9512</td>\n",
       "      <td>21000000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.412540e+12</td>\n",
       "      <td>5.167210</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>posz_21000000.00/energy_1.41e+12/thousnd21E3.2...</td>\n",
       "      <td>/home/spbproc/SPBDATA_processed/spb_simu/posz_...</td>\n",
       "      <td>2.087140</td>\n",
       "      <td>0.182200</td>\n",
       "      <td>0.162611</td>\n",
       "      <td>NaN</td>\n",
       "      <td>noise</td>\n",
       "      <td>/mnt/data_sgbc1/SPBDATA_processed/spb_simu/pos...</td>\n",
       "      <td>posz_21000000.00/energy_1.41e+12/thousnd21E3.2...</td>\n",
       "      <td>track_underflow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25116</th>\n",
       "      <td>0</td>\n",
       "      <td>39476</td>\n",
       "      <td>100445</td>\n",
       "      <td>24000000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.950000e+12</td>\n",
       "      <td>0.066001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>posz_24000000.00/energy_5.95e+12/simu.2017-07-...</td>\n",
       "      <td>/home/spbproc/SPBDATA_processed/spb_simu/posz_...</td>\n",
       "      <td>0.014447</td>\n",
       "      <td>2.365370</td>\n",
       "      <td>1.556460</td>\n",
       "      <td>NaN</td>\n",
       "      <td>noise</td>\n",
       "      <td>/mnt/data_sgbc1/SPBDATA_processed/spb_simu/pos...</td>\n",
       "      <td>posz_24000000.00/energy_5.95e+12/simu.2017-07-...</td>\n",
       "      <td>track_underflow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21799</th>\n",
       "      <td>0</td>\n",
       "      <td>38729</td>\n",
       "      <td>60454</td>\n",
       "      <td>24000000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.950000e+12</td>\n",
       "      <td>4.709430</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>posz_24000000.00/energy_5.95e+12/simu.2017-07-...</td>\n",
       "      <td>/home/spbproc/SPBDATA_processed/spb_simu/posz_...</td>\n",
       "      <td>6.273740</td>\n",
       "      <td>6.270100</td>\n",
       "      <td>0.747655</td>\n",
       "      <td>NaN</td>\n",
       "      <td>noise</td>\n",
       "      <td>/mnt/data_sgbc1/SPBDATA_processed/spb_simu/pos...</td>\n",
       "      <td>posz_24000000.00/energy_5.95e+12/simu.2017-07-...</td>\n",
       "      <td>track_underflow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3711</th>\n",
       "      <td>0</td>\n",
       "      <td>25774</td>\n",
       "      <td>7124</td>\n",
       "      <td>27000000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.258930e+12</td>\n",
       "      <td>2.466220</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>posz_27000000.00/energy_1.26e+12/thousnd27E2/l...</td>\n",
       "      <td>/home/spbproc/SPBDATA_processed/spb_simu/posz_...</td>\n",
       "      <td>6.277200</td>\n",
       "      <td>6.199100</td>\n",
       "      <td>0.001819</td>\n",
       "      <td>NaN</td>\n",
       "      <td>noise</td>\n",
       "      <td>/mnt/data_sgbc1/SPBDATA_processed/spb_simu/pos...</td>\n",
       "      <td>posz_27000000.00/energy_1.26e+12/thousnd27E2/s...</td>\n",
       "      <td>track_underflow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93171</th>\n",
       "      <td>0</td>\n",
       "      <td>20371</td>\n",
       "      <td>42824</td>\n",
       "      <td>18000000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.250000e+12</td>\n",
       "      <td>3.613280</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>posz_18000000.00/energy_5.25e+12/simu.2017-07-...</td>\n",
       "      <td>/home/spbproc/SPBDATA_processed/spb_simu/posz_...</td>\n",
       "      <td>0.384665</td>\n",
       "      <td>0.477307</td>\n",
       "      <td>6.112560</td>\n",
       "      <td>NaN</td>\n",
       "      <td>noise</td>\n",
       "      <td>/mnt/data_sgbc1/SPBDATA_processed/spb_simu/pos...</td>\n",
       "      <td>posz_18000000.00/energy_5.25e+12/simu.2017-07-...</td>\n",
       "      <td>track_underflow</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       edetector_numcellhits  edetector_numfee  edetector_numphotons  \\\n",
       "45187                      0             27651                  9512   \n",
       "25116                      0             39476                100445   \n",
       "21799                      0             38729                 60454   \n",
       "3711                       0             25774                  7124   \n",
       "93171                      0             20371                 42824   \n",
       "\n",
       "       egeometry_pos_z  eptttrigger_fnumtrigg  etruth_trueenergy  \\\n",
       "45187       21000000.0                      1       1.412540e+12   \n",
       "25116       24000000.0                      1       5.950000e+12   \n",
       "21799       24000000.0                      0       5.950000e+12   \n",
       "3711        27000000.0                      0       1.258930e+12   \n",
       "93171       18000000.0                      1       5.250000e+12   \n",
       "\n",
       "       etruth_truephi  etruth_trueshowermaxpos_x  etruth_trueshowermaxpos_y  \\\n",
       "45187        5.167210                        NaN                        NaN   \n",
       "25116        0.066001                        NaN                        NaN   \n",
       "21799        4.709430                        NaN                        NaN   \n",
       "3711         2.466220                        NaN                        NaN   \n",
       "93171        3.613280                        NaN                        NaN   \n",
       "\n",
       "       etruth_trueshowermaxpos_z          ...            \\\n",
       "45187                        NaN          ...             \n",
       "25116                        NaN          ...             \n",
       "21799                        NaN          ...             \n",
       "3711                         NaN          ...             \n",
       "93171                        NaN          ...             \n",
       "\n",
       "                                     source_file_trigger  \\\n",
       "45187  posz_21000000.00/energy_1.41e+12/thousnd21E3.2...   \n",
       "25116  posz_24000000.00/energy_5.95e+12/simu.2017-07-...   \n",
       "21799  posz_24000000.00/energy_5.95e+12/simu.2017-07-...   \n",
       "3711   posz_27000000.00/energy_1.26e+12/thousnd27E2/l...   \n",
       "93171  posz_18000000.00/energy_5.25e+12/simu.2017-07-...   \n",
       "\n",
       "                                source_file_trigger_full  \\\n",
       "45187  /home/spbproc/SPBDATA_processed/spb_simu/posz_...   \n",
       "25116  /home/spbproc/SPBDATA_processed/spb_simu/posz_...   \n",
       "21799  /home/spbproc/SPBDATA_processed/spb_simu/posz_...   \n",
       "3711   /home/spbproc/SPBDATA_processed/spb_simu/posz_...   \n",
       "93171  /home/spbproc/SPBDATA_processed/spb_simu/posz_...   \n",
       "\n",
       "       trg_gtu_x_hough_peak_thr1_major_line_phi  \\\n",
       "45187                                  2.087140   \n",
       "25116                                  0.014447   \n",
       "21799                                  6.273740   \n",
       "3711                                   6.277200   \n",
       "93171                                  0.384665   \n",
       "\n",
       "       trg_gtu_y_hough_peak_thr1_major_line_phi  \\\n",
       "45187                                  0.182200   \n",
       "25116                                  2.365370   \n",
       "21799                                  6.270100   \n",
       "3711                                   6.199100   \n",
       "93171                                  0.477307   \n",
       "\n",
       "       trg_x_y_hough_peak_thr1_major_line_phi  calc_etruth_trueshower_rmax  \\\n",
       "45187                                0.162611                          NaN   \n",
       "25116                                1.556460                          NaN   \n",
       "21799                                0.747655                          NaN   \n",
       "3711                                 0.001819                          NaN   \n",
       "93171                                6.112560                          NaN   \n",
       "\n",
       "       cond_selection_query  \\\n",
       "45187                 noise   \n",
       "25116                 noise   \n",
       "21799                 noise   \n",
       "3711                  noise   \n",
       "93171                 noise   \n",
       "\n",
       "                               simu2npy_signals_pathname  \\\n",
       "45187  /mnt/data_sgbc1/SPBDATA_processed/spb_simu/pos...   \n",
       "25116  /mnt/data_sgbc1/SPBDATA_processed/spb_simu/pos...   \n",
       "21799  /mnt/data_sgbc1/SPBDATA_processed/spb_simu/pos...   \n",
       "3711   /mnt/data_sgbc1/SPBDATA_processed/spb_simu/pos...   \n",
       "93171  /mnt/data_sgbc1/SPBDATA_processed/spb_simu/pos...   \n",
       "\n",
       "                         simu2npy_signals_pathname_short  \\\n",
       "45187  posz_21000000.00/energy_1.41e+12/thousnd21E3.2...   \n",
       "25116  posz_24000000.00/energy_5.95e+12/simu.2017-07-...   \n",
       "21799  posz_24000000.00/energy_5.95e+12/simu.2017-07-...   \n",
       "3711   posz_27000000.00/energy_1.26e+12/thousnd27E2/s...   \n",
       "93171  posz_18000000.00/energy_5.25e+12/simu.2017-07-...   \n",
       "\n",
       "       cond_selection_simple  \n",
       "45187        track_underflow  \n",
       "25116        track_underflow  \n",
       "21799        track_underflow  \n",
       "3711         track_underflow  \n",
       "93171        track_underflow  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "track_underflow_simu_df.sort_values('gtu_in_packet', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Example of track overflow subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>edetector_numcellhits</th>\n",
       "      <th>edetector_numfee</th>\n",
       "      <th>edetector_numphotons</th>\n",
       "      <th>egeometry_pos_z</th>\n",
       "      <th>eptttrigger_fnumtrigg</th>\n",
       "      <th>etruth_trueenergy</th>\n",
       "      <th>etruth_truephi</th>\n",
       "      <th>etruth_trueshowermaxpos_x</th>\n",
       "      <th>etruth_trueshowermaxpos_y</th>\n",
       "      <th>etruth_trueshowermaxpos_z</th>\n",
       "      <th>...</th>\n",
       "      <th>source_file_trigger</th>\n",
       "      <th>source_file_trigger_full</th>\n",
       "      <th>trg_gtu_x_hough_peak_thr1_major_line_phi</th>\n",
       "      <th>trg_gtu_y_hough_peak_thr1_major_line_phi</th>\n",
       "      <th>trg_x_y_hough_peak_thr1_major_line_phi</th>\n",
       "      <th>calc_etruth_trueshower_rmax</th>\n",
       "      <th>cond_selection_query</th>\n",
       "      <th>simu2npy_signals_pathname</th>\n",
       "      <th>simu2npy_signals_pathname_short</th>\n",
       "      <th>cond_selection_simple</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>53058</th>\n",
       "      <td>0</td>\n",
       "      <td>21225</td>\n",
       "      <td>13409</td>\n",
       "      <td>30000000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.995260e+12</td>\n",
       "      <td>6.275790</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>posz_30000000.00/energy_2.00e+12/thousnd30E6.2...</td>\n",
       "      <td>/home/spbproc/SPBDATA_processed/spb_simu/posz_...</td>\n",
       "      <td>1.470330</td>\n",
       "      <td>1.51624</td>\n",
       "      <td>0.060410</td>\n",
       "      <td>NaN</td>\n",
       "      <td>noise</td>\n",
       "      <td>/mnt/data_sgbc1/SPBDATA_processed/spb_simu/pos...</td>\n",
       "      <td>posz_30000000.00/energy_2.00e+12/thousnd30E6.2...</td>\n",
       "      <td>track_overflow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58199</th>\n",
       "      <td>0</td>\n",
       "      <td>29155</td>\n",
       "      <td>11260</td>\n",
       "      <td>30000000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.584890e+12</td>\n",
       "      <td>1.471500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>posz_30000000.00/energy_1.58e+12/thousnd30E4.2...</td>\n",
       "      <td>/home/spbproc/SPBDATA_processed/spb_simu/posz_...</td>\n",
       "      <td>0.700929</td>\n",
       "      <td>1.48516</td>\n",
       "      <td>6.257140</td>\n",
       "      <td>NaN</td>\n",
       "      <td>noise</td>\n",
       "      <td>/mnt/data_sgbc1/SPBDATA_processed/spb_simu/pos...</td>\n",
       "      <td>posz_30000000.00/energy_1.58e+12/thousnd30E4.2...</td>\n",
       "      <td>track_overflow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58697</th>\n",
       "      <td>0</td>\n",
       "      <td>25726</td>\n",
       "      <td>9003</td>\n",
       "      <td>30000000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.584890e+12</td>\n",
       "      <td>0.401451</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>posz_30000000.00/energy_1.58e+12/thousnd30E4.2...</td>\n",
       "      <td>/home/spbproc/SPBDATA_processed/spb_simu/posz_...</td>\n",
       "      <td>0.010381</td>\n",
       "      <td>6.17482</td>\n",
       "      <td>0.116087</td>\n",
       "      <td>NaN</td>\n",
       "      <td>noise</td>\n",
       "      <td>/mnt/data_sgbc1/SPBDATA_processed/spb_simu/pos...</td>\n",
       "      <td>posz_30000000.00/energy_1.58e+12/thousnd30E4.2...</td>\n",
       "      <td>track_overflow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59486</th>\n",
       "      <td>0</td>\n",
       "      <td>21687</td>\n",
       "      <td>151669</td>\n",
       "      <td>21000000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.940000e+12</td>\n",
       "      <td>1.387970</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>posz_21000000.00/energy_3.94e+12/ter212.2017-0...</td>\n",
       "      <td>/home/spbproc/SPBDATA_processed/spb_simu/posz_...</td>\n",
       "      <td>0.753375</td>\n",
       "      <td>0.77655</td>\n",
       "      <td>0.770847</td>\n",
       "      <td>NaN</td>\n",
       "      <td>noise</td>\n",
       "      <td>/mnt/data_sgbc1/SPBDATA_processed/spb_simu/pos...</td>\n",
       "      <td>posz_21000000.00/energy_3.94e+12/ter212.2017-0...</td>\n",
       "      <td>track_overflow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110238</th>\n",
       "      <td>0</td>\n",
       "      <td>30181</td>\n",
       "      <td>146123</td>\n",
       "      <td>18000000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>8.500000e+12</td>\n",
       "      <td>5.381020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>posz_18000000.00/energy_8.50e+12/set18.2017-07...</td>\n",
       "      <td>/home/spbproc/SPBDATA_processed/spb_simu/posz_...</td>\n",
       "      <td>0.010381</td>\n",
       "      <td>6.17482</td>\n",
       "      <td>0.116087</td>\n",
       "      <td>NaN</td>\n",
       "      <td>noise</td>\n",
       "      <td>/mnt/data_sgbc1/SPBDATA_processed/spb_simu/pos...</td>\n",
       "      <td>posz_18000000.00/energy_8.50e+12/set18.2017-07...</td>\n",
       "      <td>track_overflow</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        edetector_numcellhits  edetector_numfee  edetector_numphotons  \\\n",
       "53058                       0             21225                 13409   \n",
       "58199                       0             29155                 11260   \n",
       "58697                       0             25726                  9003   \n",
       "59486                       0             21687                151669   \n",
       "110238                      0             30181                146123   \n",
       "\n",
       "        egeometry_pos_z  eptttrigger_fnumtrigg  etruth_trueenergy  \\\n",
       "53058        30000000.0                      0       1.995260e+12   \n",
       "58199        30000000.0                      0       1.584890e+12   \n",
       "58697        30000000.0                      0       1.584890e+12   \n",
       "59486        21000000.0                      1       3.940000e+12   \n",
       "110238       18000000.0                      1       8.500000e+12   \n",
       "\n",
       "        etruth_truephi  etruth_trueshowermaxpos_x  etruth_trueshowermaxpos_y  \\\n",
       "53058         6.275790                        NaN                        NaN   \n",
       "58199         1.471500                        NaN                        NaN   \n",
       "58697         0.401451                        NaN                        NaN   \n",
       "59486         1.387970                        NaN                        NaN   \n",
       "110238        5.381020                        NaN                        NaN   \n",
       "\n",
       "        etruth_trueshowermaxpos_z          ...            \\\n",
       "53058                         NaN          ...             \n",
       "58199                         NaN          ...             \n",
       "58697                         NaN          ...             \n",
       "59486                         NaN          ...             \n",
       "110238                        NaN          ...             \n",
       "\n",
       "                                      source_file_trigger  \\\n",
       "53058   posz_30000000.00/energy_2.00e+12/thousnd30E6.2...   \n",
       "58199   posz_30000000.00/energy_1.58e+12/thousnd30E4.2...   \n",
       "58697   posz_30000000.00/energy_1.58e+12/thousnd30E4.2...   \n",
       "59486   posz_21000000.00/energy_3.94e+12/ter212.2017-0...   \n",
       "110238  posz_18000000.00/energy_8.50e+12/set18.2017-07...   \n",
       "\n",
       "                                 source_file_trigger_full  \\\n",
       "53058   /home/spbproc/SPBDATA_processed/spb_simu/posz_...   \n",
       "58199   /home/spbproc/SPBDATA_processed/spb_simu/posz_...   \n",
       "58697   /home/spbproc/SPBDATA_processed/spb_simu/posz_...   \n",
       "59486   /home/spbproc/SPBDATA_processed/spb_simu/posz_...   \n",
       "110238  /home/spbproc/SPBDATA_processed/spb_simu/posz_...   \n",
       "\n",
       "        trg_gtu_x_hough_peak_thr1_major_line_phi  \\\n",
       "53058                                   1.470330   \n",
       "58199                                   0.700929   \n",
       "58697                                   0.010381   \n",
       "59486                                   0.753375   \n",
       "110238                                  0.010381   \n",
       "\n",
       "        trg_gtu_y_hough_peak_thr1_major_line_phi  \\\n",
       "53058                                    1.51624   \n",
       "58199                                    1.48516   \n",
       "58697                                    6.17482   \n",
       "59486                                    0.77655   \n",
       "110238                                   6.17482   \n",
       "\n",
       "        trg_x_y_hough_peak_thr1_major_line_phi  calc_etruth_trueshower_rmax  \\\n",
       "53058                                 0.060410                          NaN   \n",
       "58199                                 6.257140                          NaN   \n",
       "58697                                 0.116087                          NaN   \n",
       "59486                                 0.770847                          NaN   \n",
       "110238                                0.116087                          NaN   \n",
       "\n",
       "        cond_selection_query  \\\n",
       "53058                  noise   \n",
       "58199                  noise   \n",
       "58697                  noise   \n",
       "59486                  noise   \n",
       "110238                 noise   \n",
       "\n",
       "                                simu2npy_signals_pathname  \\\n",
       "53058   /mnt/data_sgbc1/SPBDATA_processed/spb_simu/pos...   \n",
       "58199   /mnt/data_sgbc1/SPBDATA_processed/spb_simu/pos...   \n",
       "58697   /mnt/data_sgbc1/SPBDATA_processed/spb_simu/pos...   \n",
       "59486   /mnt/data_sgbc1/SPBDATA_processed/spb_simu/pos...   \n",
       "110238  /mnt/data_sgbc1/SPBDATA_processed/spb_simu/pos...   \n",
       "\n",
       "                          simu2npy_signals_pathname_short  \\\n",
       "53058   posz_30000000.00/energy_2.00e+12/thousnd30E6.2...   \n",
       "58199   posz_30000000.00/energy_1.58e+12/thousnd30E4.2...   \n",
       "58697   posz_30000000.00/energy_1.58e+12/thousnd30E4.2...   \n",
       "59486   posz_21000000.00/energy_3.94e+12/ter212.2017-0...   \n",
       "110238  posz_18000000.00/energy_8.50e+12/set18.2017-07...   \n",
       "\n",
       "        cond_selection_simple  \n",
       "53058          track_overflow  \n",
       "58199          track_overflow  \n",
       "58697          track_overflow  \n",
       "59486          track_overflow  \n",
       "110238         track_overflow  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "track_overflow_simu_df.sort_values('gtu_in_packet', ascending=True).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Visualization of a few events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Noise entries are sorted by number of simu signal pixles in x-y projection in descending order (`orig_x_y_count_nonzero`, sorted from the most potentially track-like),\n",
    "- Track entries are sorted by num frames where maximum signal is greater equal maximum background in acsending order (`num_frames_signals_ge_bg`, from the least visible track events). Non-track-like simu signal might not be necessarly incorrectly labeled entries, just a small portion of a track in signal.\n",
    "- Track underflow, track overflow should all contain empty simu signal data. Entries are sorted by GTU in packet in ascending or descending order, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "noise (1608 entries)\n",
      "--------------------------------------------------\n",
      "#0\t(0)\n",
      "\tevent_id: 2261798\n",
      "\tpacket_id: 1\n",
      "\tgtu_in_packet: 17\n",
      "\tnum_gtu: 23\n",
      "\tnum_frames_signals_ge_bg: 0.0\n",
      "\tsimu2npy_signals_pathname_short: posz_30000000.00/energy_6.31e+12/thousnd30E16.2017-07-25-13h05m21s/simu2npy/ev_34_mc_1__signals.npy\n",
      "\tcond_selection_query: noise\n",
      "\tcond_selection_simple: noise\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#1\t(0)\n",
      "\tevent_id: 2020798\n",
      "\tpacket_id: 1\n",
      "\tgtu_in_packet: 17\n",
      "\tnum_gtu: 23\n",
      "\tnum_frames_signals_ge_bg: 0.0\n",
      "\tsimu2npy_signals_pathname_short: posz_18000000.00/energy_5.62e+12/thousnd18E15.2017-07-28-11h19m08s/simu2npy/ev_77_mc_1__signals.npy\n",
      "\tcond_selection_query: noise\n",
      "\tcond_selection_simple: noise\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#2\t(0)\n",
      "\tevent_id: 2452180\n",
      "\tpacket_id: 1\n",
      "\tgtu_in_packet: 21\n",
      "\tnum_gtu: 20\n",
      "\tnum_frames_signals_ge_bg: 0.0\n",
      "\tsimu2npy_signals_pathname_short: posz_18000000.00/energy_7.15e+12/simu.2017-07-24-06h44m34s/simu2npy/ev_50_mc_1__signals.npy\n",
      "\tcond_selection_query: noise\n",
      "\tcond_selection_simple: noise\n",
      "==================================================\n",
      "track (35038 entries)\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#0\t(0)\n",
      "\tevent_id: 2626269\n",
      "\tpacket_id: 1\n",
      "\tgtu_in_packet: 67\n",
      "\tnum_gtu: 10\n",
      "\tnum_frames_signals_ge_bg: 0.0\n",
      "\tsimu2npy_signals_pathname_short: posz_33000000.00/energy_8.91e+12/thousnd33E19/simu2npy/ev_97_mc_1__signals.npy\n",
      "\tcond_selection_query: noise\n",
      "\tcond_selection_simple: track\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#1\t(0)\n",
      "\tevent_id: 2118783\n",
      "\tpacket_id: 1\n",
      "\tgtu_in_packet: 65\n",
      "\tnum_gtu: 12\n",
      "\tnum_frames_signals_ge_bg: 0.0\n",
      "\tsimu2npy_signals_pathname_short: posz_30000000.00/energy_1.58e+12/thousnd30E4/simu2npy/ev_98_mc_1__signals.npy\n",
      "\tcond_selection_query: noise\n",
      "\tcond_selection_simple: track\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#2\t(0)\n",
      "\tevent_id: 2119602\n",
      "\tpacket_id: 1\n",
      "\tgtu_in_packet: 64\n",
      "\tnum_gtu: 16\n",
      "\tnum_frames_signals_ge_bg: 0.0\n",
      "\tsimu2npy_signals_pathname_short: posz_21000000.00/energy_1.58e+12/thousnd21E4.2017-07-26-21h24m15s/simu2npy/ev_20_mc_1__signals.npy\n",
      "\tcond_selection_query: noise\n",
      "\tcond_selection_simple: track\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "track_underflow (5983 entries)\n",
      "--------------------------------------------------\n",
      "#0\t(0)\n",
      "\tevent_id: 2109098\n",
      "\tpacket_id: 1\n",
      "\tgtu_in_packet: 22\n",
      "\tnum_gtu: 11\n",
      "\tnum_frames_signals_ge_bg: nan\n",
      "\tsimu2npy_signals_pathname_short: posz_21000000.00/energy_1.41e+12/thousnd21E3.2017-07-26-20h13m39s/simu2npy/ev_79_mc_1__signals.npy\n",
      "\tcond_selection_query: noise\n",
      "\tcond_selection_simple: track_underflow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#1\t(0)\n",
      "\tevent_id: 189885\n",
      "\tpacket_id: 1\n",
      "\tgtu_in_packet: 22\n",
      "\tnum_gtu: 10\n",
      "\tnum_frames_signals_ge_bg: nan\n",
      "\tsimu2npy_signals_pathname_short: posz_24000000.00/energy_5.95e+12/simu.2017-07-20-20h00m16s/simu2npy/ev_16_mc_1__signals.npy\n",
      "\tcond_selection_query: noise\n",
      "\tcond_selection_simple: track_underflow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#2\t(0)\n",
      "\tevent_id: 154316\n",
      "\tpacket_id: 1\n",
      "\tgtu_in_packet: 22\n",
      "\tnum_gtu: 9\n",
      "\tnum_frames_signals_ge_bg: nan\n",
      "\tsimu2npy_signals_pathname_short: posz_24000000.00/energy_5.95e+12/simu.2017-07-21-05h30m38s/simu2npy/ev_59_mc_1__signals.npy\n",
      "\tcond_selection_query: noise\n",
      "\tcond_selection_simple: track_underflow\n",
      "==================================================\n",
      "track_overflow (16956 entries)\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:949: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, axs = plt.subplots(1, int(vis_xy) + int(vis_gtux) + int(vis_gtuy))\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#0\t(0)\n",
      "\tevent_id: 2156392\n",
      "\tpacket_id: 1\n",
      "\tgtu_in_packet: 62\n",
      "\tnum_gtu: 20\n",
      "\tnum_frames_signals_ge_bg: nan\n",
      "\tsimu2npy_signals_pathname_short: posz_30000000.00/energy_2.00e+12/thousnd30E6.2017-07-24-22h56m23s/simu2npy/ev_61_mc_1__signals.npy\n",
      "\tcond_selection_query: noise\n",
      "\tcond_selection_simple: track_overflow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:205: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, axs = plt.subplots(t_subplot_rows, t_subplot_cols)\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#1\t(0)\n",
      "\tevent_id: 2189735\n",
      "\tpacket_id: 1\n",
      "\tgtu_in_packet: 62\n",
      "\tnum_gtu: 10\n",
      "\tnum_frames_signals_ge_bg: nan\n",
      "\tsimu2npy_signals_pathname_short: posz_30000000.00/energy_1.58e+12/thousnd30E4.2017-07-24-21h02m30s/simu2npy/ev_62_mc_1__signals.npy\n",
      "\tcond_selection_query: noise\n",
      "\tcond_selection_simple: track_overflow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#2\t(0)\n",
      "\tevent_id: 2192502\n",
      "\tpacket_id: 1\n",
      "\tgtu_in_packet: 62\n",
      "\tnum_gtu: 14\n",
      "\tnum_frames_signals_ge_bg: nan\n",
      "\tsimu2npy_signals_pathname_short: posz_30000000.00/energy_1.58e+12/thousnd30E4.2017-07-24-21h10m14s/simu2npy/ev_47_mc_1__signals.npy\n",
      "\tcond_selection_query: noise\n",
      "\tcond_selection_simple: track_overflow\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/home/spbproc/euso-spb-patt-reco-v1/data_analysis_utils.py:251: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "def vis_simu_signal_default(i, r, visualized_projections, fig, axs_flattened): \n",
    "    show_simu_event_row(i, r, \n",
    "        npy_pathname_column='simu2npy_signals_pathname', \n",
    "        single_proj_width=4, single_proj_height=4,\n",
    "        print_info=False, warn_if_not_exact_simu=False)\n",
    "\n",
    "def vis_simu_signal_with_original(i, r, visualized_projections, fig, axs_flattened):\n",
    "    vis_simu_signal_default(i, r, visualized_projections, fig, axs_flattened)\n",
    "    show_simu_event_row(i, r, \n",
    "        npy_pathname_column='simu2npy_signals_pathname', \n",
    "        single_proj_width=4, single_proj_height=4,\n",
    "        print_info=False, warn_if_not_exact_simu=False,\n",
    "        simu_gtu_override=(30,50))\n",
    "\n",
    "for label, events_to_vis_df in [\n",
    "        ('noise', noise_simu_df.sort_values('orig_x_y_count_nonzero', ascending=False)), \n",
    "        ('track', track_simu_df.sort_values('num_frames_signals_ge_bg', ascending=True)), \n",
    "        ('track_underflow', track_underflow_simu_df.sort_values('gtu_in_packet', ascending=False)), \n",
    "        ('track_overflow', track_overflow_simu_df.sort_values('gtu_in_packet', ascending=True))\n",
    "]:\n",
    "    print('{} ({} entries)'.format(label, len(events_to_vis_df)))\n",
    "    print('-' * 50)\n",
    "    vis_events_df(\n",
    "        events_to_vis_df, \n",
    "        events_per_figure=3, max_figures=1, vis_gtux=True, vis_gtuy=True, \n",
    "        close_after_vis=False, show=True, \n",
    "        additional_printed_columns=[\n",
    "            'num_frames_signals_ge_bg', 'simu2npy_signals_pathname_short', \n",
    "            'cond_selection_query', 'cond_selection_simple'],\n",
    "        by_one=True,\n",
    "        extension_func=vis_simu_signal_with_original if label == 'track' else vis_simu_signal_default,\n",
    "        single_proj_width=4, single_proj_height=4\n",
    "    )\n",
    "    print('=' * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of NaN entries\n",
    "Events with NaN values in are currently rejected from showers dataset. \n",
    "However, final decision about rejection is made considering only columns using in ML algorithm.\n",
    "Therefore, these numbers are not exactly indicative of the the final number of rejected events - only simu_track and noise_track should be indicative. (TODO requires check)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of NaN entries by query and simu signal labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               NaN        Others\n",
      "simu - noise                   2          2\n",
      "simu - noise_underflow         0          0\n",
      "simu - noise_overflow          0          0\n",
      "simu - track                   2699       31822\n",
      "simu - track_underflow         0          0\n",
      "simu - track_overflow          0          0\n",
      "noise - noise                  1604       0\n",
      "noise - noise_underflow        24689      0\n",
      "noise - noise_overflow         70838      0\n",
      "noise - track                  517        0\n",
      "noise - track_underflow        5983       0\n",
      "noise - track_overflow         16956      0\n"
     ]
    }
   ],
   "source": [
    "print('{:<30} {:<10} {}'.format(' ', 'NaN', 'Others'))\n",
    "for selection_query in ['simu','noise']:\n",
    "    for selection_simu_signal in ['noise','track']:\n",
    "        for simu_signal_sync in ['', 'underflow', 'overflow']:\n",
    "            t_selection_simu_signal = selection_simu_signal\n",
    "            if len(simu_signal_sync) > 0:\n",
    "                t_selection_simu_signal += '_' + simu_signal_sync\n",
    "            subset_df = combined_simu_df[\n",
    "                (combined_simu_df['cond_selection_query'] == selection_query ) & \n",
    "                (combined_simu_df['cond_selection_simple'] == t_selection_simu_signal)\n",
    "            ]\n",
    "            nan_row_count = np.count_nonzero(subset_df.isnull().any(axis=1))\n",
    "            print('{:<30} {:<10} {}'.format(\n",
    "                '{} - {}'.format(selection_query, t_selection_simu_signal),\n",
    "                nan_row_count, len(subset_df) - nan_row_count\n",
    "            ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flight data were already selected excluding entries with NaN values (actually NULL in PostgreSQL table)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unl_noise_flight_df                               : 43408\n",
      "lbl_noise_flight_df                               : 543\n",
      "unl_flight_df                                     : 0\n"
     ]
    }
   ],
   "source": [
    "for subset_label, subset_df in flight_df_dict.items():\n",
    "    print('{:50}: {:d}'.format(subset_label, np.count_nonzero(subset_df.isnull().any(axis=1))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NaN columns\n",
    "Columns with a NaN value are either data from Hough transform on projections of triggered pixels - issue is a single pixel in a projection, thus it is impossible to determine orientation of a line. This impacts usable size of the dataset.\n",
    "Other source of NaN values are additional information calculated for simulated shower - it is number of frames where number of signal pixels satisfies certain condition. The NaN value is present when there are no signal present in an identified event."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trg_gtu_y_hough_peak_thr1_major_line_phi                                                                                 : 2207\n",
      "trg_gtu_x_hough_peak_thr1_major_line_phi                                                                                 : 2209\n",
      "trg_x_y_hough_peak_thr1_major_line_phi                                                                                   : 1776\n",
      "etruth_trueshowermaxpos_x                                                                                                : 128793\n",
      "etruth_trueshowermaxpos_y                                                                                                : 128793\n",
      "etruth_trueshowermaxpos_z                                                                                                : 128793\n",
      "num_frames_counts_gt_bg                                                                                                  : 123329\n",
      "num_frames_signals_ge_bg                                                                                                 : 123329\n",
      "num_frames_signals_gt_bg                                                                                                 : 123329\n",
      "calc_etruth_trueshower_rmax                                                                                              : 128793\n"
     ]
    }
   ],
   "source": [
    "nan_columns = {}\n",
    "\n",
    "for i, r in combined_simu_df[combined_simu_df.isnull().any(axis=1)].iterrows():\n",
    "    for col, val in r.iteritems():\n",
    "        if isinstance(val, numbers_Number) and math.isnan(val):\n",
    "            if col not in nan_columns:\n",
    "                nan_columns[col] = 0\n",
    "            nan_columns[col] += 1\n",
    "\n",
    "for col, val in nan_columns.items():\n",
    "    print(\"{:<120} : {:<d}\".format(col, val))\n",
    "\n",
    "# del nan_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Free memory\n",
    "(not in the report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'unclassified_simu_df' in locals(): del unclassified_simu_df\n",
    "if 'track_simu_df' in locals(): del track_simu_df\n",
    "if 'noisy_simu_df' in locals(): del noisy_simu_df\n",
    "if 'simu_signal_track_events_df' in locals(): del simu_signal_track_events_df\n",
    "if 'simu_signal_noisy_events_df' in locals(): del simu_signal_noisy_events_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unclassified_simu_df, \\\n",
    "# track_simu_df, track_underflow_simu_df, track_overflow_simu_df, \\\n",
    "# noise_simu_df, noise_underflow_simu_df, noise_overflow_simu_df, \\\n",
    "# simu_signal_track_events_df, simu_signal_noisy_events_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation of the testing and training datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selected datasets are used in training and testing of a machine learning algorithm. \n",
    "Because of different inital number of noise and shower events, sizes of the datasets need to be balanced. This is done by decreasing a size of a smaller dataset.\n",
    "\n",
    "Another potential solution would be to change class weights in the configuration of a machine learning algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column names\n",
    "(not in the report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_condenser_df_columns = list(common_df_columns)\n",
    "for col in [  \n",
    "#         'event_id',\n",
    "#         'source_file_acquisition_full',\n",
    "        'source_file_trigger_full',\n",
    "        'source_file_acquisition',\n",
    "        'source_file_trigger',\n",
    "        'global_gtu',\n",
    "#         'packet_id',\n",
    "#         'gtu_in_packet',\n",
    "        'orig_x_y_count_nonzero',\n",
    "        'bg_x_y_count_nonzero',\n",
    "        'bg_count_nonzero',\n",
    "        'orig_count_nonzero',\n",
    "        'bg_size'\n",
    "\n",
    "]:\n",
    "    if col in dataset_condenser_df_columns:\n",
    "        dataset_condenser_df_columns.remove(col)\n",
    "\n",
    "# IMPORTANT - NaN columns excluded from the analysis\n",
    "    \n",
    "for col in nan_columns.keys():\n",
    "    if col in dataset_condenser_df_columns:\n",
    "        dataset_condenser_df_columns.remove(col)\n",
    "    \n",
    "simu_class_column = 'cond_selection_combined'\n",
    "flight_class_column = classification_df_cls_column_name\n",
    "    \n",
    "dataset_condenser_df_columns_w_event_id = list(dataset_condenser_df_columns)\n",
    "if 'event_id' not in dataset_condenser_df_columns:\n",
    "    dataset_condenser_df_columns_w_event_id.append('event_id')\n",
    "dataset_condenser_df_columns_w_event_id_simu_class = list(dataset_condenser_df_columns_w_event_id) + [simu_class_column]\n",
    "dataset_condenser_df_columns_w_event_id_flight_class = list(dataset_condenser_df_columns_w_event_id) + [flight_class_column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['event_id',\n",
       " 'source_file_acquisition_full',\n",
       " 'packet_id',\n",
       " 'gtu_in_packet',\n",
       " 'num_gtu']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_condenser_df_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Showers dataset\n",
    "Showers dataset consists of processed simulated showers that belong to the **\"simu track\"** class and potentially flight events classified as an air shower.\n",
    "\n",
    "Another potential source in the future might consist set of laser shots from Utah tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_simu_track(df):\n",
    "    return df.query('cond_selection_combined == \"simu_track\"')\n",
    "\n",
    "def query_event_class_shower(df):\n",
    "    return df.query(\n",
    "        '{classification_df_cls_column_name} == {event_class_shower}'.format(\n",
    "            classification_df_cls_column_name=classification_df_cls_column_name,\n",
    "            event_class_shower=EVENT_CLASSES['shower']\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "# this function is pointeless\n",
    "# _flight_class\n",
    "def get_labeled_shower(columns=dataset_condenser_df_columns_w_event_id):\n",
    "    #  unsuitable name of the dict item\n",
    "    #  expected to be empty\n",
    "    return query_event_class_shower(flight_df_dict['lbl_noise_flight_df']) \\\n",
    "        [columns] \\\n",
    "        .dropna()\n",
    "\n",
    "# _simu_class\n",
    "def get_simu_shower_track(columns=dataset_condenser_df_columns_w_event_id):\n",
    "    return query_simu_track(combined_simu_df) \\\n",
    "        [columns] \\\n",
    "        .dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "EVENT_CLASS_LABELED_SHOWER_FLIGHT = 2\n",
    "EVENT_CLASS_SIMU_TRACK = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "shower_subset_df_funcs_dict = {\n",
    "    'lbl_shower_flight_df': get_labeled_shower,\n",
    "    'combined_simu_df_shower_track': get_simu_shower_track\n",
    "}\n",
    "\n",
    "shower_subset_class_numbers_dict = {\n",
    "    'lbl_shower_flight_df': EVENT_CLASS_LABELED_SHOWER_FLIGHT,\n",
    "    'combined_simu_df_shower_track': EVENT_CLASS_SIMU_TRACK\n",
    "}\n",
    "shower_subset_priority_order = ['lbl_shower_flight_df', 'combined_simu_df_shower_track']\n",
    "\n",
    "def get_shower_subsets_list(\n",
    "        df_columns={\n",
    "            'lbl_shower_flight_df': dataset_condenser_df_columns_w_event_id,\n",
    "            'combined_simu_df_shower_track': dataset_condenser_df_columns_w_event_id\n",
    "        }, \n",
    "        shower_subset_df_funcs_dict=shower_subset_df_funcs_dict,\n",
    "        shower_subset_priority_order=shower_subset_priority_order\n",
    "):\n",
    "    shower_subsets_list = []\n",
    "    \n",
    "    for shower_subset_label in shower_subset_priority_order:\n",
    "        \n",
    "        this_df_columns = df_columns[shower_subset_label] \\\n",
    "            if isinstance(df_columns, dict) else df_columns\n",
    "        \n",
    "        shower_subsets_list.append(\n",
    "            shower_subset_df_funcs_dict[shower_subset_label](this_df_columns)\n",
    "        )\n",
    "    \n",
    "    return shower_subsets_list\n",
    "\n",
    "shower_subsets_list = get_shower_subsets_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "showers_nonan_w_event_id_df = pd.concat(shower_subsets_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total size of the simualated showers dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(showers_nonan_w_event_id_df) 34521\n"
     ]
    }
   ],
   "source": [
    "print('len(showers_nonan_w_event_id_df)', len(showers_nonan_w_event_id_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-showers dataset\n",
    "Noise dataset is presently constructed from three subsets, in the follwing priority\n",
    "1. **Classified noise** - *Flight labeled events* excluding classes `shower` and `unspecified`.\n",
    "2. **Unclassified flight** - Dataset of noise of that triggered using configuration with decreased thresholds (bgf=0.5) outside of window of expected cause of the hardware trigger in GTU 40 (Dataset *Flight improbable events* - 20 GTU before or after GTU 42). \n",
    "3. **Overflow simu** - In principle same as **unclassified flight** but on simu simulation - frames consist of a repeating sequence. The entries should be slightly more different form the **unclassified flight** than **underflow simu**. That's set events should be generally shorter than than the repeated sequence length, on the other hand, **overflow simu** contains some events of containing repetition of the frames sequence (should be verified).\n",
    "3. **Unclassified simu** - In principle same as **unclassified flight** but on simu simulation - **overflow** and **noise noise\"** classified events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "EVENT_CLASS_NUMBER_SIMU_OVERFLOW = 0\n",
    "EVENT_CLASS_NUMBER_SIMU_NOISE_NOISE = -4\n",
    "EVENT_CLASS_NUMBER_SIMU_UNDERFLOW = -5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_labeled_flight_noise(df):\n",
    "    return df.query(\n",
    "        '{classification_df_cls_column_name} >= {min_class_number:d} ' \\\n",
    "        'and {classification_df_cls_column_name} not in ({event_class_shower}, {event_class_unspecified})'.format(\n",
    "            classification_df_cls_column_name=classification_df_cls_column_name,\n",
    "            min_class_number=min(EVENT_CLASSES.values()),\n",
    "            event_class_shower=EVENT_CLASSES['shower'],\n",
    "            event_class_unspecified=EVENT_CLASSES['unspecified']\n",
    "    ))\n",
    "\n",
    "def query_unlabeled_flight_noise(df):\n",
    "    return df.query('{classification_df_cls_column_name} == {EVENT_CLASS_NUMBER_UNLABELED_NOISE:d}'.format(\n",
    "        classification_df_cls_column_name=classification_df_cls_column_name, \n",
    "        EVENT_CLASS_NUMBER_UNLABELED_NOISE=EVENT_CLASS_NUMBER_UNLABELED_NOISE,\n",
    "    ))\n",
    "    \n",
    "def query_simu_noise_noise(df):\n",
    "    return df.query('cond_selection_combined == \"noise_noise\"')\n",
    "\n",
    "def query_simu_overflow(df):\n",
    "    return df[df['cond_selection_simple'].isin(['noise_overflow', 'track_overflow'])]\n",
    "\n",
    "def query_simu_underflow(df):\n",
    "    return df[df['cond_selection_simple'].isin(['noise_underflow', 'track_underflow'])]\n",
    "\n",
    "def concatenate_balanced(df_list):\n",
    "    min_len = min([len(t_df) for t_df in df_list])\n",
    "    df_shortened = [(t_df.iloc[np.random.randint(0, len(t_df), min_len)] if len(t_df) > min_len else t_df) \\\n",
    "                    for t_df in df_list]\n",
    "    return pd.concat(df_shortened)\n",
    "\n",
    "def get_labeled_flight_noise(columns=dataset_condenser_df_columns_w_event_id_flight_class):\n",
    "    return query_labeled_flight_noise(flight_df_dict['lbl_noise_flight_df']) \\\n",
    "        [columns] \\\n",
    "        .dropna()\n",
    "\n",
    "def get_unlabeled_flight_noise(columns=dataset_condenser_df_columns_w_event_id_flight_class):\n",
    "    return query_unlabeled_flight_noise(flight_df_dict['unl_noise_flight_df']) \\\n",
    "        [columns] \\\n",
    "        .dropna()\n",
    "\n",
    "def get_simu_noise_noise(columns=dataset_condenser_df_columns_w_event_id_simu_class):\n",
    "    return query_simu_noise_noise(combined_simu_df) \\\n",
    "        [columns] \\\n",
    "        .dropna()\n",
    "\n",
    "def get_simu_overflow(columns=dataset_condenser_df_columns_w_event_id_simu_class):\n",
    "    return query_simu_overflow(combined_simu_df) \\\n",
    "        [columns] \\\n",
    "        .dropna()\n",
    "\n",
    "def get_simu_underflow(columns=dataset_condenser_df_columns_w_event_id_simu_class):\n",
    "    return query_simu_underflow(combined_simu_df) \\\n",
    "        [columns] \\\n",
    "        .dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Size of the dataset in progressively extended by non-shower data until it as large as shower data dataset. \n",
    "If required number of events is lower than size of a subset, events are randomly sampled from the subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current subset size: 0       ; Added lbl_noise_flight_df            subset size: 2619    ; Potentional new dataset size: 2619    ; Required size: 34521  \n",
      "Current subset size: 2619    ; Added unl_noise_flight_df            subset size: 56229   ; Potentional new dataset size: 58848   ; Required size: 34521  \n"
     ]
    }
   ],
   "source": [
    "noise_subset_df_funcs_dict = {\n",
    "    'lbl_noise_flight_df': get_labeled_flight_noise, \n",
    "    'unl_noise_flight_df': get_unlabeled_flight_noise,\n",
    "    'combined_simu_df_overflow': get_simu_overflow,\n",
    "    'combined_simu_df_noise_noise': get_simu_noise_noise,\n",
    "    'combined_simu_df_underflow': get_simu_underflow,\n",
    "}\n",
    "\n",
    "noise_subset_class_numbers_dict = {\n",
    "    'lbl_noise_flight_df': EVENT_CLASS_LABLELED_NOISE_FLIGHT, \n",
    "    'unl_noise_flight_df': EVENT_CLASS_NUMBER_UNLABELED_NOISE, \n",
    "    'combined_simu_df_overflow': EVENT_CLASS_NUMBER_SIMU_OVERFLOW,\n",
    "    'combined_simu_df_noise_noise': EVENT_CLASS_NUMBER_SIMU_NOISE_NOISE,\n",
    "    'combined_simu_df_underflow': EVENT_CLASS_NUMBER_SIMU_UNDERFLOW\n",
    "}\n",
    "\n",
    "noise_subset_priority_order = [\n",
    "    'lbl_noise_flight_df', 'unl_noise_flight_df', \n",
    "    #'combined_simu_df_overflow', 'combined_simu_df_noise_noise', 'combined_simu_df_underflow'\n",
    "]\n",
    "\n",
    "np.random.seed(123)\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "def get_non_shower_subsets_list(\n",
    "        df_columns={\n",
    "            'lbl_noise_flight_df': dataset_condenser_df_columns_w_event_id,  #_flight_class,\n",
    "            'unl_noise_flight_df': dataset_condenser_df_columns_w_event_id,  #_flight_class,\n",
    "            'combined_simu_df_overflow': dataset_condenser_df_columns_w_event_id,  #_simu_class,\n",
    "            'combined_simu_df_noise_noise': dataset_condenser_df_columns_w_event_id,  #_simu_class,\n",
    "            'combined_simu_df_underflow': dataset_condenser_df_columns_w_event_id,  #_simu_class,\n",
    "        }, \n",
    "        noise_subset_df_funcs_dict=noise_subset_df_funcs_dict,\n",
    "        noise_subset_priority_order=noise_subset_priority_order,\n",
    "        len_limit=len(showers_nonan_w_event_id_df)\n",
    "):\n",
    "\n",
    "    non_shower_subsets_list = []\n",
    "    non_shower_subsets_tot_len = 0\n",
    "    for noise_subset_label in noise_subset_priority_order:\n",
    "        get_non_shower_events_func = noise_subset_df_funcs_dict[noise_subset_label]\n",
    "        \n",
    "        this_df_columns = df_columns[noise_subset_label] \\\n",
    "            if isinstance(df_columns, dict) else df_columns\n",
    "        \n",
    "        non_shower_subset_df = get_non_shower_events_func(this_df_columns)\n",
    "        new_len = len(non_shower_subset_df) + non_shower_subsets_tot_len\n",
    "\n",
    "        print('Current subset size: {:<7} ; Added {:<30} subset size: {:<7} ; ' \\\n",
    "              'Potentional new dataset size: {:<7} ; Required size: {:<7}'.format(\n",
    "            non_shower_subsets_tot_len, noise_subset_label, len(non_shower_subset_df),\n",
    "            new_len, len_limit\n",
    "        ))\n",
    "\n",
    "        if new_len > len_limit:\n",
    "            non_shower_subset_df = \\\n",
    "                non_shower_subset_df.iloc[\n",
    "                    np.random.randint(0, len(non_shower_subset_df), \n",
    "                                      len_limit - non_shower_subsets_tot_len)\n",
    "            ]\n",
    "\n",
    "        non_shower_subsets_list.append(non_shower_subset_df)\n",
    "        non_shower_subsets_tot_len += len(non_shower_subset_df)\n",
    "\n",
    "        if new_len >= len_limit:\n",
    "            break\n",
    "            \n",
    "    return non_shower_subsets_list\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "            \n",
    "non_shower_subsets_list = get_non_shower_subsets_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_showers_nonan_w_event_id_df = pd.concat(non_shower_subsets_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total number of noise subset required:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(non_shower_subsets_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenated noise subsets total size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34521\n"
     ]
    }
   ],
   "source": [
    "print(len(non_showers_nonan_w_event_id_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenated arrays (np.ndarray)\n",
    "(not in the report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformation of multiple `pandas.DataFrame` objects into concatenated `numpy.ndarray`. \n",
    "Following arrays are created:\n",
    "- `packets` - training data for an algorithm - packet data - source_file, packet_id, gtu_in_packet\n",
    "- `y` - training data for an algorithm - labels\n",
    "- `event_id` - event id of the data in the dataset - important after `test_train_split()`, used to associate predictions with the original events\n",
    "- `source_class` - source class of the data in the dataset - important after `test_train_split()`, used to associate predictions with the original events, especially to be able to expres accuracy of predictions for a specific source class of data - e.g. label flight noise events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_data_dict = {\n",
    "    'test': {},\n",
    "    'train': {},\n",
    "    'all': pd.concat([\n",
    "        showers_nonan_w_event_id_df[dataset_condenser_df_columns], \n",
    "        non_showers_nonan_w_event_id_df[dataset_condenser_df_columns]\n",
    "    ])\n",
    "}\n",
    "learning_data_dict['all']['target_class'] = np.concatenate([\n",
    "    np.ones(len(showers_nonan_w_event_id_df)), \n",
    "    np.zeros(len(non_showers_nonan_w_event_id_df))\n",
    "])      \n",
    "learning_data_dict['all']['source_class'] = np.concatenate([\n",
    "    *[np.ones(len(shower_subset_df)) * shower_subset_class_numbers_dict[shower_subset_label] \\\n",
    "      for shower_subset_df, shower_subset_label in zip(shower_subsets_list, shower_subset_priority_order)],\n",
    "    *[np.ones(len(non_shower_subset_df)) * noise_subset_class_numbers_dict[noise_subset_label] \\\n",
    "      for non_shower_subset_df, noise_subset_label in zip(non_shower_subsets_list, noise_subset_priority_order)]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3.0: w=6.5905, k=0.5000, num_source_class=2619.0  , norm_num_source_class=17260.5 , 1/frac_noise=13.1810, frac_noise=0.0759, \n",
      "-2.0: w=0.5410, k=0.5000, num_source_class=31902.0 , norm_num_source_class=17260.5 , 1/frac_noise=1.0821, frac_noise=0.9241, \n",
      "sum weights = 34521.0000 , per class = 17260.5000\n"
     ]
    }
   ],
   "source": [
    "def calc_learning_data_weights(learning_data__y, learning_data__source_class, print_info=True):\n",
    "    \n",
    "    learning_data__weights = np.ones_like(learning_data__y)\n",
    "    \n",
    "    uniq_noise_source_classes = np.unique(learning_data__source_class[learning_data__y != 1])\n",
    "\n",
    "    num_shower_events = np.count_nonzero(learning_data__y == 1)\n",
    "    num_noise_events = len(learning_data__y) - num_shower_events\n",
    "\n",
    "    k = num_shower_events / (len(uniq_noise_source_classes) * num_noise_events)\n",
    "\n",
    "    for noise_source_class in uniq_noise_source_classes:\n",
    "        noise_source_class_mask = learning_data__source_class == noise_source_class\n",
    "        \n",
    "        num_noise_source_class = np.count_nonzero(noise_source_class_mask)\n",
    "\n",
    "        w =  k * num_noise_events / num_noise_source_class \n",
    "\n",
    "        learning_data__weights[noise_source_class_mask] = w\n",
    "        \n",
    "        if print_info:\n",
    "            print('{}: w={:.4f}, k={:.4f}, num_source_class={:<8.1f}, norm_num_source_class={:<8.1f}, 1/frac_noise={:.4f}, frac_noise={:.4f}, '.format(\n",
    "                noise_source_class, w, k, \n",
    "                num_noise_source_class, \n",
    "                w*num_noise_source_class , \n",
    "                num_noise_events / num_noise_source_class, \n",
    "                num_noise_source_class / num_noise_events\n",
    "            ))\n",
    "    \n",
    "    if print_info:\n",
    "        s = np.sum(learning_data__weights[learning_data__y == 0])\n",
    "        print('sum weights = {:.4f} , per class = {:.4f}'.format(s, s/len(uniq_noise_source_classes)))\n",
    "    \n",
    "    return learning_data__weights\n",
    "        \n",
    "learning_data_dict['all']['weights'] = \\\n",
    "    calc_learning_data_weights(learning_data_dict['all']['target_class'], learning_data_dict['all']['source_class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labeled concatenated dataset (pd.DataFrame)\n",
    "(not in the report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1., -3., -2.])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning_data_dict['all']['source_class'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-test split\n",
    "\n",
    "The data are split into training and testing subsets in **60:40** ratio. The data are shuffled before splitting, thus there should not be a significat difference in ratios of source clases of the data within the testing and training sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_data_dict['train'], learning_data_dict['test'] = \\\n",
    "    (pd.DataFrame(_df) for _df in sklearn.model_selection.train_test_split(\n",
    "        learning_data_dict['all'],\n",
    "        test_size=.4, \n",
    "        random_state=123, \n",
    "        shuffle=True\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subset: train\n",
      "-3.0: w=6.4672, k=0.4998, num_source_class=1601.0  , norm_num_source_class=10354.0 , 1/frac_noise=12.9400, frac_noise=0.0773, \n",
      "-2.0: w=0.5416, k=0.4998, num_source_class=19116.0 , norm_num_source_class=10354.0 , 1/frac_noise=1.0838, frac_noise=0.9227, \n",
      "sum weights = 20708.0000 , per class = 10354.0000\n",
      "Subset: test\n",
      "-3.0: w=6.7844, k=0.5003, num_source_class=1018.0  , norm_num_source_class=6906.5  , 1/frac_noise=13.5599, frac_noise=0.0737, \n",
      "-2.0: w=0.5402, k=0.5003, num_source_class=12786.0 , norm_num_source_class=6906.5  , 1/frac_noise=1.0796, frac_noise=0.9263, \n",
      "sum weights = 13813.0000 , per class = 6906.5000\n"
     ]
    }
   ],
   "source": [
    "for subset_name in ['train', 'test']:\n",
    "    print('Subset:', subset_name)\n",
    "    learning_data_dict[subset_name]['weights'] = calc_learning_data_weights(\n",
    "        learning_data_dict[subset_name]['target_class'], learning_data_dict[subset_name]['source_class'], print_info=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of entries in training and testing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " test: 27617\n",
      "train: 41425\n",
      "  all: 69042\n"
     ]
    }
   ],
   "source": [
    "for subset_name, _df in learning_data_dict.items():\n",
    "    print('{:>5}: {}'.format(subset_name, len(_df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of entries in training and testing datasets by a class (shower, non-shower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num. non-shower entries in train 20717\n",
      "Num. shower entries in train     20708\n",
      "Num. non-shower entries in test  13804\n",
      "Num. shower entries in test      13813\n"
     ]
    }
   ],
   "source": [
    "print('Num. non-shower entries in train', np.count_nonzero(learning_data_dict['train']['target_class'] == 0))\n",
    "print('Num. shower entries in train    ', np.count_nonzero(learning_data_dict['train']['target_class'] == 1))\n",
    "print('Num. non-shower entries in test ', np.count_nonzero(learning_data_dict['test']['target_class'] == 0))\n",
    "print('Num. shower entries in test     ', np.count_nonzero(learning_data_dict['test']['target_class'] == 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_data__simu_shower_track_mask_arr_all = \\\n",
    "    learning_data_dict['all']['source_class'] == shower_subset_class_numbers_dict['combined_simu_df_shower_track']\n",
    "learning_data__simu_shower_track_mask_arr_test = \\\n",
    "    learning_data_dict['test']['source_class'] == shower_subset_class_numbers_dict['combined_simu_df_shower_track']\n",
    "\n",
    "learning_data__lbl_noise_flight_mask_arr_all = \\\n",
    "    learning_data_dict['all']['source_class'] == noise_subset_class_numbers_dict['lbl_noise_flight_df']\n",
    "learning_data__lbl_noise_flight_mask_arr_train = \\\n",
    "    learning_data_dict['train']['source_class'] == noise_subset_class_numbers_dict['lbl_noise_flight_df']\n",
    "learning_data__lbl_noise_flight_mask_arr_test = \\\n",
    "    learning_data_dict['test']['source_class'] == noise_subset_class_numbers_dict['lbl_noise_flight_df']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of entries in training and testing datasets considering only labeled noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lbl_noise_flight_df in train 1601\n",
      "lbl_noise_flight_df in test  1018\n"
     ]
    }
   ],
   "source": [
    "print('lbl_noise_flight_df in train', np.count_nonzero(learning_data__lbl_noise_flight_mask_arr_train))\n",
    "print('lbl_noise_flight_df in test ', np.count_nonzero(learning_data__lbl_noise_flight_mask_arr_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions have been copied to data_analysis_utils.py\n",
    "\n",
    "def get_first_packet_frame_num(\n",
    "        r, packet_id_column='packet_id', gtu_in_packet_column='gtu_in_packet', packet_size=128, gtu_in_packet_offset=-4,\n",
    "        int_func=int, max_func=max\n",
    "):\n",
    "    gtu_packet_offset = int_func(r[packet_id_column]) * packet_size\n",
    "    total_gtu_offset = gtu_packet_offset + int_func(r[gtu_in_packet_column]) + gtu_in_packet_offset\n",
    "    return max_func((total_gtu_offset, gtu_packet_offset))\n",
    "\n",
    "def get_last_packet_frame_num_high(\n",
    "        r, packet_id_column='packet_id', gtu_in_packet_column='gtu_in_packet', num_gtu_column='num_gtu', num_gtu_overwrite=None,\n",
    "        packet_size=128, gtu_in_packet_offset=-4,\n",
    "        int_func=int, max_func=max, min_func=min\n",
    "):\n",
    "    next_gtu_packet_offset = (int_func(r[packet_id_column]) + 1) * packet_size\n",
    "\n",
    "    num_gtu = int_func(r[num_gtu_column]) if num_gtu_overwrite is None else num_gtu_overwrite\n",
    "    last_frame_num_high = num_gtu + \\\n",
    "        get_first_packet_frame_num(r, packet_id_column=packet_id_column, gtu_in_packet_column=gtu_in_packet_column, \n",
    "            packet_size=packet_size, gtu_in_packet_offset=gtu_in_packet_offset,\n",
    "            int_func=int_func, max_func=max_func)\n",
    "        \n",
    "    return min_func((last_frame_num_high, next_gtu_packet_offset))\n",
    "\n",
    "def get_first_packet_frame_num_in_df(\n",
    "        r, packet_id_column='packet_id', gtu_in_packet_column='gtu_in_packet', \n",
    "        packet_size=128, gtu_in_packet_offset=-4,\n",
    "        int_func=lambda x:x, max_func=lambda x: np.max(x, axis=0)\n",
    "):\n",
    "    return get_first_packet_frame_num(\n",
    "        r, packet_id_column=packet_id_column, gtu_in_packet_column=gtu_in_packet_column, \n",
    "        packet_size=packet_size, gtu_in_packet_offset=gtu_in_packet_offset,\n",
    "        int_func=int_func, max_func=max_func\n",
    "    )\n",
    "\n",
    "def get_last_packet_frame_num_high_in_df(\n",
    "        r, packet_id_column='packet_id', gtu_in_packet_column='gtu_in_packet', num_gtu_column='num_gtu', num_gtu_overwrite=None,\n",
    "        packet_size=128, gtu_in_packet_offset=-4,\n",
    "        int_func=lambda x:x, max_func=lambda x: np.max(x, axis=0), min_func=lambda x: np.min(x, axis=0)\n",
    "):\n",
    "    return get_last_packet_frame_num_high(\n",
    "        r, packet_id_column=packet_id_column, gtu_in_packet_column=gtu_in_packet_column, num_gtu_column=num_gtu_column, \n",
    "        num_gtu_overwrite=num_gtu_overwrite,\n",
    "        packet_size=packet_size, gtu_in_packet_offset=gtu_in_packet_offset,\n",
    "        int_func=int_func, max_func=max_func, min_func=min_func\n",
    "    )\n",
    "\n",
    "def make_frame_sequence_projection(proj_label, frames_sequence):\n",
    "    if proj_label == 'x_y':\n",
    "        proj_image = np.max(frames_sequence, axis=0)\n",
    "    elif proj_label == 'gtu_y':\n",
    "        proj_image = np.transpose(np.max(frames_sequence, axis=2))\n",
    "    elif proj_label == 'gtu_x':\n",
    "        proj_image = np.transpose(np.max(frames_sequence, axis=1))\n",
    "    return proj_image\n",
    "\n",
    "def get_frame_array(\n",
    "        all_rows, transform_func=make_frame_sequence_projection,\n",
    "        return_x_y=True, return_gtu_x=False, return_gtu_y=False, return_offsets=False,\n",
    "        event_id_column='event_id', packet_id_column='packet_id', gtu_in_packet_column='gtu_in_packet', num_gtu_column='num_gtu',\n",
    "        source_file_acquisition_full_column='source_file_acquisition_full',\n",
    "        inverse_means_arr=None,\n",
    "        get_first_frame_num_func=get_first_packet_frame_num,\n",
    "        get_last_frame_num_high_func=get_last_packet_frame_num_high,\n",
    "        print_info=True, allow_not_exists=False, status_update_every=100,\n",
    "        x_y_num_gtu_overwrite=None, gtu_x_num_gtu_overwrite=None, gtu_y_num_gtu_overwrite=None,\n",
    "        packet_size=128, gtu_in_packet_offset=-4\n",
    "):\n",
    "    import pandas as pd\n",
    "    import datetime\n",
    "\n",
    "    visualized_projections_x_y = []\n",
    "    visualized_projections_gtu_x = []\n",
    "    visualized_projections_gtu_y = []\n",
    "\n",
    "    num_npy = 0\n",
    "    num_root = 0\n",
    "    \n",
    "    if print_info:\n",
    "        t0 = datetime.datetime.now()\n",
    "        print('Extracting frames start: {:%Y:%m:%d %H:%M:%S}'.format(t0))\n",
    "    \n",
    "    ####\n",
    "    \n",
    "    num_gtu_dict = {'x_y': x_y_num_gtu_overwrite, 'gtu_x': gtu_x_num_gtu_overwrite, 'gtu_y': gtu_y_num_gtu_overwrite}\n",
    "    abs_start_frame_arr_dict = {'x_y': None, 'gtu_x': None, 'gtu_y': None}\n",
    "    abs_end_frame_arr_dict = {'x_y': None, 'gtu_x': None, 'gtu_y': None}\n",
    "    arr_slice_start_corr_arr_dict = {'x_y': None, 'gtu_x': None, 'gtu_y': None}\n",
    "    # arr_slice_len  - same as num_gtu_dict\n",
    "        \n",
    "    abs_start_frame_arr = np.array(get_first_packet_frame_num_in_df(\n",
    "        all_rows, packet_size=packet_size, gtu_in_packet_offset=gtu_in_packet_offset))\n",
    "\n",
    "    abs_end_frame_arr = np.array(get_last_packet_frame_num_high_in_df(\n",
    "        all_rows, packet_size=packet_size, gtu_in_packet_offset=gtu_in_packet_offset))\n",
    "    \n",
    "    for proj_label, num_gtu_overwrite in num_gtu_dict.items():\n",
    "        \n",
    "        if num_gtu_overwrite is None:\n",
    "            abs_start_frame_arr_dict[proj_label] = abs_start_frame_arr\n",
    "            abs_end_frame_arr_dict[proj_label] = abs_end_frame_arr\n",
    "            num_gtu_dict[proj_label] = np.array(all_rows[num_gtu_column])  # memory inefficient\n",
    "        else:\n",
    "            abs_end_frame_at_owr_gtu_arr = np.array(get_last_packet_frame_num_high_in_df(\n",
    "                all_rows, \n",
    "                num_gtu_overwrite=np.maximum(np.array(all_rows[num_gtu_column]), num_gtu_overwrite), \n",
    "                packet_size=packet_size, gtu_in_packet_offset=gtu_in_packet_offset))\n",
    "            \n",
    "            d = abs_end_frame_at_owr_gtu_arr - abs_start_frame_arr\n",
    "            d_lt_num_gtu_overwrite_mask = d < num_gtu_overwrite\n",
    "\n",
    "            abs_start_frame_at_owr_gtu_arr = np.array(abs_start_frame_arr)\n",
    "                \n",
    "            abs_start_frame_at_owr_gtu_arr[d_lt_num_gtu_overwrite_mask] = \\\n",
    "                abs_start_frame_arr[d_lt_num_gtu_overwrite_mask] - (num_gtu_overwrite - d[d_lt_num_gtu_overwrite_mask])\n",
    "            \n",
    "            check_start_frame_at_owr_gtu_mask = \\\n",
    "                abs_start_frame_at_owr_gtu_arr[d_lt_num_gtu_overwrite_mask] < all_rows[packet_id_column][d_lt_num_gtu_overwrite_mask]*packet_size\n",
    "\n",
    "            if np.any(check_start_frame_at_owr_gtu_mask):\n",
    "                print(np.count_nonzero(check_start_frame_at_owr_gtu_mask))\n",
    "                # inefficient to increase compatibility\n",
    "                first_event_id =  np.array(all_rows[event_id_column][d_lt_num_gtu_overwrite_mask][check_start_frame_at_owr_gtu_mask])[0]\n",
    "                first_gtu_in_packet = np.array(all_rows[gtu_in_packet_column][d_lt_num_gtu_overwrite_mask][check_start_frame_at_owr_gtu_mask])[0]\n",
    "                first_packet_id = np.array(all_rows[packet_id_column][d_lt_num_gtu_overwrite_mask][check_start_frame_at_owr_gtu_mask])[0]\n",
    "                first_num_gtu = np.array(all_rows[num_gtu_column][d_lt_num_gtu_overwrite_mask][check_start_frame_at_owr_gtu_mask])[0]\n",
    "                first_start_frame_at_owr_gtu = abs_start_frame_at_owr_gtu_arr[d_lt_num_gtu_overwrite_mask][check_start_frame_at_owr_gtu_mask][0]\n",
    "                first_end_frame_at_owr_gtu = abs_end_frame_at_owr_gtu_arr[d_lt_num_gtu_overwrite_mask][check_start_frame_at_owr_gtu_mask][0]\n",
    "                first_start_frame = abs_start_frame_arr[d_lt_num_gtu_overwrite_mask][check_start_frame_at_owr_gtu_mask][0]\n",
    "                first_end_frame = abs_end_frame_arr[d_lt_num_gtu_overwrite_mask][check_start_frame_at_owr_gtu_mask][0]\n",
    "                first_lower_packet_bound = (np.array(all_rows[packet_id_column][d_lt_num_gtu_overwrite_mask][check_start_frame_at_owr_gtu_mask])*packet_size)[0]\n",
    "                \n",
    "                raise RuntimeError(\n",
    "                    'Cannot accommodate sufficient window of packet frames in projection {proj}, num_gtu_overwrite={num_gtu_overwrite}. '\n",
    "                    '(First invalid entry: event_id={event_id}, gtu_in_packet={gtu_in_packet}, num_gtu={num_gtu}, packet_id={packet_id}, '\n",
    "                    'computed frame range w/o overwrite=[{start_frame},{end_frame}], '\n",
    "                    'computed frame range w/ overwrite=[{start_frame_at_owr_gtu},{end_frame_at_owr_gtu}], '\n",
    "                    'packet_bounds=[{lower_packet_bound}, {higher_packet_bound}])'.format(\n",
    "                        proj=proj_label, num_gtu_overwrite=num_gtu_overwrite,\n",
    "                        event_id=first_event_id, \n",
    "                        gtu_in_packet=first_gtu_in_packet,\n",
    "                        num_gtu=first_num_gtu, packet_id=first_packet_id,\n",
    "                        start_frame_at_owr_gtu=first_start_frame_at_owr_gtu,\n",
    "                        end_frame_at_owr_gtu=first_end_frame_at_owr_gtu,\n",
    "                        start_frame=first_start_frame,\n",
    "                        end_frame=first_end_frame,\n",
    "                        lower_packet_bound=first_lower_packet_bound, \n",
    "                        higher_packet_bound=first_lower_packet_bound + packet_size\n",
    "                ))\n",
    "\n",
    "            abs_start_frame_arr_dict[proj_label] = abs_start_frame_at_owr_gtu_arr\n",
    "            abs_end_frame_arr_dict[proj_label] = abs_end_frame_at_owr_gtu_arr\n",
    "\n",
    "    \n",
    "    # probably could be not necessary if max overwrite is determined sooner/better\n",
    "    lowest_start_frame_arr = np.min(list(abs_start_frame_arr_dict.values()), axis=0)\n",
    "    highest_end_frame_arr = np.max(list(abs_end_frame_arr_dict.values()), axis=0)\n",
    "    \n",
    "    for proj_label, abs_start_frame_arr in abs_start_frame_arr_dict.items():\n",
    "        arr_slice_start_corr_arr_dict[proj_label] = abs_start_frame_arr - lowest_start_frame_arr \n",
    "    \n",
    "    ####\n",
    "    \n",
    "    if isinstance(all_rows, pd.DataFrame):\n",
    "        \n",
    "        # possible optimization\n",
    "        # c = ['source_file_acquisition_full', 'packet_id', 'gtu_in_packet']\n",
    "        # optimized_order_df = all_rows[c].reset_index().sort_values(c)\n",
    "        # optimized_order_index = \\\n",
    "        #     optimized_order_df.index\n",
    "        # optimized_to_original_mapping_index = \\\n",
    "        #     optimized_order_df.reset_index().sort_values('level_0').index\n",
    "        \n",
    "        _all_rows = all_rows.iterrows()\n",
    "    else:\n",
    "        _all_rows = enumerate(all_rows)\n",
    "        \n",
    "    ####\n",
    "        \n",
    "    for j, (i, r) in enumerate(_all_rows):\n",
    "        \n",
    "        lowest_start_frame = lowest_start_frame_arr[j]\n",
    "        highest_end_frame = highest_end_frame_arr[j]\n",
    "        \n",
    "        if print_info:\n",
    "            if j % status_update_every == 0 and j > 0:\n",
    "                print('{:>5} / {:<5} ({:>5} npy, {:>5} root, {} since start)'.format(\n",
    "                    j+1, len(all_rows), num_npy, num_root, datetime.datetime.now() - t0))\n",
    "        \n",
    "        sfa_str = r[source_file_acquisition_full_column]\n",
    "        if sfa_str.endswith('.npy'):\n",
    "            if not os.path.exists(sfa_str):\n",
    "                msg_str = \"Npy file does not exist: {}\".format(sfa_str)\n",
    "                if allow_not_exists:\n",
    "                    if print_info:\n",
    "                        print(msg_str, file=sys.stderr)\n",
    "                    continue\n",
    "                else:\n",
    "                    raise RuntimeError(msg_str)\n",
    "            acquisition_arr = np.load(sfa_str)\n",
    "            if acquisition_arr.shape[0] != 256:\n",
    "                raise Exception('Unexpected number of frames in the acquisition file \"{}\" (#{}  ID {})'.format(\n",
    "                    sfa_str, i, r[event_id_column]))\n",
    "            frames_acquisition = acquisition_arr[lowest_start_frame:highest_end_frame]\n",
    "            num_npy += 1\n",
    "        elif sfa_str.endswith('.root'):\n",
    "            try:\n",
    "                frames_acquisition = tool.acqconv.get_frames(\n",
    "                    sfa_str, lowest_start_frame, highest_end_frame-1,\n",
    "                    entry_is_gtu_optimization=True)\n",
    "            except Exception as e:\n",
    "                if print_info:\n",
    "                    print('{:>5} / {:<5} ({:<5} npy, {:<5} root, {} since start)'.format(\n",
    "                        j+1, len(all_rows), num_npy, num_root, datetime.datetime.now() - t0))\n",
    "                    sys.stdout.flush()\n",
    "                raise e\n",
    "            num_root += 1\n",
    "        else:\n",
    "            raise Exception('Unexpected source_file_acquisition_full \"{}\"'.format(sfa_str))\n",
    "\n",
    "        if inverse_means_arr is not None:\n",
    "            if callable(inverse_means_arr):\n",
    "                _inverse_means_arr = inverse_means_arr(r)\n",
    "            else:\n",
    "                _inverse_means_arr = inverse_means_arr\n",
    "\n",
    "            if _inverse_means_arr is not None:\n",
    "                frames_acquisition = frames_acquisition * _inverse_means_arr\n",
    "        \n",
    "        for proj_label, ret, target_list in (\n",
    "                ('x_y', return_x_y, visualized_projections_x_y), \n",
    "                ('gtu_y', return_gtu_y, visualized_projections_gtu_y), \n",
    "                ('gtu_x', return_gtu_x, visualized_projections_gtu_x)):\n",
    "            if not return_x_y:\n",
    "                continue\n",
    "            \n",
    "            arr_slice_start_corr = arr_slice_start_corr_arr_dict[proj_label][j]\n",
    "            try:\n",
    "                arr_slice_end_corr = int(num_gtu_dict[proj_label])\n",
    "            except TypeError:\n",
    "                arr_slice_end_corr = num_gtu_dict[proj_label][j]\n",
    "                \n",
    "            arr_slice_end_corr += arr_slice_start_corr\n",
    "            \n",
    "            _frames_acquisition = frames_acquisition[arr_slice_start_corr:arr_slice_end_corr]\n",
    "            \n",
    "            target_item = transform_func(proj_label, _frames_acquisition) \\\n",
    "                if callable(transform_func) else _frames_acquisition\n",
    "                        \n",
    "            target_list.append(target_item)\n",
    "        \n",
    "    ret = []\n",
    "    if return_x_y:\n",
    "        ret.append(visualized_projections_x_y)\n",
    "    if return_gtu_y:\n",
    "        ret.append(visualized_projections_gtu_y)\n",
    "    if return_gtu_x:\n",
    "        ret.append(visualized_projections_gtu_x)\n",
    "\n",
    "    if return_offsets:\n",
    "        ret += [num_gtu_dict, abs_start_frame_arr_dict, abs_end_frame_arr_dict, \n",
    "                arr_slice_start_corr_arr_dict]\n",
    "        \n",
    "    return tuple(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_inverse_means_arr(r, inverse_means_frame_arr=inverse_means_frame_arr):\n",
    "    if r['source_class'] in ((EVENT_CLASS_LABELED_SHOWER_FLIGHT, EVENT_CLASS_LABLELED_NOISE_FLIGHT, EVENT_CLASS_NUMBER_UNLABELED_NOISE)):\n",
    "        return inverse_means_frame_arr\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already exists: ver4_machine_learning_convnet_szakcs_w_labeled_flight_20190628_2__v2/data/train.npz\n",
      "\trealpath /mnt/data_900p/EUSO-Balloon/vrabel/notebooks/ver4_machine_learning_convnet_szakcs_w_labeled_flight_20190628_2__v2/data\n",
      "Already exists: ver4_machine_learning_convnet_szakcs_w_labeled_flight_20190628_2__v2/data/train_class_targets.npy\n",
      "Saving ver4_machine_learning_convnet_szakcs_w_labeled_flight_20190628_2__v2/data/train_config.ini\n",
      "Mock meta file: ver4_machine_learning_convnet_szakcs_w_labeled_flight_20190628_2__v2/data/train_meta.npy\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Already exists: ver4_machine_learning_convnet_szakcs_w_labeled_flight_20190628_2__v2/data/test.npz\n",
      "\trealpath /mnt/data_900p/EUSO-Balloon/vrabel/notebooks/ver4_machine_learning_convnet_szakcs_w_labeled_flight_20190628_2__v2/data\n",
      "Already exists: ver4_machine_learning_convnet_szakcs_w_labeled_flight_20190628_2__v2/data/test_class_targets.npy\n",
      "Saving ver4_machine_learning_convnet_szakcs_w_labeled_flight_20190628_2__v2/data/test_config.ini\n",
      "Mock meta file: ver4_machine_learning_convnet_szakcs_w_labeled_flight_20190628_2__v2/data/test_meta.npy\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "learning_data_frames_dict = {}\n",
    "\n",
    "gtu_proj_num_frames = 30\n",
    "data_export_dir = os.path.join(data_snippets_dir, 'data')  # TODO gtu_proj_num_frames should be incorporated into the file name\n",
    "\n",
    "for subset_name in ['train', 'test']:\n",
    "        \n",
    "    output_npy_pathname = os.path.join(data_export_dir, '{}.npz'.format(subset_name))\n",
    "    output_dirname = os.path.dirname(output_npy_pathname)\n",
    "    output_dirname_realpath = os.path.realpath(output_dirname)\n",
    "    \n",
    "    os.makedirs(subset_output_dir, exist_ok=True)\n",
    "    \n",
    "    print('{}: {}\\n\\trealpath {}'.format(\n",
    "        'Already exists' if os.path.exists(output_npy_pathname) else 'Saving',\n",
    "        output_npy_pathname, output_dirname_realpath,\n",
    "        ))\n",
    "    \n",
    "    if not os.path.exists(output_npy_pathname):\n",
    "                \n",
    "        x_y_list, gtu_y_list, gtu_x_list = \\\n",
    "            get_frame_array(\n",
    "                learning_data_dict[subset_name], inverse_means_arr=get_inverse_means_arr,\n",
    "                x_y_num_gtu_overwrite=None, gtu_x_num_gtu_overwrite=gtu_proj_num_frames, gtu_y_num_gtu_overwrite=gtu_proj_num_frames,\n",
    "                return_x_y=True, return_gtu_x=True, return_gtu_y=True)\n",
    "\n",
    "        # learning_data_frames_dict[subset_name] = \\\n",
    "        _frames = {\n",
    "            'x_y': np.array(x_y_list), 'gtu_y': np.array(gtu_y_list), 'gtu_x': np.array(gtu_x_list)\n",
    "        }\n",
    "        \n",
    "        np.savez_compressed(output_npy_pathname, **_frames)\n",
    "    \n",
    "    # else:\n",
    "    #     learning_data_frames_dict[subset_name] = np.load(output_npy_pathname)\n",
    "        \n",
    "    output_npy_pathname = os.path.join(data_export_dir, '{}_class_targets.npy'.format(subset_name))\n",
    "    \n",
    "    if not os.path.exists(output_npy_pathname):\n",
    "        print('Saving:',output_npy_pathname)\n",
    "        np.save(output_npy_pathname, learning_data_dict[subset_name]['target_class'])\n",
    "    else:\n",
    "        print('Already exists:',output_npy_pathname)\n",
    "    \n",
    "    config_ini_file = os.path.join(data_export_dir, '{}_config.ini'.format(subset_name))\n",
    "    \n",
    "    if not os.path.exists(config_ini_file):\n",
    "        print('Saving', config_ini_file)\n",
    "        config_file_content = \\\n",
    "'''[general]\n",
    "num_data = {list_len}\n",
    "metafields = {{}}\n",
    "dtype = float32\n",
    "\n",
    "[packet_shape]\n",
    "num_frames = {num_frames}\n",
    "frame_height = 48\n",
    "frame_width = 48\n",
    "\n",
    "[item_types]\n",
    "raw = False\n",
    "yx = True\n",
    "gtux = True\n",
    "gtuy = True\n",
    "'''.format(\n",
    "            list_len=len(learning_data_dict[subset_name]),\n",
    "            num_frames=gtu_proj_num_frames\n",
    "        )\n",
    "        with open(config_ini_file, 'w+') as f:\n",
    "            f.write(config_file_content)\n",
    "        \n",
    "    else:\n",
    "        print('Already exists', config_ini_file)\n",
    "    \n",
    "    mock_empty_meta_file = os.path.join(data_export_dir, '{}_meta.npy'.format(subset_name))\n",
    "        \n",
    "    print('Mock meta file:',mock_empty_meta_file)\n",
    "    if not os.path.exists(mock_empty_meta_file):\n",
    "        with open(mock_empty_meta_file, 'w+') as _:\n",
    "            pass\n",
    "        \n",
    "    print('-'*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import utility_functions\n",
    "\n",
    "# max_depth = 4\n",
    "# max_num_dirs = 4\n",
    "\n",
    "# trie_prefix_len = 1\n",
    "# sep='/'\n",
    "\n",
    "# dataset_condenser_input_data_dirs_dict = {}\n",
    "\n",
    "# def _add_dir_tree_node(prefix_groups_tree, t_i):\n",
    "#     node_found = False\n",
    "#     exchange_root = False\n",
    "#     for start_prefix, v in prefix_groups_tree.items(): \n",
    "#         if len(start_prefix) < len(t_i[0]) and t_i[0].startswith(start_prefix):\n",
    "#             _add_dir_tree_node(v, t_i)\n",
    "#             node_found = True\n",
    "#             break\n",
    "#         elif len(start_prefix) > len(t_i[0]) and start_prefix.startswith(t_i[0]):\n",
    "#             exchange_root = True\n",
    "#             break\n",
    "#     if exchange_root:\n",
    "#         prefix_groups_tree[t_i[0]] = {start_prefix: prefix_groups_tree[start_prefix]}\n",
    "#         del prefix_groups_tree[start_prefix]\n",
    "#     elif not node_found:\n",
    "#         prefix_groups_tree[t_i[0]] = {}\n",
    "\n",
    "# def _get_dirs_by_depth(prefix_groups_tree, target_depth, cur_depth=1):\n",
    "#     dirs_list = []\n",
    "#     for k, v in prefix_groups_tree.items():\n",
    "#         if cur_depth != target_depth:\n",
    "#             if len(v) > 0:\n",
    "#                 dirs_list += _get_dirs_by_depth(v, target_depth, cur_depth+1)\n",
    "#             else:\n",
    "#                 dirs_list.append(k)\n",
    "#         else:\n",
    "#             dirs_list.append(k)\n",
    "#     return dirs_list\n",
    "\n",
    "# for subset_name in ['train', 'test']:\n",
    "    \n",
    "#     dataset_condenser_input_data_dirs_dict[subset_name] = {}\n",
    "    \n",
    "#     print('Subset:', subset_name)\n",
    "    \n",
    "#     l = \\\n",
    "#         list(set(dataset_condenser_input_df_dict[subset_name]['source_file_acquisition_full'].apply(os.path.dirname)))\n",
    "#     l_realpath = list(map(os.path.realpath, l))\n",
    "    \n",
    "#     for t_label, t_l in (('absolute', l), ('realpath',l_realpath)):\n",
    "\n",
    "#         t_input_data_dirs = input_data_dirs = t_l\n",
    "#         items_list = utility_functions.get_grouping_by_prefix(t_input_data_dirs, trie_prefix_len=1, sep='/')\n",
    "\n",
    "#         row_keys_trie = utility_functions.StrPrefixTrie()\n",
    "#         for k in items_list:\n",
    "#             row_keys_trie.insert(k)\n",
    "\n",
    "#         trie_prefixes = []\n",
    "#         for prefix, multiplicity in row_keys_trie.getPrefixes(trie_prefix_len):\n",
    "#             if prefix.endswith(sep):\n",
    "#                 prefix_no_sep = prefix[:-len(sep)]\n",
    "#                 if len(prefix_no_sep) == 0:\n",
    "#                     continue\n",
    "#                 trie_prefixes.append((prefix_no_sep, multiplicity))\n",
    "\n",
    "#         trie_prefixes_filtered = [t for t in trie_prefixes if len(t[0].split('/'))-1 <= max_depth or t[1] == 1]\n",
    "\n",
    "#         prefix_groups_tree = { trie_prefixes[0][0]: {} }\n",
    "\n",
    "#         for t_i  in trie_prefixes[1:]:\n",
    "#             _add_dir_tree_node(prefix_groups_tree, t_i)\n",
    "\n",
    "#         for i in range(max_depth,0,-1):\n",
    "#             dirs_list = _get_dirs_by_depth(prefix_groups_tree, i)\n",
    "#             if len(dirs_list) <= max_num_dirs:\n",
    "#                 break\n",
    "\n",
    "#         dataset_condenser_input_data_dirs_dict[subset_name][t_label] = dirs_list\n",
    "        \n",
    "#         print(dirs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection and classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(This is part that might be changed in the later machine learning procedures)\n",
    "1. Variance thresholding to remove features without any variance.\n",
    "2. Univariate feature selection to select smaller but still large enough subset of features (mainly to limit the computational demands). This particular procedure selects 400 features.\n",
    "3. Recursive feature elimination with cross-validation - Training and validating Extremely Randomized Trees model (ExtraTreesClassifier) on multiple combinations of features aimed to select set of features that provide the best classification accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args='docker build --tag convnet_euso:0.25 -f /mnt/data_wdblue3d1/spbproc/convnet_euso/Dockerfile-gpu /mnt/data_wdblue3d1/spbproc/convnet_euso', returncode=0)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending build context to Docker daemon  498.2MB\r",
      "\r\n",
      "Step 1/13 : FROM nvidia/cuda:9.0-base\n",
      " ---> 3c57055e68a2\n",
      "Step 2/13 : LABEL maintainer \"MichalVrabel\"\n",
      " ---> Using cache\n",
      " ---> 3eb2732508fe\n",
      "Step 3/13 : ADD resources/get-pip.py /tmp/get-pip.py\n",
      " ---> Using cache\n",
      " ---> d8690a277d20\n",
      "Step 4/13 : ADD resources/root_v6.15.02.source.tar.gz /tmp\n",
      " ---> Using cache\n",
      " ---> aef9868638ca\n",
      "Step 5/13 : ENV DEBIAN_FRONTEND noninteractive\n",
      " ---> Using cache\n",
      " ---> 6551947ed3a1\n",
      "Step 6/13 : RUN apt-get update\n",
      " ---> Using cache\n",
      " ---> 8a4cccf38e01\n",
      "Step 7/13 : RUN apt-get install -y apt-utils\n",
      " ---> Using cache\n",
      " ---> 444e7f1c75d5\n",
      "Step 8/13 : RUN apt-get install -y python python3 python3-dev cmake git dpkg-dev g++ gcc binutils libx11-dev libxpm-dev libxft-dev libxext-dev\n",
      " ---> Using cache\n",
      " ---> a4be10a5cfb2\n",
      "Step 9/13 : RUN python3 /tmp/get-pip.py\n",
      " ---> Using cache\n",
      " ---> c36ad9ad3df5\n",
      "Step 10/13 : RUN mkdir /tmp/cern_root_build && cd /tmp/cern_root_build &&     cmake         -DPYTHON_EXECUTABLE=/usr/bin/python3         -DPYTHON_INCLUDE_DIR=$(python3-config --includes | sed 's/-I/\\n/g' | tail -n1)         -DPYTHON_LIBRARY=$(find $(cat /etc/ld.so.conf.d/* | grep -v '^#' |             xargs -l1 ls -d 2>/dev/null) -name \"$(pkg-config --libs python3 | sed 's/-l/lib/').so\")         /tmp/root*6.15.02 &&     cmake --build . -- -j $(grep -c \"vendor_id\" /proc/cpuinfo) -l $(grep -c \"vendor_id\" /proc/cpuinfo) &&     cmake --build . --target install\n",
      " ---> Using cache\n",
      " ---> 2f2453d6118a\n",
      "Step 11/13 : RUN ldconfig\n",
      " ---> Using cache\n",
      " ---> 26028e20b167\n",
      "Step 12/13 : RUN pip install numpy scipy matplotlib==3.0.3 pandas scikit-learn scikit-image==0.14.4 html5lib Markdown enum34 tensorflow-gpu==1.14.0 tensorboard==1.14.0 tflearn\n",
      " ---> Running in 2bc8d0f920eb\n",
      "Collecting numpy\n",
      "  Downloading https://files.pythonhosted.org/packages/52/e6/1715e592ef47f28f3f50065322423bb75619ed2f7c24be86380ecc93503c/numpy-1.18.1-cp35-cp35m-manylinux1_x86_64.whl (19.9MB)\n",
      "Collecting scipy\n",
      "  Downloading https://files.pythonhosted.org/packages/c1/60/8cbf00c0deb50a971e6e3a015fb32513960a92867df979870a454481817c/scipy-1.4.1-cp35-cp35m-manylinux1_x86_64.whl (26.0MB)\n",
      "Collecting matplotlib==3.0.3\n",
      "  Downloading https://files.pythonhosted.org/packages/89/61/465fb3bfba684b0f53b5c4829c3c89e86e6fe9fdcdfda93e38f1788090f0/matplotlib-3.0.3-cp35-cp35m-manylinux1_x86_64.whl (13.0MB)\n",
      "Collecting pandas\n",
      "  Downloading https://files.pythonhosted.org/packages/74/24/0cdbf8907e1e3bc5a8da03345c23cbed7044330bb8f73bb12e711a640a00/pandas-0.24.2-cp35-cp35m-manylinux1_x86_64.whl (10.0MB)\n",
      "Collecting scikit-learn\n",
      "  Downloading https://files.pythonhosted.org/packages/a8/01/a37d1ae4191ef09adc6385ae9f9306409e93370f7e85338152b608e7d6a3/scikit_learn-0.22.1-cp35-cp35m-manylinux1_x86_64.whl (7.0MB)\n",
      "Collecting scikit-image==0.14.4\n",
      "  Downloading https://files.pythonhosted.org/packages/64/d2/a92b1ab6ae859ee9b52f3218ef6482742dd512d692bacb3bbe1c5db96529/scikit_image-0.14.4-cp35-cp35m-manylinux1_x86_64.whl (25.3MB)\n",
      "Collecting html5lib\n",
      "  Downloading https://files.pythonhosted.org/packages/a5/62/bbd2be0e7943ec8504b517e62bab011b4946e1258842bc159e5dfde15b96/html5lib-1.0.1-py2.py3-none-any.whl (117kB)\n",
      "Collecting Markdown\n",
      "  Downloading https://files.pythonhosted.org/packages/c0/4e/fd492e91abdc2d2fcb70ef453064d980688762079397f779758e055f6575/Markdown-3.1.1-py2.py3-none-any.whl (87kB)\n",
      "Collecting enum34\n",
      "  Downloading https://files.pythonhosted.org/packages/af/42/cb9355df32c69b553e72a2e28daee25d1611d2c0d9c272aa1d34204205b2/enum34-1.1.6-py3-none-any.whl\n",
      "Collecting tensorflow-gpu==1.14.0\n",
      "  Downloading https://files.pythonhosted.org/packages/8b/dc/922125284fb70d5ac17a3c3be87d8f1d95908bb5067977e7813bf7b7f712/tensorflow_gpu-1.14.0-cp35-cp35m-manylinux1_x86_64.whl (377.0MB)\n",
      "\u001b[91mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))': /simple/tensorboard/\n",
      "\u001b[0mCollecting tensorboard==1.14.0\n",
      "  Downloading https://files.pythonhosted.org/packages/91/2d/2ed263449a078cd9c8a9ba50ebd50123adf1f8cfbea1492f9084169b89d9/tensorboard-1.14.0-py3-none-any.whl (3.1MB)\n",
      "Collecting tflearn\n",
      "  Downloading https://files.pythonhosted.org/packages/16/ec/e9ce1b52e71f6dff3bd944f020cef7140779e783ab27512ea7c7275ddee5/tflearn-0.3.2.tar.gz (98kB)\n",
      "Collecting pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1\n",
      "  Downloading https://files.pythonhosted.org/packages/5d/bc/1e58593167fade7b544bfe9502a26dc860940a79ab306e651e7f13be68c2/pyparsing-2.4.6-py2.py3-none-any.whl (67kB)\n",
      "Collecting cycler>=0.10\n",
      "  Downloading https://files.pythonhosted.org/packages/f7/d2/e07d3ebb2bd7af696440ce7e754c59dd546ffe1bbe732c8ab68b9c834e61/cycler-0.10.0-py2.py3-none-any.whl\n",
      "Collecting python-dateutil>=2.1\n",
      "  Downloading https://files.pythonhosted.org/packages/d4/70/d60450c3dd48ef87586924207ae8907090de0b306af2bce5d134d78615cb/python_dateutil-2.8.1-py2.py3-none-any.whl (227kB)\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Downloading https://files.pythonhosted.org/packages/ee/18/4cd2e84c6aff0c6a50479118083d20b9e676e5175a913c0ea76d700fc244/kiwisolver-1.1.0-cp35-cp35m-manylinux1_x86_64.whl (90kB)\n",
      "Collecting pytz>=2011k\n",
      "  Downloading https://files.pythonhosted.org/packages/e7/f9/f0b53f88060247251bf481fa6ea62cd0d25bf1b11a87888e53ce5b7c8ad2/pytz-2019.3-py2.py3-none-any.whl (509kB)\n",
      "Collecting joblib>=0.11\n",
      "  Downloading https://files.pythonhosted.org/packages/28/5c/cf6a2b65a321c4a209efcdf64c2689efae2cb62661f8f6f4bb28547cf1bf/joblib-0.14.1-py2.py3-none-any.whl (294kB)\n",
      "Collecting six>=1.10.0\n",
      "  Downloading https://files.pythonhosted.org/packages/65/26/32b8464df2a97e6dd1b656ed26b2c194606c16fe163c695a992b36c11cdf/six-1.13.0-py2.py3-none-any.whl\n",
      "Collecting PyWavelets>=0.4.0\n",
      "  Downloading https://files.pythonhosted.org/packages/7f/25/b2a6099c528fee4a132e1070033191dbaacded2ebe48804ec31b4c9aac13/PyWavelets-1.1.1-cp35-cp35m-manylinux1_x86_64.whl (4.4MB)\n",
      "Collecting networkx>=1.8\n",
      "  Downloading https://files.pythonhosted.org/packages/41/8f/dd6a8e85946def36e4f2c69c84219af0fa5e832b018c970e92f2ad337e45/networkx-2.4-py3-none-any.whl (1.6MB)\n",
      "Collecting cloudpickle>=0.2.1\n",
      "  Downloading https://files.pythonhosted.org/packages/c1/49/334e279caa3231255725c8e860fa93e72083567625573421db8875846c14/cloudpickle-1.2.2-py2.py3-none-any.whl\n",
      "Collecting pillow>=4.3.0\n",
      "  Downloading https://files.pythonhosted.org/packages/c6/42/fdaf9b53942b103462db3d843c5bc3eb660f9b2e58419ebc99ed87d93dd2/Pillow-7.0.0-cp35-cp35m-manylinux1_x86_64.whl (2.1MB)\n",
      "Collecting webencodings\n",
      "  Downloading https://files.pythonhosted.org/packages/f4/24/2a3e3df732393fed8b3ebf2ec078f05546de641fe1b667ee316ec1dcf3b7/webencodings-0.5.1-py2.py3-none-any.whl\n",
      "Requirement already satisfied: setuptools>=36 in /usr/local/lib/python3.5/dist-packages (from Markdown) (42.0.2)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.5/dist-packages (from tensorflow-gpu==1.14.0) (0.33.6)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Downloading https://files.pythonhosted.org/packages/8a/48/a76be51647d0eb9f10e2a4511bf3ffb8cc1e6b14e9e4fab46173aa79f981/termcolor-1.1.0.tar.gz\n",
      "Collecting grpcio>=1.8.6\n",
      "  Downloading https://files.pythonhosted.org/packages/d8/85/4bf2bbe6d347f6b249bb07e863970469b1206aea99118b232497fa701d8c/grpcio-1.26.0-cp35-cp35m-manylinux2010_x86_64.whl (2.4MB)\n",
      "Collecting absl-py>=0.7.0\n",
      "  Downloading https://files.pythonhosted.org/packages/1a/53/9243c600e047bd4c3df9e69cfabc1e8004a82cac2e0c484580a78a94ba2a/absl-py-0.9.0.tar.gz (104kB)\n",
      "Collecting keras-preprocessing>=1.0.5\n",
      "  Downloading https://files.pythonhosted.org/packages/28/6a/8c1f62c37212d9fc441a7e26736df51ce6f0e38455816445471f10da4f0a/Keras_Preprocessing-1.1.0-py2.py3-none-any.whl (41kB)\n",
      "Collecting protobuf>=3.6.1\n",
      "  Downloading https://files.pythonhosted.org/packages/dd/45/65a730c50262d6bfc573807a15ad40d3e9e401af7af70ad1c689a99918ca/protobuf-3.11.2-cp35-cp35m-manylinux1_x86_64.whl (1.3MB)\n",
      "Collecting wrapt>=1.11.1\n",
      "  Downloading https://files.pythonhosted.org/packages/23/84/323c2415280bc4fc880ac5050dddfb3c8062c2552b34c2e512eb4aa68f79/wrapt-1.11.2.tar.gz\n",
      "Collecting astor>=0.6.0\n",
      "  Downloading https://files.pythonhosted.org/packages/c3/88/97eef84f48fa04fbd6750e62dcceafba6c63c81b7ac1420856c8dcc0a3f9/astor-0.8.1-py2.py3-none-any.whl\n",
      "Collecting gast>=0.2.0\n",
      "  Downloading https://files.pythonhosted.org/packages/1f/04/4e36c33f8eb5c5b6c622a1f4859352a6acca7ab387257d4b3c191d23ec1d/gast-0.3.2.tar.gz\n",
      "Collecting keras-applications>=1.0.6\n",
      "  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
      "Collecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0\n",
      "  Downloading https://files.pythonhosted.org/packages/3c/d5/21860a5b11caf0678fbc8319341b0ae21a07156911132e0e71bffed0510d/tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488kB)\n",
      "Collecting google-pasta>=0.1.6\n",
      "  Downloading https://files.pythonhosted.org/packages/c3/fd/1e86bc4837cc9a3a5faf3db9b1854aa04ad35b5f381f9648fbe81a6f94e4/google_pasta-0.1.8-py3-none-any.whl (57kB)\n",
      "Collecting werkzeug>=0.11.15\n",
      "  Downloading https://files.pythonhosted.org/packages/ce/42/3aeda98f96e85fd26180534d36570e4d18108d62ae36f87694b476b83d6f/Werkzeug-0.16.0-py2.py3-none-any.whl (327kB)\n",
      "Collecting decorator>=4.3.0\n",
      "  Downloading https://files.pythonhosted.org/packages/8f/b7/f329cfdc75f3d28d12c65980e4469e2fa373f1953f5df6e370e84ea2e875/decorator-4.4.1-py2.py3-none-any.whl\n",
      "Collecting h5py\n",
      "  Downloading https://files.pythonhosted.org/packages/10/56/d5c53cd170529bb40cd7dd43e2b68944cb65a45f65ab4c78a68f4ac9e51e/h5py-2.10.0-cp35-cp35m-manylinux1_x86_64.whl (2.8MB)\n",
      "Building wheels for collected packages: tflearn, termcolor, absl-py, wrapt, gast\n",
      "  Building wheel for tflearn (setup.py): started\n",
      "  Building wheel for tflearn (setup.py): finished with status 'done'\n",
      "  Created wheel for tflearn: filename=tflearn-0.3.2-cp35-none-any.whl size=128208 sha256=fae62287e5ba4749ae81bb6c2cde173d1697247e4e87e4ddeffc93fce473bf0b\n",
      "  Stored in directory: /root/.cache/pip/wheels/d0/f6/69/0ef3ee395aac2e5d15d89efd29a9a216f3c27767b43b72c006\n",
      "  Building wheel for termcolor (setup.py): started\n",
      "  Building wheel for termcolor (setup.py): finished with status 'done'\n",
      "  Created wheel for termcolor: filename=termcolor-1.1.0-cp35-none-any.whl size=4832 sha256=4fce72a1948c7706856f598d2737c94636a7e42c72c74751e95a6634b1c5c924\n",
      "  Stored in directory: /root/.cache/pip/wheels/7c/06/54/bc84598ba1daf8f970247f550b175aaaee85f68b4b0c5ab2c6\n",
      "  Building wheel for absl-py (setup.py): started\n",
      "  Building wheel for absl-py (setup.py): finished with status 'done'\n",
      "  Created wheel for absl-py: filename=absl_py-0.9.0-cp35-none-any.whl size=121932 sha256=4d9c06f8e7cdd6fc350b4b7d40a569af1a41495bd756c8ae10935e9b9e96f461\n",
      "  Stored in directory: /root/.cache/pip/wheels/8e/28/49/fad4e7f0b9a1227708cbbee4487ac8558a7334849cb81c813d\n",
      "  Building wheel for wrapt (setup.py): started\n",
      "  Building wheel for wrapt (setup.py): finished with status 'done'\n",
      "  Created wheel for wrapt: filename=wrapt-1.11.2-cp35-cp35m-linux_x86_64.whl size=64255 sha256=0107af4a81b52709d4ad4d52a99f020c123fa05e87b200423a9e59dbf796fba1\n",
      "  Stored in directory: /root/.cache/pip/wheels/d7/de/2e/efa132238792efb6459a96e85916ef8597fcb3d2ae51590dfd\n",
      "  Building wheel for gast (setup.py): started\n",
      "  Building wheel for gast (setup.py): finished with status 'done'\n",
      "  Created wheel for gast: filename=gast-0.3.2-cp35-none-any.whl size=9677 sha256=e3a8db97390091bd0f311fd99f4c0834d34901fc6137629297e77e20b001b82e\n",
      "  Stored in directory: /root/.cache/pip/wheels/59/38/c6/234dc39b4f6951a0768fbc02d5b7207137a5b1d9094f0d54bf\n",
      "Successfully built tflearn termcolor absl-py wrapt gast\n",
      "Installing collected packages: numpy, scipy, pyparsing, six, cycler, python-dateutil, kiwisolver, matplotlib, pytz, pandas, joblib, scikit-learn, PyWavelets, decorator, networkx, cloudpickle, pillow, scikit-image, webencodings, html5lib, Markdown, enum34, absl-py, protobuf, grpcio, werkzeug, tensorboard, termcolor, keras-preprocessing, wrapt, astor, gast, h5py, keras-applications, tensorflow-estimator, google-pasta, tensorflow-gpu, tflearn\n",
      "Successfully installed Markdown-3.1.1 PyWavelets-1.1.1 absl-py-0.9.0 astor-0.8.1 cloudpickle-1.2.2 cycler-0.10.0 decorator-4.4.1 enum34-1.1.6 gast-0.3.2 google-pasta-0.1.8 grpcio-1.26.0 h5py-2.10.0 html5lib-1.0.1 joblib-0.14.1 keras-applications-1.0.8 keras-preprocessing-1.1.0 kiwisolver-1.1.0 matplotlib-3.0.3 networkx-2.4 numpy-1.18.1 pandas-0.24.2 pillow-7.0.0 protobuf-3.11.2 pyparsing-2.4.6 python-dateutil-2.8.1 pytz-2019.3 scikit-image-0.14.4 scikit-learn-0.22.1 scipy-1.4.1 six-1.13.0 tensorboard-1.14.0 tensorflow-estimator-1.14.0 tensorflow-gpu-1.14.0 termcolor-1.1.0 tflearn-0.3.2 webencodings-0.5.1 werkzeug-0.16.0 wrapt-1.11.2\n",
      "Removing intermediate container 2bc8d0f920eb\n",
      " ---> 4e6caf0cd361\n",
      "Step 13/13 : RUN cd /usr/local/lib/python3.*/dist-packages/ &&     for f in /usr/local/lib/*.py /usr/local/lib/libPyROOT.so ; do         b=$(basename \"$f\");         [ -e \"$b\" ] && continue;         ln -s -v $f ;     done\n",
      " ---> Running in a817998a9f59\n",
      "'./ROOT.py' -> '/usr/local/lib/ROOT.py'\n",
      "'./_pythonization.py' -> '/usr/local/lib/_pythonization.py'\n",
      "'./cmdLineUtils.py' -> '/usr/local/lib/cmdLineUtils.py'\n",
      "'./cppyy.py' -> '/usr/local/lib/cppyy.py'\n",
      "'./libPyROOT.so' -> '/usr/local/lib/libPyROOT.so'\n",
      "Removing intermediate container a817998a9f59\n",
      " ---> 22d1a8ae2dec\n",
      "Successfully built 22d1a8ae2dec\n",
      "Successfully tagged convnet_euso:0.25\n"
     ]
    }
   ],
   "source": [
    "subprocess.run(\n",
    "    'docker build --tag convnet_euso:0.25 -f {} {}'.format(\n",
    "        covnet_euso_dockerfile, covnet_euso_docker_dir\n",
    "    ), \n",
    "    shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args='docker run --rm  -v /mnt/data_wdblue3d1/spbproc/convnet_euso/src:/src -w /src  convnet_euso:0.25 python3 model_trainer.py --help', returncode=0)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: model_trainer.py [-h] --name NAME --srcdir SRCDIR\n",
      "                        [--test_name TEST_NAME] [--test_srcdir TEST_SRCDIR]\n",
      "                        [--load_raw] [--load_yx] [--load_gtux] [--load_gtuy]\n",
      "                        [--test_items_count TEST_ITEMS_COUNT]\n",
      "                        [--test_items_fraction TEST_ITEMS_FRACTION]\n",
      "                        --split_mode {FROM_START,FROM_END,RANDOM,args} -n\n",
      "                        NETWORK [-m MODEL_FILE] [--tb_dir TB_DIR] [--save]\n",
      "                        [--batch_size BATCH_SIZE]\n",
      "                        [--learning_rate LEARNING_RATE] [-e NUM_EPOCHS]\n",
      "                        [--validation_batch_size VALIDATION_BATCH_SIZE]\n",
      "                        [--snapshot_step SNAPSHOT_STEP] [--loss_fn LOSS_FN]\n",
      "                        [--optimizer OPTIMIZER]\n",
      "\n",
      "Train network using provided dataset\n",
      "\n",
      "optional arguments:\n",
      "  -h, --help            show this help message and exit\n",
      "\n",
      "Input dataset:\n",
      "  --name NAME           input dataset name\n",
      "  --srcdir SRCDIR       input dataset directory\n",
      "  --test_name TEST_NAME\n",
      "                        input dataset name\n",
      "  --test_srcdir TEST_SRCDIR\n",
      "                        input dataset directory\n",
      "  --load_raw            load raw packets\n",
      "  --load_yx             load yx packet projections\n",
      "  --load_gtux           load gtux packet projections\n",
      "  --load_gtuy           load gtuy packet projections\n",
      "  --test_items_count TEST_ITEMS_COUNT\n",
      "                        Number of dataset items to include in the test set.\n",
      "                        Overrides test_items_fraction.\n",
      "  --test_items_fraction TEST_ITEMS_FRACTION\n",
      "                        Number of dataset items to include in the test set,\n",
      "                        expressed as a fraction.\n",
      "  --split_mode {FROM_START,FROM_END,RANDOM,args}\n",
      "                        Method of splitting the test items subset from the\n",
      "                        input dataset.\n",
      "\n",
      "Network configuration:\n",
      "  -n NETWORK, --network NETWORK\n",
      "                        Name of network module/architecture\n",
      "  -m MODEL_FILE, --model_file MODEL_FILE\n",
      "                        File with trained model of given architecture\n",
      "  --tb_dir TB_DIR       directory to store training logs for tensorboard.\n",
      "  --save                save the model after training. Model files are saved\n",
      "                        under tb_dir as\n",
      "                        net.network_name/net.network_name.tflearn.*\n",
      "\n",
      "Training parameters:\n",
      "  --batch_size BATCH_SIZE\n",
      "                        Batch size for training data\n",
      "  --learning_rate LEARNING_RATE\n",
      "                        Learning rate to use\n",
      "  -e NUM_EPOCHS, --num_epochs NUM_EPOCHS\n",
      "                        Number of training epochs\n",
      "  --validation_batch_size VALIDATION_BATCH_SIZE\n",
      "                        Batch size for test data\n",
      "  --snapshot_step SNAPSHOT_STEP\n",
      "                        Number of training steps between snapshots\n",
      "  --loss_fn LOSS_FN     Loss function to use\n",
      "  --optimizer OPTIMIZER\n",
      "                        Gradient descent optimizer to use\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tflearn/helpers/summarizer.py:9: The name tf.summary.merge is deprecated. Please use tf.compat.v1.summary.merge instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tflearn/helpers/trainer.py:25: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tflearn/collections.py:13: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tflearn/config.py:123: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tflearn/config.py:129: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tflearn/config.py:131: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "subprocess.run(\n",
    "    'docker run --rm  -v {}:/src -w /src  convnet_euso:0.25 python3 model_trainer.py --help'.format(\n",
    "        covnet_euso_src_dir\n",
    "    ),\n",
    "    shell=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ver4_machine_learning_convnet_szakcs_w_labeled_flight_20190628_2__v2/data'"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_export_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_trainer_output_dir = os.path.join(data_snippets_dir, 'model_trainer')\n",
    "os.makedirs(model_trainer_output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume_dirs = {'export_dir': data_export_dir, 'trainer_dir': model_trainer_output_dir}\n",
    "in_container_dirs = {}\n",
    "volumes_set = set()\n",
    "common_path = os.path.commonpath(volume_dirs.values())\n",
    "if common_path:\n",
    "    common_path_realpath = os.path.realpath(common_path)\n",
    "    common_path_basename = os.path.basename(common_path)\n",
    "for k, d in volume_dirs.items():\n",
    "    if common_path and d.startswith(common_path):\n",
    "        volumes_set.add('{}:/{}'.format(common_path_realpath, common_path_basename))\n",
    "        in_container_dirs[k] = '/' + os.path.join(common_path_basename, d[len(common_path)+1:])\n",
    "    else:\n",
    "        volumes_set.add('{}:{}'.format(d, d))\n",
    "        in_container_dirs[k] = d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'export_dir': '/ver4_machine_learning_convnet_szakcs_w_labeled_flight_20190628_2__v2/data',\n",
       " 'trainer_dir': '/ver4_machine_learning_convnet_szakcs_w_labeled_flight_20190628_2__v2/model_trainer'}"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_container_dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'/mnt/data_900p/EUSO-Balloon/vrabel/notebooks/ver4_machine_learning_convnet_szakcs_w_labeled_flight_20190628_2__v2:/ver4_machine_learning_convnet_szakcs_w_labeled_flight_20190628_2__v2'}"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "volumes_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "docker run --rm -v /mnt/data_900p/EUSO-Balloon/vrabel/notebooks/ver4_machine_learning_convnet_szakcs_w_labeled_flight_20190628_2__v2:/ver4_machine_learning_convnet_szakcs_w_labeled_flight_20190628_2__v2 -v /mnt/data_wdblue3d1/spbproc/convnet_euso/src:/src -w /src convnet_euso:0.25 python3 model_trainer.py --name train --test_name test --srcdir /ver4_machine_learning_convnet_szakcs_w_labeled_flight_20190628_2__v2/data --tb_dir /ver4_machine_learning_convnet_szakcs_w_labeled_flight_20190628_2__v2/model_trainer --load_yx --load_gtux --load_gtuy --split_mode args -n github_net3\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args='docker run --rm -v /mnt/data_900p/EUSO-Balloon/vrabel/notebooks/ver4_machine_learning_convnet_szakcs_w_labeled_flight_20190628_2__v2:/ver4_machine_learning_convnet_szakcs_w_labeled_flight_20190628_2__v2 -v /mnt/data_wdblue3d1/spbproc/convnet_euso/src:/src -w /src convnet_euso:0.25 python3 model_trainer.py --name train --test_name test --srcdir /ver4_machine_learning_convnet_szakcs_w_labeled_flight_20190628_2__v2/data --tb_dir /ver4_machine_learning_convnet_szakcs_w_labeled_flight_20190628_2__v2/model_trainer --load_yx --load_gtux --load_gtuy --split_mode args -n github_net3', returncode=1)"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_epochs': 11, 'test_name': 'test', 'test_items_count': None, 'learning_rate': None, 'name': 'train', 'validation_batch_size': None, 'split_mode': 'args', 'test_srcdir': '/ver4_machine_learning_convnet_szakcs_w_labeled_flight_20190628_2__v2/data', 'loss_fn': None, 'item_types': {'raw': False, 'yx': True, 'gtux': True, 'gtuy': True}, 'model_file': None, 'test_items_fraction': 0.1, 'srcdir': '/ver4_machine_learning_convnet_szakcs_w_labeled_flight_20190628_2__v2/data', 'snapshot_step': None, 'optimizer': None, 'save': False, 'batch_size': None, 'tb_dir': '/ver4_machine_learning_convnet_szakcs_w_labeled_flight_20190628_2__v2/model_trainer', 'network': 'github_net3'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tflearn/helpers/summarizer.py:9: The name tf.summary.merge is deprecated. Please use tf.compat.v1.summary.merge instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tflearn/helpers/trainer.py:25: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tflearn/collections.py:13: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tflearn/config.py:123: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tflearn/config.py:129: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tflearn/config.py:131: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"model_trainer.py\", line 21, in <module>\n",
      "    dataset = input_handler.load_dataset(name, item_types=item_types)\n",
      "  File \"/src/dataset/io/fs_io.py\", line 339, in load_dataset\n",
      "    data = self.load_data(name, dataset.item_types)\n",
      "  File \"/src/dataset/io/fs_io.py\", line 312, in load_data\n",
      "    raise Exception('File for item type {} does not exist'.format(item_type))\n",
      "Exception: File for item type yx does not exist\n"
     ]
    }
   ],
   "source": [
    "dataset_condenser_run_cmd_str = (\n",
    "    'docker run --rm {volumes} -v {src}:/src -w /src convnet_euso:0.25 python3 model_trainer.py ' \n",
    "    '--name train --test_name test --srcdir {export_dir} --tb_dir {trainer_dir} '\n",
    "    '--load_yx --load_gtux --load_gtuy --split_mode args -n {net_model}' \n",
    ").format(\n",
    "    volumes=' '.join('-v '+v for v in volumes_set),\n",
    "    src=covnet_euso_src_dir,\n",
    "    net_model='github_net3',\n",
    "    export_dir=in_container_dirs['export_dir'],\n",
    "    trainer_dir=in_container_dirs['trainer_dir'],\n",
    ")\n",
    "\n",
    "print('-'*100)\n",
    "print(dataset_condenser_run_cmd_str)\n",
    "print('-'*100)\n",
    "\n",
    "subprocess.run(\n",
    "    dataset_condenser_run_cmd_str, shell=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert 'y' in extra_metafields\n",
    "\n",
    "# for subset_name, dataset_condenser_input_df_path in dataset_condenser_input_df_path_dict.items():\n",
    "\n",
    "#     output_name = subset_name\n",
    "#     output_dir = os.path.join(data_snippets_dir, 'dataset_condenser', subset_name)  \n",
    "#     # data_snippets_dir mus be base, otherwise addtional docker volume is required\n",
    "    \n",
    "#     os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "#     data_volumes_str = ''\n",
    "#     for t_label, t_l in dataset_condenser_input_data_dirs_dict[subset_name].items():\n",
    "#         for d in t_l:\n",
    "#             data_volumes_str += ' -v {d}:{d}:ro'.format(d=d)\n",
    "    \n",
    "#     dataset_condenser_run_cmd_str = (\n",
    "#         'docker run --rm {data_volumes_str} -v {realpath_data_dir}:/{in_container_data_dir} -v {src}:/src -w /src convnet_euso:0.2 python3 dataset_condenser.py ' \n",
    "#             '--packet_dims 128 48 48 16 16 ' \n",
    "#             '-f /{input_df_path} ' \n",
    "#             '-d /{output_dir} '\n",
    "#             '-n {output_name} '\n",
    "#             '--store_yx --store_gtux --store_gtuy '\n",
    "#             '--target _meta '\n",
    "#             '--extra_metafields {extra_metafields_str} '\n",
    "#             '--target_column {target_column} '\n",
    "#             'gtupack --num_gtu_around 4 15' \n",
    "#     ).format(\n",
    "#             src=covnet_euso_src_dir,\n",
    "#             input_df_path=dataset_condenser_input_df_path,\n",
    "#             target_column='y',\n",
    "#             extra_metafields_str=' '.join(extra_metafields),\n",
    "#             output_name=output_name,\n",
    "#             output_dir=output_dir,\n",
    "#             in_container_data_dir=data_snippets_dir,\n",
    "#             realpath_data_dir=os.path.realpath(data_snippets_dir),\n",
    "#             data_volumes_str=data_volumes_str\n",
    "#         )\n",
    "    \n",
    "#     print('-'*100)\n",
    "#     print(dataset_condenser_run_cmd_str)\n",
    "#     print('-'*100)\n",
    "    \n",
    "#     subprocess.run(\n",
    "#         dataset_condenser_run_cmd_str, shell=True\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# docker build --tag convnet_euso:0.2 -f Dockerfile-gpu /mnt/data_wdblue3d1/spbproc/convnet_euso\n",
    "# docker run --rm  -v `realpath src`:/src -w /src  convnet_euso:0.2 dataset_condenser.py --help\n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance of the ExtraTreesClassifier model with RFECV features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# y_test = learning_data__y_test\n",
    "# y_test_pred = rfecv_selector_on_extra_trees_cls.predict(learning_data__var_th_X_test)\n",
    "\n",
    "# # intentionally not T (for comparison with older)\n",
    "# print(sklearn.metrics.confusion_matrix(\n",
    "#     y_test, \n",
    "#     y_test_pred))\n",
    "\n",
    "# print_confusion_matrix(\n",
    "#     y_test, \n",
    "#     y_test_pred, output_format='ipython_html_styled')\n",
    "\n",
    "# print_accuracy_cls_report(\n",
    "#     y_test, \n",
    "#     y_test_pred)\n",
    "\n",
    "# labeled_data_cls_stats = \\\n",
    "#     print_labeled_data_cls_stats(\n",
    "#         mask_arr_test=learning_data__lbl_noise_flight_mask_arr_test,\n",
    "#         y_test=y_test,\n",
    "#         y_test_pred=y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # y_test, y_test_pred\n",
    "# # sklearn.metrics.accuracy_score\n",
    "# X_train = learning_data__var_th_X_train\n",
    "# y_train = learning_data__y_train\n",
    "# w_train = learning_data__weights_train\n",
    "\n",
    "# X_test = learning_data__var_th_X_test\n",
    "# y_test = learning_data__y_test\n",
    "# y_test_pred = rfecv_selector_on_extra_trees_cls.predict(learning_data__var_th_X_test)\n",
    "# w_test = learning_data__weights_test\n",
    "\n",
    "# print('sklearn.metrics.accuracy_score:', sklearn.metrics.accuracy_score(y_test, y_test_pred, sample_weight=w_test))\n",
    "# print('balanced_accuracy_score:       ', balanced_accuracy_score(y_test, y_test_pred, sample_weight=w_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(figsize=(4,3))\n",
    "# ax.hist(rfecv_selector_on_extra_trees_cls.predict_proba(learning_data__var_th_X_test[learning_data__source_class_test == EVENT_CLASS_SIMU_TRACK])[:,1], \n",
    "#         bins=100, alpha=1, range=(0,1), label='Simu track')\n",
    "# ax.set_ylabel('Number of events')\n",
    "# ax.set_xlabel('Probability')\n",
    "# ax.set_yscale('log')\n",
    "# fig.savefig(os.path.join(data_snippets_dir, 'test_set_simu_track_proba_distribution_horizontal.svg'))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(figsize=(4,3))\n",
    "# ax.hist(rfecv_selector_on_extra_trees_cls.predict_proba(learning_data__var_th_X_test[learning_data__source_class_test == EVENT_CLASS_SIMU_TRACK])[:,1], \n",
    "#         bins=100, alpha=.5, range=(0,1), label='Simu track')\n",
    "# ax.hist(rfecv_selector_on_extra_trees_cls.predict_proba(learning_data__var_th_X_test[learning_data__source_class_test != EVENT_CLASS_SIMU_TRACK])[:,1], \n",
    "#         bins=100, alpha=.5, range=(0,1), label='Noise')\n",
    "# ax.set_ylabel('Number of events')\n",
    "# ax.set_xlabel('Probability')\n",
    "# ax.set_yscale('log')\n",
    "# fig.savefig(os.path.join(data_snippets_dir, 'test_set_both_proba_distribution_horizontal.svg'))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def cross_val_calc_weights(indices, learning_data__y=learning_data__y, learning_data__source_class=learning_data__source_class): \n",
    "#     return calc_learning_data_weights(learning_data__y[indices], learning_data__source_class[indices], print_info=False)\n",
    "\n",
    "# extra_trees_cls_on_train_rfecv_for_crossvalidation = sklearn.ensemble.ExtraTreesClassifier(**rfe_extra_trees_params)\n",
    "# # not entirely correct, feature selection should be also included in crossvalidation training\n",
    "\n",
    "# learning_data__rfecv_var_th_X = \\\n",
    "#     rfecv_selector_on_extra_trees_cls.transform(\n",
    "#         var_th_selector_on_scaled_train.transform(\n",
    "#             learning_data__X\n",
    "#         )\n",
    "#     )\n",
    "\n",
    "# extra_trees_cls_on_train_rfecv_for_crossvalidation_crv_results = \\\n",
    "#     cross_val_score_meta_scored(\n",
    "#         extra_trees_cls_on_train_rfecv_for_crossvalidation, \n",
    "#         learning_data__rfecv_var_th_X, learning_data__y, \n",
    "#         meta_score_func=None,\n",
    "#         score_func=balanced_accuracy_score,\n",
    "#         cv=3, random_state=32, \n",
    "#         train_sample_weight_func=cross_val_calc_weights\n",
    "# )\n",
    "\n",
    "# print('Cross-validation accuracy:', extra_trees_cls_on_train_rfecv_for_crossvalidation_crv_results)\n",
    "# print('Mean accuracy:            ', np.mean(extra_trees_cls_on_train_rfecv_for_crossvalidation_crv_results))\n",
    "# print('Std accuracy:             ', np.std(extra_trees_cls_on_train_rfecv_for_crossvalidation_crv_results))\n",
    "\n",
    "# extra_trees_cls_on_train_rfecv_for_crossvalidation_lbl_noise_flight_crv_results = \\\n",
    "# cross_val_score_meta_scored(\n",
    "#     extra_trees_cls_on_train_rfecv_for_crossvalidation,\n",
    "#     learning_data__rfecv_var_th_X, learning_data__y, \n",
    "#     cv=3, random_state=32, verbose=1,\n",
    "#     meta_score_func=score_masked_using_indices_lbl_noise_flight_mask_arr_all,\n",
    "#     train_sample_weight_func=cross_val_calc_weights\n",
    "# )\n",
    "\n",
    "# print('Cross-validation accuracy (lbl_noise):', extra_trees_cls_on_train_rfecv_for_crossvalidation_lbl_noise_flight_crv_results)\n",
    "# print('Mean accuracy (lbl_noise):            ', np.mean(extra_trees_cls_on_train_rfecv_for_crossvalidation_lbl_noise_flight_crv_results))\n",
    "# print('Std accuracy (lbl_noise):             ', np.std(extra_trees_cls_on_train_rfecv_for_crossvalidation_lbl_noise_flight_crv_results))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross-validation of labeled noise data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### random_state = 123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extra_trees_cls_on_train_rfecv_for_crossvalidation_lbl_noise_flight_crv_results_2 = \\\n",
    "# cross_val_score_meta_scored(\n",
    "#     extra_trees_cls_on_train_rfecv_for_crossvalidation,\n",
    "#     learning_data__rfecv_var_th_X, learning_data__y, \n",
    "#     cv=3, random_state=128, verbose=1,\n",
    "#     meta_score_func=score_masked_using_indices_lbl_noise_flight_mask_arr_all,\n",
    "#     train_sample_weight_func=cross_val_calc_weights\n",
    "# )\n",
    "# print('Cross-validation accuracy (lbl_noise, seed=123):', extra_trees_cls_on_train_rfecv_for_crossvalidation_lbl_noise_flight_crv_results_2)\n",
    "# print('Mean accuracy (lbl_noise, seed=123):            ', np.mean(extra_trees_cls_on_train_rfecv_for_crossvalidation_lbl_noise_flight_crv_results_2))\n",
    "# print('Std accuracy (lbl_noise, seed=123):             ', np.std(extra_trees_cls_on_train_rfecv_for_crossvalidation_lbl_noise_flight_crv_results_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recognition efficiency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test set sensitivity as function of the energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extra_trees_cls_on_train_rfecv__test__numbers_by_energy = \\\n",
    "#     score_by_column(\n",
    "#         rfecv_selector_on_extra_trees_cls, \n",
    "#         learning_data__var_th_X_test[learning_data__simu_shower_track_mask_arr_test], \n",
    "#         learning_data__y_test[learning_data__simu_shower_track_mask_arr_test], \n",
    "#         calc_cls_numbers, #sklearn.metrics.accuracy_score, \n",
    "#         learning_data__event_id_test[learning_data__simu_shower_track_mask_arr_test], \n",
    "#         combined_simu_df, 'etruth_trueenergy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.close('all')\n",
    "# for xscale in ('linear', 'log'):\n",
    "#     fig, ax, errbr = \\\n",
    "#         plot_efficiency_stat(\n",
    "#             extra_trees_cls_on_train_rfecv__test__numbers_by_energy, \n",
    "#             plotted_stat='sensitivity', plotted_yerr_stat='positive_sm_confint_beta_95', num_steps = 20, \n",
    "#             xscale=xscale, xtranslate_func=lambda l: [v*1e6 for v in l],\n",
    "#             xlabel = 'Energy [eV]', ylabel = 'Sensitivity', \n",
    "#             calc_cls_stats_from_numbers_func=calc_cls_stats_from_numbers_with_sm_proportion_confint,\n",
    "#             figsize=(6,3), ylim=(0,1.2), show=False)\n",
    "#     ax.grid(linestyle='--')\n",
    "#     fig.savefig(os.path.join(data_snippets_dir, 'figures', \n",
    "#                              'test_set_sensitivity_function_of_energy_{}_ev.svg'.format(xscale)), dpi=150)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.close('all')\n",
    "# for xscale in ('linear', 'log'):\n",
    "#     fig, ax, errbr = \\\n",
    "#         plot_efficiency_stat(\n",
    "#             extra_trees_cls_on_train_rfecv__test__numbers_by_energy, \n",
    "#             plotted_stat='sensitivity', plotted_yerr_stat='positive_sm_confint_beta_95', num_steps=11, \n",
    "#             xscale=xscale, xtranslate_func=lambda l: [v*1e6 for v in l],\n",
    "#             xlabel = 'Energy [MeV]', ylabel = 'Sensitivity', \n",
    "#             calc_cls_stats_from_numbers_func=calc_cls_stats_from_numbers_with_sm_proportion_confint,\n",
    "#             figsize=(6,3), ylim=(0,1.2), show=False)\n",
    "#     ax.grid(linestyle='--')\n",
    "#     fig.savefig(os.path.join(data_snippets_dir, 'figures', \n",
    "#                              'test_set_sensitivity_function_of_energy_{}_11steps.svg'.format(xscale)), dpi=150)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plt.close('all')\n",
    "# for xscale in ( 'linear', 'log', ):\n",
    "#     fig, ax, errbr = \\\n",
    "#         plot_efficiency_stat(\n",
    "#             extra_trees_cls_on_train_rfecv__test__numbers_by_energy, \n",
    "#             plotted_stat='sensitivity', plotted_yerr_stat='positive_sm_confint_beta_95', num_steps=20, \n",
    "#             xscale=xscale, xtranslate_func=lambda l: [v*1e6 for v in l],\n",
    "#             xlabel = 'Energy [MeV]', ylabel = 'Sensitivity', \n",
    "#             calc_cls_stats_from_numbers_func=calc_cls_stats_from_numbers_with_sm_proportion_confint,\n",
    "#             figsize=(5,3), ylim=(.2,1.2), show=False,\n",
    "# #         show_fill_between=False, show_yerr=True,\n",
    "# #         errorbar_attrs={**EFFICIENCY_STAT_ERRORBAR_DEFAULTS, 'ecolor': 'gray'}\n",
    "#     )\n",
    "#     ax.grid(linestyle='--')\n",
    "#     if xscale == 'linear' :\n",
    "# #         ax.xaxis.set_major_formatter(mpl.ticker.LogFormatterExponent(minor_thresholds=(np.inf, np.inf), labelOnlyBase=False))\n",
    "#         ax.xaxis.set_major_locator(mpl.ticker.LinearLocator(numticks=6))\n",
    "#         ax.xaxis.set_major_formatter(mpl.ticker.FuncFormatter(lambda v,n: '{:.3f}'.format(np.log10(v)) if v > 0 else '' ))\n",
    "#         ax.set_xlabel('log(Energy [eV])')\n",
    "        \n",
    "# #     else:\n",
    "# #         ax.set_xscale('symlog')\n",
    "# #         ax.xaxis.set_minor_formatter(mpl.ticker.ExponentFormatter(minor_thresholds=(100, 100), labelOnlyBase=False))\n",
    "# #         ax.xaxis.set_minor_formatter(mpl.ticker.LogFormatterExponent(minor_thresholds=(np.inf, np.inf), labelOnlyBase=False))\n",
    "# #         ax.xaxis.set_minor_locator(mpl.ticker.LogLocator(base=10.0, subs='auto', numdecs=4, numticks='auto'))\n",
    "        \n",
    "# #         ax.xaxis.set_minor_formatter(mpl.ticker.FuncFormatter(_t_f))\n",
    "\n",
    "# #         mil = ax.xaxis.get_minor_locator()\n",
    "\n",
    "# #         print(dir(mil))\n",
    "# #         print(mil._base)\n",
    "# #         print(mil._subs)\n",
    "# #         print(mil.numdecs)\n",
    "# #         print(mil.numticks)\n",
    "    \n",
    "# #     plt.close('all')\n",
    "    \n",
    "#     fig.savefig(os.path.join(data_snippets_dir, 'figures', \n",
    "#                              'test_set_sensitivity_function_of_energy_{}_20steps.svg'.format(xscale)), dpi=150)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.close('all')\n",
    "# for xscale in ( 'linear', 'log', ):\n",
    "#     fig, ax, errbr = \\\n",
    "#         plot_efficiency_stat(\n",
    "#             extra_trees_cls_on_train_rfecv__test__numbers_by_energy, \n",
    "#             plotted_stat='sensitivity', plotted_yerr_stat='positive_sm_confint_beta_95', num_steps=20, \n",
    "#             xscale=xscale, xtranslate_func=lambda l: [v*1e6 for v in l],\n",
    "#             xlabel = 'Energy [MeV]', ylabel = 'Efficiency', \n",
    "#             calc_cls_stats_from_numbers_func=calc_cls_stats_from_numbers_with_sm_proportion_confint,\n",
    "#             figsize=(5,3), ylim=(.4,1.1), show=False,\n",
    "# #         show_fill_between=False, show_yerr=True,\n",
    "# #         errorbar_attrs={**EFFICIENCY_STAT_ERRORBAR_DEFAULTS, 'ecolor': 'gray'}\n",
    "#     )\n",
    "#     ax.grid(linestyle='--')\n",
    "#     if xscale == 'linear' :\n",
    "# #         ax.xaxis.set_major_formatter(mpl.ticker.LogFormatterExponent(minor_thresholds=(np.inf, np.inf), labelOnlyBase=False))\n",
    "#         ax.xaxis.set_major_locator(mpl.ticker.LinearLocator(numticks=6))\n",
    "#         ax.xaxis.set_major_formatter(mpl.ticker.FuncFormatter(lambda v,n: '{:.3f}'.format(np.log10(v)) if v > 0 else '' ))\n",
    "#         ax.set_xlabel('log(Energy [eV])')\n",
    "        \n",
    "# #     else:\n",
    "# #         ax.set_xscale('symlog')\n",
    "# #         ax.xaxis.set_minor_formatter(mpl.ticker.ExponentFormatter(minor_thresholds=(100, 100), labelOnlyBase=False))\n",
    "# #         ax.xaxis.set_minor_formatter(mpl.ticker.LogFormatterExponent(minor_thresholds=(np.inf, np.inf), labelOnlyBase=False))\n",
    "# #         ax.xaxis.set_minor_locator(mpl.ticker.LogLocator(base=10.0, subs='auto', numdecs=4, numticks='auto'))\n",
    "        \n",
    "# #         ax.xaxis.set_minor_formatter(mpl.ticker.FuncFormatter(_t_f))\n",
    "\n",
    "# #         mil = ax.xaxis.get_minor_locator()\n",
    "\n",
    "# #         print(dir(mil))\n",
    "# #         print(mil._base)\n",
    "# #         print(mil._subs)\n",
    "# #         print(mil.numdecs)\n",
    "# #         print(mil.numticks)\n",
    "    \n",
    "# #     plt.close('all')\n",
    "    \n",
    "#     fig.savefig(os.path.join(data_snippets_dir, 'figures', \n",
    "#                              'test_set_sensitivity_function_of_energy_{}_20steps_efficiency_range_04_11.svg'.format(xscale)), dpi=150)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.close('all')\n",
    "# for xscale in ( 'linear', 'log', ):\n",
    "#     fig, ax, errbr = \\\n",
    "#         plot_efficiency_stat(\n",
    "#             extra_trees_cls_on_train_rfecv__test__numbers_by_energy, \n",
    "#             plotted_stat='sensitivity', plotted_yerr_stat='positive_sm_confint_beta_95', num_steps=20, \n",
    "#             xscale=xscale, xtranslate_func=lambda l: [v*1e6 for v in l],\n",
    "#             xlabel = 'Energy [MeV]', ylabel = 'Efficiency', \n",
    "#             calc_cls_stats_from_numbers_func=calc_cls_stats_from_numbers_with_sm_proportion_confint,\n",
    "#             figsize=(5,2.6), ylim=(.4,1.1), show=False,\n",
    "# #         show_fill_between=False, show_yerr=True,\n",
    "# #         errorbar_attrs={**EFFICIENCY_STAT_ERRORBAR_DEFAULTS, 'ecolor': 'gray'}\n",
    "#     )\n",
    "#     ax.grid(linestyle='--')\n",
    "#     if xscale == 'linear' :\n",
    "# #         ax.xaxis.set_major_formatter(mpl.ticker.LogFormatterExponent(minor_thresholds=(np.inf, np.inf), labelOnlyBase=False))\n",
    "#         ax.xaxis.set_major_locator(mpl.ticker.LinearLocator(numticks=6))\n",
    "#         ax.xaxis.set_major_formatter(mpl.ticker.FuncFormatter(lambda v,n: '{:.3f}'.format(np.log10(v)) if v > 0 else '' ))\n",
    "#         ax.set_xlabel('log(Energy [eV])')\n",
    "        \n",
    "# #     else:\n",
    "# #         ax.set_xscale('symlog')\n",
    "# #         ax.xaxis.set_minor_formatter(mpl.ticker.ExponentFormatter(minor_thresholds=(100, 100), labelOnlyBase=False))\n",
    "# #         ax.xaxis.set_minor_formatter(mpl.ticker.LogFormatterExponent(minor_thresholds=(np.inf, np.inf), labelOnlyBase=False))\n",
    "# #         ax.xaxis.set_minor_locator(mpl.ticker.LogLocator(base=10.0, subs='auto', numdecs=4, numticks='auto'))\n",
    "        \n",
    "# #         ax.xaxis.set_minor_formatter(mpl.ticker.FuncFormatter(_t_f))\n",
    "\n",
    "# #         mil = ax.xaxis.get_minor_locator()\n",
    "\n",
    "# #         print(dir(mil))\n",
    "# #         print(mil._base)\n",
    "# #         print(mil._subs)\n",
    "# #         print(mil.numdecs)\n",
    "# #         print(mil.numticks)\n",
    "    \n",
    "# #     plt.close('all')\n",
    "    \n",
    "#     fig.savefig(os.path.join(data_snippets_dir, 'figures', \n",
    "#                              'test_set_sensitivity_function_of_energy_{}_20steps_efficiency_range_04_11_h26.svg'.format(xscale)), dpi=150)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.close('all')\n",
    "# for xscale in ( 'linear', 'log', ):\n",
    "#     fig, ax, errbr = \\\n",
    "#         plot_efficiency_stat(\n",
    "#             extra_trees_cls_on_train_rfecv__test__numbers_by_energy, \n",
    "#             plotted_stat='sensitivity', plotted_yerr_stat='positive_sm_confint_beta_95', num_steps=20, \n",
    "#             xscale=xscale, xtranslate_func=lambda l: [v*1e6 for v in l],\n",
    "#             xlabel = 'Energy [MeV]', ylabel = 'Sensitivity', \n",
    "#             calc_cls_stats_from_numbers_func=calc_cls_stats_from_numbers_with_sm_proportion_confint,\n",
    "#             figsize=(5,3), ylim=(.4,1.1), show=False,\n",
    "#             show_fill_between=False, show_yerr=True,\n",
    "#             errorbar_attrs={**EFFICIENCY_STAT_ERRORBAR_DEFAULTS, 'ecolor': '#000000', 'linestyle': '--', 'color': 'gray'}\n",
    "#     )\n",
    "#     ax.grid(linestyle='--')\n",
    "#     if xscale == 'linear' :\n",
    "# #         ax.xaxis.set_major_formatter(mpl.ticker.LogFormatterExponent(minor_thresholds=(np.inf, np.inf), labelOnlyBase=False))\n",
    "#         ax.xaxis.set_major_locator(mpl.ticker.LinearLocator(numticks=6))\n",
    "#         ax.xaxis.set_major_formatter(mpl.ticker.FuncFormatter(lambda v,n: '{:.3f}'.format(np.log10(v)) if v > 0 else '' ))\n",
    "#         ax.set_xlabel('log(Energy [eV])')\n",
    "        \n",
    "# #     else:\n",
    "# #         ax.set_xscale('symlog')\n",
    "# #         ax.xaxis.set_minor_formatter(mpl.ticker.ExponentFormatter(minor_thresholds=(100, 100), labelOnlyBase=False))\n",
    "# #         ax.xaxis.set_minor_formatter(mpl.ticker.LogFormatterExponent(minor_thresholds=(np.inf, np.inf), labelOnlyBase=False))\n",
    "# #         ax.xaxis.set_minor_locator(mpl.ticker.LogLocator(base=10.0, subs='auto', numdecs=4, numticks='auto'))\n",
    "        \n",
    "# #         ax.xaxis.set_minor_formatter(mpl.ticker.FuncFormatter(_t_f))\n",
    "\n",
    "# #         mil = ax.xaxis.get_minor_locator()\n",
    "\n",
    "# #         print(dir(mil))\n",
    "# #         print(mil._base)\n",
    "# #         print(mil._subs)\n",
    "# #         print(mil.numdecs)\n",
    "# #         print(mil.numticks)\n",
    "    \n",
    "# #     plt.close('all')\n",
    "    \n",
    "#     fig.savefig(os.path.join(data_snippets_dir, 'figures', \n",
    "#                              'test_set_sensitivity_function_of_energy_{}_20steps_range_04_11_errbars.svg'.format(xscale)), dpi=150)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.close('all')\n",
    "# for xscale in ( 'linear',  ): #'log',\n",
    "#     fig, ax, errbr = \\\n",
    "#         plot_efficiency_stat(\n",
    "#             extra_trees_cls_on_train_rfecv__test__numbers_by_energy, \n",
    "#             plotted_stat='sensitivity', plotted_yerr_stat='positive_sm_confint_beta_95', num_steps=20, \n",
    "#             xscale=xscale, xtranslate_func=lambda l: [v*1e6 for v in l],\n",
    "#             xlabel = 'Energy [MeV]', ylabel = 'Sensitivity', \n",
    "#             calc_cls_stats_from_numbers_func=calc_cls_stats_from_numbers_with_sm_proportion_confint,\n",
    "#             figsize=(5,3), ylim=(.2,1.2), show=False,\n",
    "# #         show_fill_between=False, show_yerr=True,\n",
    "# #         errorbar_attrs={**EFFICIENCY_STAT_ERRORBAR_DEFAULTS, 'ecolor': 'gray'}\n",
    "#     )\n",
    "#     ax.grid(linestyle='--')\n",
    "#     if xscale == 'linear' :\n",
    "# #         ax.xaxis.set_major_formatter(mpl.ticker.LogFormatterExponent(minor_thresholds=(np.inf, np.inf), labelOnlyBase=False))\n",
    "#         ax.xaxis.set_major_locator(mpl.ticker.LinearLocator(numticks=6))\n",
    "#         ax.xaxis.xaxis.set_major_formatter(mpl.ticker.FuncFormatter(lambda v,n: '{:.3f}'.format(np.log10(v)) if v > 0 else '' ))\n",
    "#         ax.set_xlabel('log(Energy [eV])')\n",
    "        \n",
    "#         print(ax.get_xlim())\n",
    "#         print(ax.xaxis.get_major_locator())\n",
    "        \n",
    "# #     else:\n",
    "# #         ax.set_xscale('symlog')\n",
    "# #         ax.xaxis.set_minor_formatter(mpl.ticker.ExponentFormatter(minor_thresholds=(100, 100), labelOnlyBase=False))\n",
    "# #         ax.xaxis.set_minor_formatter(mpl.ticker.LogFormatterExponent(minor_thresholds=(np.inf, np.inf), labelOnlyBase=False))\n",
    "# #         ax.xaxis.set_minor_locator(mpl.ticker.LogLocator(base=10.0, subs='auto', numdecs=4, numticks='auto'))\n",
    "        \n",
    "# #         ax.xaxis.set_minor_formatter(mpl.ticker.FuncFormatter(_t_f))\n",
    "\n",
    "# #         mil = ax.xaxis.get_minor_locator()\n",
    "\n",
    "# #         print(dir(mil))\n",
    "# #         print(mil._base)\n",
    "# #         print(mil._subs)\n",
    "# #         print(mil.numdecs)\n",
    "# #         print(mil.numticks)\n",
    "    \n",
    "# #     plt.close('all')\n",
    "    \n",
    "# #     fig.savefig(os.path.join(data_snippets_dir, 'figures', \n",
    "# #                              'test_set_sensitivity_function_of_energy_{}_20steps.svg'.format(xscale)), dpi=150)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.close('all')\n",
    "# fig, ax, errbr = \\\n",
    "#     plot_efficiency_stat(\n",
    "#         extra_trees_cls_on_train_rfecv__test__numbers_by_energy, \n",
    "#         plotted_stat='sensitivity', plotted_yerr_stat='positive_sm_confint_beta_95', num_steps=20, \n",
    "#         xscale='linear', xtranslate_func=lambda l: [v*1e6 for v in l],\n",
    "#         xlabel = 'Energy [MeV]', ylabel = 'Sensitivity', \n",
    "#         calc_cls_stats_from_numbers_func=calc_cls_stats_from_numbers_with_sm_proportion_confint,\n",
    "#         figsize=(5,3), ylim=(.2,1.2), show=False,\n",
    "# #         show_fill_between=False, show_yerr=True,\n",
    "# #         errorbar_attrs={**EFFICIENCY_STAT_ERRORBAR_DEFAULTS, 'ecolor': 'gray'}\n",
    "# )\n",
    "\n",
    "# ax.grid(linestyle='--')\n",
    "# # ax.xaxis.set_major_formatter(mpl.ticker.LogFormatterExponent(minor_thresholds=(np.inf, np.inf), labelOnlyBase=False))\n",
    "# ax.xaxis.set_major_locator(mpl.ticker.LinearLocator(numticks=6))\n",
    "# ax.xaxis.set_major_formatter(mpl.ticker.FuncFormatter(lambda v,n: '{:.3f}'.format(np.log10(v)) if v > 0 else '' ))\n",
    "# ax.set_xlabel('log(Energy [eV])')\n",
    "\n",
    "# plot_x, plot_y, plot_xerr, plot_yerr = \\\n",
    "#     get_efficiency_stat_plot_data(extra_trees_cls_on_train_rfecv__test__numbers_by_energy, \n",
    "#                              plotted_stat='sensitivity', plotted_yerr_stat='positive_sm_confint_beta_95', num_steps = 10, \n",
    "# #                              xtranslate_func=lambda l: [v*1e6 for v in l],\n",
    "#                              calc_cls_stats_from_numbers_func=calc_cls_stats_from_numbers_with_sm_proportion_confint)\n",
    "\n",
    "# def fit_func(x, A,B,C): \n",
    "#     return A*np.exp(-B*x) + C\n",
    "\n",
    "# plot_x = np.array(plot_x) * 1e6\n",
    "\n",
    "# popt, pcov = sp_opt.curve_fit(fit_func, plot_x, plot_y, method='lm', p0=(-0.56, 0.965/1e18, 0.965), \n",
    "#                               sigma=np.array(plot_yerr[1])-plot_yerr[0])\n",
    "# print('popt:\\n', popt.tolist())\n",
    "# print('pcov:\\n', pcov)\n",
    "\n",
    "# orig_lim = ax.get_xlim()\n",
    "\n",
    "# func_plt_x = np.linspace(*orig_lim,100)\n",
    "# func_plt_y = fit_func(func_plt_x, *popt)\n",
    "\n",
    "# func_plt_y_simple = fit_func(func_plt_x, -0.927, 1.123e-18, 0.96)\n",
    "\n",
    "\n",
    "# # print(func_plt_x)\n",
    "# # print(func_plt_y)\n",
    "\n",
    "# # f,ax = plt.subplots()\n",
    "# ax.plot(func_plt_x, func_plt_y, 'r', alpha=0.5, zorder=10)\n",
    "# # ax.plot(func_plt_x, func_plt_y_simple, 'b', alpha=0.5, zorder=10)\n",
    "\n",
    "\n",
    "# ax.set_xlim(*orig_lim)\n",
    "# # ax.set_ylim(0.8,1)\n",
    "\n",
    "# fig.savefig(os.path.join(data_snippets_dir, 'figures', \n",
    "#                          'test_set_sensitivity_function_of_energy_linear_20steps_fitted.svg'), dpi=150)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of true positivie and positive samples as function of the energy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of positive samples as function of the energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for xscale in ('linear', 'log'):\n",
    "#     fig, ax, errbr = \\\n",
    "#         plot_efficiency_stat(extra_trees_cls_on_train_rfecv__test__numbers_by_energy, \n",
    "#                              plotted_stat='num_positive', num_steps = 20, \n",
    "#                              xscale=xscale, xtranslate_func=lambda l: [v*1e6 for v in l],\n",
    "#                              xlabel = 'Energy [eV]', ylabel = 'Num. positive', \n",
    "#                              figsize =(6,3), show=False)\n",
    "\n",
    "#     ax.grid(linestyle='--')\n",
    "#     if xscale == 'linear' :\n",
    "# #         ax.xaxis.set_major_formatter(mpl.ticker.LogFormatterExponent(minor_thresholds=(np.inf, np.inf), labelOnlyBase=False))\n",
    "#         ax.xaxis.set_major_locator(mpl.ticker.LinearLocator(numticks=6))\n",
    "#         ax.xaxis.set_major_formatter(mpl.ticker.FuncFormatter(lambda v,n: '{:.3f}'.format(np.log10(v)) if v > 0 else '' ))\n",
    "#         ax.set_xlabel('log(Energy [eV])')\n",
    "        \n",
    "#     fig.savefig(os.path.join(data_snippets_dir, 'figures', \n",
    "#                              'Number of positive samples as function of the energy - {}.svg'.format(xscale)), dpi=150)\n",
    "#     plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Number of true positive samples as function of the energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for xscale in ('linear', 'log'):\n",
    "#     fig, ax, errbr = \\\n",
    "#         plot_efficiency_stat(extra_trees_cls_on_train_rfecv__test__numbers_by_energy, \n",
    "#                              plotted_stat='num_true_positive', num_steps = 20, \n",
    "#                              xscale=xscale, xtranslate_func=lambda l: [v*1e6 for v in l],\n",
    "#                              xlabel = 'Energy [eV]', ylabel = 'Num. true positive', \n",
    "#                              figsize = (6,3), show=False)\n",
    "#     ax.grid(linestyle='--')\n",
    "#     if xscale == 'linear' :\n",
    "#         ax.xaxis.set_major_locator(mpl.ticker.LinearLocator(numticks=6))\n",
    "#         ax.xaxis.set_major_formatter(mpl.ticker.FuncFormatter(lambda v,n: '{:.3f}'.format(np.log10(v)) if v > 0 else '' ))\n",
    "# #         ax.xaxis.set_major_formatter(mpl.ticker.LogFormatterExponent(minor_thresholds=(np.inf, np.inf), labelOnlyBase=False))\n",
    "#         ax.set_xlabel('log(Energy [eV])')\n",
    "#     fig.savefig(os.path.join(data_snippets_dir, 'figures', \n",
    "#                              'Number of true positive samples as function of the energy - {}.svg'.format(xscale)), dpi=150)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Number of true positive or positive samples as function of the energy - comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plt.close('all')\n",
    "# for xscale in ('linear', 'log'):\n",
    "#     fig, ax = plt.subplots()\n",
    "#     fig, ax, errbr_num_positive = \\\n",
    "#         plot_efficiency_stat(\n",
    "#             extra_trees_cls_on_train_rfecv__test__numbers_by_energy, \n",
    "#             plotted_stat='num_positive', num_steps = 20, xscale=xscale, xtranslate_func=lambda l: [v*1e6 for v in l],\n",
    "#             xlabel = 'Energy [eV]', ylabel = 'Num. positive', label='Num. positive',\n",
    "#             figsize = (6,3), errorbar_attrs=dict(linestyle='--', color='blue'), \n",
    "#             ax=ax, show=False)\n",
    "#     fig, ax, errbr_num_true_positive = \\\n",
    "#         plot_efficiency_stat(\n",
    "#             extra_trees_cls_on_train_rfecv__test__numbers_by_energy, \n",
    "#             plotted_stat='num_true_positive', num_steps = 20, xscale=xscale, xtranslate_func=lambda l: [v*1e6 for v in l],\n",
    "#             xlabel='Energy [eV]', ylabel = 'Num. true positive', label='Num. true positive',\n",
    "#             figsize=(6,3), errorbar_attrs=dict(linestyle='-', color='green'),\n",
    "#             ax=ax, show=False)\n",
    "#     ax.set_ylabel('Num. samples')\n",
    "#     ax.grid(linestyle='--')\n",
    "#     if xscale == 'linear' :\n",
    "#         ax.xaxis.set_major_locator(mpl.ticker.LinearLocator(numticks=6))\n",
    "#         ax.xaxis.set_major_formatter(mpl.ticker.FuncFormatter(lambda v,n: '{:.3f}'.format(np.log10(v)) if v > 0 else '' ))\n",
    "# #         ax.xaxis.set_major_formatter(mpl.ticker.LogFormatterExponent(minor_thresholds=(np.inf, np.inf), labelOnlyBase=False))\n",
    "#         ax.set_xlabel('log(Energy [eV])')\n",
    "#     ax.grid(linestyle='--')\n",
    "#     fig.savefig(os.path.join(data_snippets_dir, 'figures', \n",
    "#                              'Number of true positive or positive samples as function of the energy - comparison - {}.svg'.format(xscale)), dpi=150)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test set sensitivity as function of the theta (zenith angle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extra_trees_cls_on_train_rfecv__test__numbers_by_theta = \\\n",
    "#     score_by_column(\n",
    "#         rfecv_selector_on_extra_trees_cls, \n",
    "#         learning_data__var_th_X_test[learning_data__simu_shower_track_mask_arr_test], \n",
    "#         learning_data__y_test[learning_data__simu_shower_track_mask_arr_test], \n",
    "#         calc_cls_numbers,\n",
    "#         learning_data__event_id_test[learning_data__simu_shower_track_mask_arr_test], \n",
    "#         combined_simu_df, 'etruth_truetheta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax, errbr = \\\n",
    "#     plot_efficiency_stat(extra_trees_cls_on_train_rfecv__test__numbers_by_theta, \n",
    "#                          plotted_stat='sensitivity', plotted_yerr_stat='positive_sm_confint_beta_95', num_steps = 90/2.5, \n",
    "#                          xtranslate_func=np.rad2deg,\n",
    "#                          xlabel ='True theta [deg]', ylabel = 'Sensitivity', \n",
    "#                          calc_cls_stats_from_numbers_func=calc_cls_stats_from_numbers_with_sm_proportion_confint,\n",
    "#                          figsize = (6,3), ylim=(0,1.5), show=False)\n",
    "# ax.grid()\n",
    "# fig.savefig(os.path.join(data_snippets_dir, 'figures', \n",
    "#                          'test_set_sensitivity_function_of_theta.svg'), dpi=150)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax, errbr = \\\n",
    "#     plot_efficiency_stat(extra_trees_cls_on_train_rfecv__test__numbers_by_theta, \n",
    "#                          plotted_stat='sensitivity', plotted_yerr_stat='positive_sm_confint_beta_95', num_steps = 90/5, \n",
    "#                          xtranslate_func=np.rad2deg,\n",
    "#                          xlabel ='Zenith angle [deg]', ylabel = 'Sensitivity', \n",
    "#                          calc_cls_stats_from_numbers_func=calc_cls_stats_from_numbers_with_sm_proportion_confint,\n",
    "#                          figsize = (5,3), ylim=(0.7,1.1), show=False,\n",
    "#                         )\n",
    "# ax.grid(linestyle='--')\n",
    "# fig.savefig(os.path.join(data_snippets_dir, 'figures', \n",
    "#                          'test_set_sensitivity_function_of_theta_5deg.svg'), dpi=150)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax, errbr = \\\n",
    "#     plot_efficiency_stat(extra_trees_cls_on_train_rfecv__test__numbers_by_theta, \n",
    "#                          plotted_stat='sensitivity', plotted_yerr_stat='positive_sm_confint_beta_95', num_steps = 90/5, \n",
    "#                          xtranslate_func=np.rad2deg,\n",
    "#                          xlabel ='Zenith angle', ylabel = 'Sensitivity', \n",
    "#                          calc_cls_stats_from_numbers_func=calc_cls_stats_from_numbers_with_sm_proportion_confint,\n",
    "#                          figsize = (5,3), ylim=(0.7,1.1), show=False,\n",
    "#                         )\n",
    "# ax.grid(linestyle='--')\n",
    "# ax.xaxis.set_major_formatter(mpl.ticker.StrMethodFormatter('{x:2.0f}°'))\n",
    "# fig.savefig(os.path.join(data_snippets_dir, 'figures', \n",
    "#                          'test_set_sensitivity_function_of_theta_5deg_formatter.svg'), dpi=150)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax, errbr = \\\n",
    "#     plot_efficiency_stat(extra_trees_cls_on_train_rfecv__test__numbers_by_theta, \n",
    "#                          plotted_stat='sensitivity', plotted_yerr_stat='positive_sm_confint_beta_95', num_steps = 90/10, \n",
    "#                          xtranslate_func=np.rad2deg,\n",
    "#                          xlabel ='Zenith angle', ylabel = 'Sensitivity', \n",
    "#                          calc_cls_stats_from_numbers_func=calc_cls_stats_from_numbers_with_sm_proportion_confint,\n",
    "#                          figsize = (5,3), ylim=(0.7,1.1), show=False,\n",
    "#                         )\n",
    "# ax.grid(linestyle='--')\n",
    "# ax.xaxis.set_major_formatter(mpl.ticker.StrMethodFormatter('{x:2.0f}°'))\n",
    "# fig.savefig(os.path.join(data_snippets_dir, 'figures', \n",
    "#                          'test_set_sensitivity_function_of_theta_10deg_formatter.svg'), dpi=150)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test set sensitivity as function of the phi (azimuth angle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extra_trees_cls_on_train_rfecv__test__numbers_by_phi = \\\n",
    "#     score_by_column(\n",
    "#         rfecv_selector_on_extra_trees_cls, \n",
    "#         learning_data__var_th_X_test[learning_data__simu_shower_track_mask_arr_test], \n",
    "#         learning_data__y_test[learning_data__simu_shower_track_mask_arr_test], \n",
    "#         calc_cls_numbers,\n",
    "#         learning_data__event_id_test[learning_data__simu_shower_track_mask_arr_test], \n",
    "#         combined_simu_df, 'etruth_truephi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax, errbr = \\\n",
    "#     plot_efficiency_stat(extra_trees_cls_on_train_rfecv__test__numbers_by_phi, \n",
    "#                          plotted_stat='sensitivity', plotted_yerr_stat='positive_sm_confint_beta_95', num_steps = 360/5, \n",
    "#                          xtranslate_func=np.rad2deg,\n",
    "#                          xlabel = 'Azmuth angle [deg]', ylabel = 'Sensitivity', \n",
    "#                          calc_cls_stats_from_numbers_func=calc_cls_stats_from_numbers_with_sm_proportion_confint,\n",
    "#                          figsize = (6,3), ylim=(0,1.5), show=False)\n",
    "# ax.grid()\n",
    "# fig.savefig(os.path.join(data_snippets_dir, 'figures', \n",
    "#                          'test_set_sensitivity_function_of_phi_10deg_5deg.svg'), dpi=150)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax, errbr = \\\n",
    "#     plot_efficiency_stat(extra_trees_cls_on_train_rfecv__test__numbers_by_phi, \n",
    "#                          plotted_stat='sensitivity', plotted_yerr_stat='positive_sm_confint_beta_95', num_steps = 360/15, \n",
    "#                          xtranslate_func=np.rad2deg,\n",
    "#                          xlabel = 'Azimuth angle [deg]', ylabel = 'Sensitivity', \n",
    "#                          calc_cls_stats_from_numbers_func=calc_cls_stats_from_numbers_with_sm_proportion_confint,\n",
    "#                          figsize = (5,3), ylim=(0.7,1.1), show=False)\n",
    "# ax.grid(linestyle='--')\n",
    "# fig.savefig(os.path.join(data_snippets_dir, 'figures', \n",
    "#                          'test_set_sensitivity_function_of_phi_15deg.svg'), dpi=150)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax, errbr = \\\n",
    "#     plot_efficiency_stat(extra_trees_cls_on_train_rfecv__test__numbers_by_phi, \n",
    "#                          plotted_stat='sensitivity', plotted_yerr_stat='positive_sm_confint_beta_95', num_steps = 360/15, \n",
    "#                          xtranslate_func=np.rad2deg,\n",
    "#                          xlabel = 'Azimuth angle', ylabel = 'Sensitivity', \n",
    "#                          calc_cls_stats_from_numbers_func=calc_cls_stats_from_numbers_with_sm_proportion_confint,\n",
    "#                          figsize = (5,3), ylim=(0.7,1.1), show=False)\n",
    "# ax.grid(linestyle='--')\n",
    "# ax.xaxis.set_major_formatter(mpl.ticker.StrMethodFormatter('{x:2.0f}°'))\n",
    "# fig.savefig(os.path.join(data_snippets_dir, 'figures', \n",
    "#                          'test_set_sensitivity_function_of_phi_15deg_formatter.svg'), dpi=150)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax, errbr = \\\n",
    "#     plot_efficiency_stat(extra_trees_cls_on_train_rfecv__test__numbers_by_phi, \n",
    "#                          plotted_stat='sensitivity', plotted_yerr_stat='positive_sm_confint_beta_95', num_steps = 360/10, \n",
    "#                          xtranslate_func=np.rad2deg,\n",
    "#                          xlabel = 'Azimuth angle [deg]', ylabel = 'Sensitivity', \n",
    "#                          calc_cls_stats_from_numbers_func=calc_cls_stats_from_numbers_with_sm_proportion_confint,\n",
    "#                          figsize = (5,3), ylim=(0.7,1.1), show=False)\n",
    "# ax.grid(linestyle='--')\n",
    "# fig.savefig(os.path.join(data_snippets_dir, 'figures', \n",
    "#                          'test_set_sensitivity_function_of_phi_10deg.svg'), dpi=150)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.close('all')\n",
    "# fig, ax = plt.subplots()\n",
    "# fig, ax, errbr_num_positive = \\\n",
    "#     plot_efficiency_stat(\n",
    "#         extra_trees_cls_on_train_rfecv__test__numbers_by_phi, \n",
    "#         plotted_stat='num_positive', num_steps = 360/10, \n",
    "#         xtranslate_func=np.rad2deg,\n",
    "#         xlabel = 'Azimuth angle [deg]', ylabel = 'Num. positive', label='Num. positive',\n",
    "#         figsize = (5,3), errorbar_attrs=dict(linestyle='--', color='blue'), \n",
    "#         ax=ax, show=False)\n",
    "# fig, ax, errbr_num_true_positive = \\\n",
    "#     plot_efficiency_stat(\n",
    "#         extra_trees_cls_on_train_rfecv__test__numbers_by_phi, \n",
    "#         plotted_stat='num_true_positive', num_steps = 360/10, \n",
    "#         xtranslate_func=np.rad2deg,\n",
    "#         xlabel='Azimuth angle [deg]', ylabel = 'Num. true positive', label='Num. true positive',\n",
    "#         figsize=(5,3), errorbar_attrs=dict(linestyle='-', color='green'),\n",
    "#         ax=ax, show=False)\n",
    "# ax.set_ylabel('Num. samples')\n",
    "# ax.grid(linestyle='--')\n",
    "# fig.savefig(os.path.join(data_snippets_dir, 'figures', \n",
    "#                          'test_set_num_positive_function_of_phi_comparison_10deg_{}.svg'.format(xscale)), dpi=150)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.close('all')\n",
    "\n",
    "# fig, ax, errbr = \\\n",
    "#     plot_efficiency_stat(extra_trees_cls_on_train_rfecv__test__numbers_by_phi, \n",
    "#                          plotted_stat='sensitivity', plotted_yerr_stat='positive_sm_confint_beta_95', num_steps = 360/10, \n",
    "#                          xtranslate_func=np.rad2deg,\n",
    "#                          xlabel = 'Azimuth angle [deg]', ylabel = 'Sensitivity', label='Sensitivity',\n",
    "#                          calc_cls_stats_from_numbers_func=calc_cls_stats_from_numbers_with_sm_proportion_confint,\n",
    "#                          figsize = (5,3), ylim=(0.7,1.1), show=False)\n",
    "\n",
    "\n",
    "# plot_x, plot_y, plot_xerr, plot_yerr = \\\n",
    "#     get_efficiency_stat_plot_data(\n",
    "#         extra_trees_cls_on_train_rfecv__test__numbers_by_phi, \n",
    "#         plotted_stat='num_positive', num_steps = 360/10, \n",
    "#         xtranslate_func=np.rad2deg)\n",
    "\n",
    "# ax.plot(plot_x, plot_y/max(plot_y), color='red', label='Norm. num. positive')\n",
    "\n",
    "# plot_x, plot_y, plot_xerr, plot_yerr = \\\n",
    "#     get_efficiency_stat_plot_data(\n",
    "#         extra_trees_cls_on_train_rfecv__test__numbers_by_phi, \n",
    "#         plotted_stat='num_true_positive', num_steps = 360/10, \n",
    "#         xtranslate_func=np.rad2deg)\n",
    "# ax.plot(plot_x, plot_y/max(plot_y), color='magenta', label='Norm. num. true positive')\n",
    "        \n",
    "# ax.set_ylim(0.2, 1.05)        \n",
    "# ax.set_ylabel('')\n",
    "# ax.grid(linestyle='--')\n",
    "# ax.legend()\n",
    "\n",
    "# fig.savefig(os.path.join(data_snippets_dir, 'figures', \n",
    "#                          'test_set_num_positive_function_of_phi_comparison_w_phi_10deg_{}.svg'.format(xscale)), dpi=150)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax, errbr = \\\n",
    "#     plot_efficiency_stat(extra_trees_cls_on_train_rfecv__test__numbers_by_phi, \n",
    "#                          plotted_stat='sensitivity', plotted_yerr_stat='positive_sm_confint_beta_95', num_steps = 360/20, \n",
    "#                          xtranslate_func=np.rad2deg,\n",
    "#                          xlabel = 'Azimuth angle [deg]', ylabel = 'Sensitivity', \n",
    "#                          calc_cls_stats_from_numbers_func=calc_cls_stats_from_numbers_with_sm_proportion_confint,\n",
    "#                          figsize = (5,3), ylim=(0.7,1.1), show=False)\n",
    "# ax.grid(linestyle='--')\n",
    "# fig.savefig(os.path.join(data_snippets_dir, 'figures', \n",
    "#                          'test_set_sensitivity_function_of_phi_20deg.svg'), dpi=150)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax, errbr = \\\n",
    "#     plot_efficiency_stat(extra_trees_cls_on_train_rfecv__test__numbers_by_phi, \n",
    "#                          plotted_stat='sensitivity', plotted_yerr_stat='sensitivity_err_mario', num_steps = 360/15, \n",
    "#                          xtranslate_func=np.rad2deg,\n",
    "#                          xlabel = 'Azimuth angle [deg]', ylabel = 'Sensitivity', \n",
    "#                          calc_cls_stats_from_numbers_func=calc_cls_stats_from_numbers_with_sm_proportion_confint,\n",
    "#                          figsize = (5,3), ylim=(0.7,1.1), show=False)\n",
    "# ax.grid(linestyle='--')\n",
    "# fig.savefig(os.path.join(data_snippets_dir, 'figures', \n",
    "#                          'test_set_sensitivity_function_of_phi_15deg_sensitivity_err_mario.svg'), dpi=150)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax, errbr = \\\n",
    "#     plot_efficiency_stat(extra_trees_cls_on_train_rfecv__test__numbers_by_phi, \n",
    "#                          plotted_stat='sensitivity', plotted_yerr_stat='positive_sm_confint_beta_95', num_steps = 360/20, \n",
    "#                          xtranslate_func=np.rad2deg,\n",
    "#                          xlabel = 'Azimuth angle [rad]', ylabel = 'Sensitivity', \n",
    "#                          calc_cls_stats_from_numbers_func=calc_cls_stats_from_numbers_with_sm_proportion_confint,\n",
    "#                          figsize = (6,3), ylim=(0,1.5), show=False)\n",
    "# ax.grid()\n",
    "# fig.savefig(os.path.join(data_snippets_dir, 'figures', \n",
    "#                          'test_set_sensitivity_function_of_phi_20deg_far.svg'), dpi=150)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extra_trees_cls_on_train_rfecv__test__numbers_by_rmax = \\\n",
    "#     score_by_column(\n",
    "#         rfecv_selector_on_extra_trees_cls, \n",
    "#         learning_data__var_th_X_test[learning_data__simu_shower_track_mask_arr_test], \n",
    "#         learning_data__y_test[learning_data__simu_shower_track_mask_arr_test], \n",
    "#         calc_cls_numbers,\n",
    "#         learning_data__event_id_test[learning_data__simu_shower_track_mask_arr_test], \n",
    "#         combined_simu_df, 'calc_etruth_trueshower_rmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax, errbr = \\\n",
    "#     plot_efficiency_stat(extra_trees_cls_on_train_rfecv__test__numbers_by_rmax, \n",
    "#                          plotted_stat='sensitivity', plotted_yerr_stat='positive_sm_confint_beta_95', num_steps = 10, \n",
    "#                          xtranslate_func=lambda l: [v/1e6 for v in l],\n",
    "#                          xlabel = '$R_{max}$ [km]', ylabel = 'Sensitivity', \n",
    "#                          calc_cls_stats_from_numbers_func=calc_cls_stats_from_numbers_with_sm_proportion_confint,\n",
    "#                          figsize = (5,3), ylim=(0,1.2), show=False,\n",
    "#                          filter_max_yerr=0.9\n",
    "# #                          show_fill_between=False, show_yerr=True\n",
    "#                         )\n",
    "# ax.grid(linestyle='--')\n",
    "# fig.savefig(os.path.join(data_snippets_dir, 'figures', \n",
    "#                          'test_set_sensitivity_function_of_rmax_10steps.svg'), dpi=150)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax, errbr = \\\n",
    "#     plot_efficiency_stat(extra_trees_cls_on_train_rfecv__test__numbers_by_rmax, \n",
    "#                          plotted_stat='sensitivity', plotted_yerr_stat='positive_sm_confint_beta_95', num_steps = 7, \n",
    "#                          xtranslate_func=lambda l: [v/1e6 for v in l],\n",
    "#                          xlabel = '$R_{max}$ [km]', ylabel = 'Sensitivity', \n",
    "#                          calc_cls_stats_from_numbers_func=calc_cls_stats_from_numbers_with_sm_proportion_confint,\n",
    "#                          figsize = (5,3), ylim=(0,1.5), show=False)\n",
    "# ax.grid(linestyle='--')\n",
    "# fig.savefig(os.path.join(data_snippets_dir, 'figures', \n",
    "#                          'test_set_sensitivity_function_of_rmax_7steps.svg'), dpi=150)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-validated recognition performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TODO\n",
    "\n",
    "# extra_trees_cls_on_train_rfecv_for_crossvalidation_per_trueenergy_results = \\\n",
    "#     cross_val_score_meta_scored(\n",
    "    \n",
    "#         extra_trees_cls_on_train_rfecv_for_crossvalidation, \n",
    "#         learning_data__rfecv_var_th_X, learning_data__y, \n",
    "#         meta_score_func=None,\n",
    "#         score_func=calc_cls_numbers,\n",
    "#         cv=3, random_state=32, \n",
    "#         train_sample_weight_func=cross_val_calc_weights\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#         extra_trees_cls_on_train_rfecv_for_crossvalidation,\n",
    "#         learning_data__rfecv_var_th_X, learning_data__y,\n",
    "#         get_func_score_by_column_using_indices(None, learning_data__event_id, combined_simu_df, 'etruth_trueenergy'),\n",
    "#         score_func=calc_cls_numbers,\n",
    "#         cv=sklearn.model_selection.RepeatedKFold(n_splits=5, n_repeats=10, random_state=123), verbose=1\n",
    "#     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Considering all samples from cross-validations (not very correct)\n",
    "All results from the cross-validations are joined into a single set (list) and then this set is used to calculate error - this multiplies size of the dataset by number of cross-validation folds.\n",
    "\n",
    "Functions are not using any results reduce function - parameter `dict_stats_yerr_reduce` is not set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.close('all')\n",
    "# for xscale in ['linear', 'log']:\n",
    "#     fig, ax, errbr = \\\n",
    "#         plot_efficiency_stat(extra_trees_cls_on_train_rfecv_for_crossvalidation_per_trueenergy_results, \n",
    "#                              plotted_stat='sensitivity', plotted_yerr_stat='positive_sm_confint_beta_95', num_steps = 20, xscale=xscale,\n",
    "#                              calc_cls_stats_from_numbers_func=calc_cls_stats_from_numbers_with_sm_proportion_confint,\n",
    "#                              xlabel = 'True energy [MeV]', ylabel = 'Sensitivity', \n",
    "#                              figsize = (10,6), ylim=(0,1.2), show=False)\n",
    "#     fig.savefig(os.path.join(data_snippets_dir, 'figures', \n",
    "#                              'Cross-validated - Considering all samples from cross-validations (not very correct) - sensitivity - {}.svg'.format(xscale)), dpi=150)\n",
    "# for xscale in ['linear', 'log']: \n",
    "#     fig, ax = plt.subplots()\n",
    "#     fig, ax, errbr_num_positive = \\\n",
    "#         plot_efficiency_stat(\n",
    "#             extra_trees_cls_on_train_rfecv_for_crossvalidation_per_trueenergy_results, \n",
    "#             plotted_stat='num_positive', num_steps = 20, xscale=xscale,\n",
    "#             xlabel = 'True energy [MeV]', ylabel = 'Num. positive', label='Num. positive',\n",
    "#             figsize = (10,6), errorbar_attrs=dict(linestyle='-', color='blue'),\n",
    "#             ax=ax, show=False)\n",
    "#     fig, ax, errbr_num_true_positive = \\\n",
    "#         plot_efficiency_stat(\n",
    "#             extra_trees_cls_on_train_rfecv_for_crossvalidation_per_trueenergy_results, \n",
    "#             plotted_stat='num_true_positive', num_steps = 20, xscale=xscale,\n",
    "#             xlabel='True energy [MeV]', ylabel = 'Num. true positive', label='Num. true positive',\n",
    "#             figsize=(10,6), errorbar_attrs=dict(linestyle='-', color='green'),\n",
    "#             ax=ax, show=False)\n",
    "#     ax.set_ylabel('Num. samples')\n",
    "#     ax.legend()\n",
    "#     fig.savefig(os.path.join(data_snippets_dir, 'figures', \n",
    "#                              'Cross-validated - Considering all samples from cross-validations (not very correct) - num samples - {}.svg'.format(xscale)), dpi=150)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Averaging sensitivities, error is standard deviation\n",
    "Parameter `dict_stats_yerr_reduce` is set to compute standard deviation of different cross-validation results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plt.close('all')\n",
    "# for xscale in ['linear', 'log']:\n",
    "#     fig, ax, errbr = \\\n",
    "#         plot_efficiency_stat(extra_trees_cls_on_train_rfecv_for_crossvalidation_per_trueenergy_results, \n",
    "#                              concat_dicts=False, dict_stats_yerr_reduce='std_y',\n",
    "#                              plotted_stat='sensitivity', plotted_yerr_stat='positive_sm_confint_beta_95', \n",
    "#                              calc_cls_stats_from_numbers_func=calc_cls_stats_from_numbers_with_sm_proportion_confint,\n",
    "#                              num_steps = 20, xscale=xscale,\n",
    "#                              xlabel = 'True energy [MeV]', ylabel = 'Sensitivity', \n",
    "#                              figsize = (10,6), ylim=(0,1.2), show=False)\n",
    "#     fig.savefig(os.path.join(data_snippets_dir, 'figures', \n",
    "#                              'Cross-validated - Averaging sensitivities, error is standard deviation - sensitivity - {}.svg'.format(xscale)), dpi=150)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Averaging sensitivities, error is min-max range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for confidence in [68, 95, 100]:\n",
    "#     print('Confidence:', confidence)\n",
    "#     for xscale in ['linear', 'log']:\n",
    "#         fig, ax, errbr = \\\n",
    "#             plot_efficiency_stat(extra_trees_cls_on_train_rfecv_for_crossvalidation_per_trueenergy_results, \n",
    "#                                  concat_dicts=False, dict_stats_yerr_reduce='minmax_y',\n",
    "#                                  plotted_stat='sensitivity', plotted_yerr_stat='positive_sm_confint_beta_'+str(confidence), \n",
    "#                                  num_steps = 20, xscale=xscale,\n",
    "#                                  calc_cls_stats_from_numbers_func=calc_cls_stats_from_numbers_with_sm_proportion_confint,\n",
    "#                                  xlabel = 'True energy [MeV]', ylabel = 'Sensitivity', \n",
    "#                                  figsize = (10,6), ylim=(0,1.2), show=False)\n",
    "#         fig.savefig(os.path.join(data_snippets_dir, 'figures', \n",
    "#                                  'Cross-validated - Averaging sensitivities, error is min-max range - sensitivity - {}.svg'.format(xscale)), dpi=150)\n",
    "#         plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Averaging sensitivities, error is avg_yerr_weighted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error should be an average of errors for cross-validated sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for confidence in [68, 95, 100]:\n",
    "#     print('Confidence:', confidence)\n",
    "#     for xscale in ['linear', 'log']:\n",
    "#         fig, ax, errbr = \\\n",
    "#             plot_efficiency_stat(extra_trees_cls_on_train_rfecv_for_crossvalidation_per_trueenergy_results, \n",
    "#                                  concat_dicts=False, dict_stats_yerr_reduce='avg_yerr_weighted',\n",
    "#                                  plotted_stat='sensitivity', plotted_yerr_stat='positive_sm_confint_beta_'+str(confidence), \n",
    "#                                  calc_cls_stats_from_numbers_func=calc_cls_stats_from_numbers_with_sm_proportion_confint,\n",
    "#                                  num_steps = 20, xscale=xscale,\n",
    "#                                  xlabel = 'True energy [MeV]', ylabel = 'Sensitivity', \n",
    "#                                  figsize = (10,6), ylim=(0,1.2))\n",
    "#         fig.savefig(os.path.join(data_snippets_dir, 'figures', \n",
    "#                                  'Cross-validated - Averaging sensitivities, error is avg_yerr_weighted - sensitivity - {}.svg'.format(xscale)), dpi=150)\n",
    "#         plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO\n",
    "- investigate sensitivity(background), use bg_mean column\n",
    "- investigate sensitivity(shower_max_pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flight data classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline_from_trained_models__extr_rfecv_vth__y_pred = \\\n",
    "#     pipeline_from_trained_models__extr_rfecv_vth.predict(\n",
    "#         unl_flight_df[dataset_condenser_df_columns].dropna().values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_non_shower = np.count_nonzero(pipeline_from_trained_models__extr_rfecv_vth__y_pred == 0)\n",
    "# num_shower = np.count_nonzero(pipeline_from_trained_models__extr_rfecv_vth__y_pred == 1)\n",
    "# tot_entries = len(unl_flight_df[dataset_condenser_df_columns].dropna().values)\n",
    "\n",
    "# print(\"Num. non-shower\", num_non_shower)\n",
    "# print(\"Num. shower\", num_shower)\n",
    "# print(\"All entries\", tot_entries)\n",
    "# print(\"-\"*30)\n",
    "# print(\"Fraction non-shower: {:.3f}\".format(num_non_shower/tot_entries))\n",
    "# print(\"Fraction shower: {:.3f}\".format(num_shower/tot_entries))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tsne_on_learning_data_60_rfecv_column_names_hexdigest = hashlib.md5((','.join(rfecv_selector_on_extra_trees__column_names__sorted[0:60])).encode()).hexdigest()\n",
    "\n",
    "# tsne_on_learning_data_60_rfecv_columns_alldata_pathname = \\\n",
    "#     os.path.join(data_snippets_dir, 'tsne_on_learning_data_60_rfecv_columns_alldata_{}.pkl'.format(\n",
    "#         tsne_on_learning_data_60_rfecv_column_names_hexdigest))\n",
    "# tsne_on_learning_data_60_rfecv_columns_scaler_alldata_pathname = \\\n",
    "#     os.path.join(data_snippets_dir, 'tsne_on_learning_data_60_rfecv_columns_{}_scale_alldatar.pkl'.format(\n",
    "#         tsne_on_learning_data_60_rfecv_column_names_hexdigest))\n",
    "\n",
    "# if refit_tsne_model or not os.path.exists(tsne_on_learning_data_60_rfecv_columns_alldata_pathname):\n",
    "#     tsne_on_learning_data_60_rfecv_columns_alldata = sklearn.manifold.TSNE(learning_rate=100, verbose=10, n_iter=5000)\n",
    "#     tsne_on_learning_data_60_rfecv_columns_scaler_alldata = sklearn.preprocessing.StandardScaler()\n",
    "    \n",
    "#     learning_data__X__tsne_learning_data_60_rfecv_columns_alldata = \\\n",
    "#         tsne_on_learning_data_60_rfecv_columns_alldata.fit_transform(\n",
    "#             tsne_on_learning_data_60_rfecv_columns_scaler_alldata.fit_transform(\n",
    "#                 rfecv_selector_on_extra_trees_cls.transform(learning_data__var_th_X_train).T[   # 232.T[\n",
    "#                     rfecv_selector_on_extra_trees__column_indices__sorted[0:60]].T              #       232[0:60]].T\n",
    "#             )\n",
    "#         )\n",
    "    \n",
    "#     if dump_tsne_model: \n",
    "#         print(tsne_on_learning_data_60_rfecv_columns_alldata_pathname)\n",
    "#         joblib.dump(tsne_on_learning_data_60_rfecv_columns_alldata, \n",
    "#                     tsne_on_learning_data_60_rfecv_columns_alldata_pathname, compress=1)\n",
    "        \n",
    "#         print(tsne_on_learning_data_60_rfecv_columns_scaler_alldata_pathname)\n",
    "#         joblib.dump(tsne_on_learning_data_60_rfecv_columns_scaler_alldata, \n",
    "#                     tsne_on_learning_data_60_rfecv_columns_scaler_alldata_pathname, compress=1)\n",
    "# else:\n",
    "#     tsne_on_learning_data_60_rfecv_columns = joblib.load(tsne_on_learning_data_60_rfecv_columns_alldata_pathname)\n",
    "\n",
    "#     learning_data__X__tsne_learning_data_60_rfecv_columns_alldata = \\\n",
    "#         tsne_on_learning_data_60_rfecv_columns.embedding_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joblib.dump(learning_data__X__tsne_learning_data_60_rfecv_columns_alldata, \n",
    "#                     tsne_on_learning_data_60_rfecv_columns_alldata_pathname, compress=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tsne_on_learning_data_60_rfecv_columns_alldata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
